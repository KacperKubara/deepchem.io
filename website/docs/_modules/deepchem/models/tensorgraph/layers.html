<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>deepchem.models.tensorgraph.layers &mdash; deepchem 1.3.1 documentation</title>
    
    <link rel="stylesheet" href="../../../../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../../',
        VERSION:     '1.3.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../../../../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../../../../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../../../../_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../../../../_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="deepchem 1.3.1 documentation" href="../../../../index.html" />
    <link rel="up" title="Module code" href="../../../index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-inverse navbar-default ">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../../index.html"><span><img src="../../../../_static/logo.png"></span>
          deepchem</a>
        <span class="navbar-text navbar-version pull-left"><b>1.3</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../../../../notebooks/index.html">Notebooks</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../../../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../deepchem.html">deepchem package</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"></ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <h1>Source code for deepchem.models.tensorgraph.layers</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: UTF-8 -*-</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Sequence</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">deepchem.models.tensorgraph</span> <span class="kn">import</span> <span class="n">model_ops</span><span class="p">,</span> <span class="n">initializations</span><span class="p">,</span> <span class="n">regularizers</span><span class="p">,</span> <span class="n">activations</span>
<span class="kn">import</span> <span class="nn">math</span>


<div class="viewcode-block" id="Layer"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Layer">[docs]</a><span class="k">class</span> <span class="nc">Layer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="n">layer_number_dict</span> <span class="o">=</span> <span class="p">{}</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="s2">&quot;name&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">if</span> <span class="n">in_layers</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">in_layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
      <span class="n">in_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">in_layers</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span> <span class="o">=</span> <span class="n">in_layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">op_type</span> <span class="o">=</span> <span class="s2">&quot;gpu&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">variable_scope</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">variable_values</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn_initial_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn_final_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn_zero_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tb_input</span> <span class="o">=</span> <span class="bp">None</span>

  <span class="k">def</span> <span class="nf">_get_layer_number</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">class_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
    <span class="k">if</span> <span class="n">class_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">Layer</span><span class="o">.</span><span class="n">layer_number_dict</span><span class="p">:</span>
      <span class="n">Layer</span><span class="o">.</span><span class="n">layer_number_dict</span><span class="p">[</span><span class="n">class_name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">Layer</span><span class="o">.</span><span class="n">layer_number_dict</span><span class="p">[</span><span class="n">class_name</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">Layer</span><span class="o">.</span><span class="n">layer_number_dict</span><span class="p">[</span><span class="n">class_name</span><span class="p">]</span>

<div class="viewcode-block" id="Layer.none_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Layer.none_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">none_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="Layer.set_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Layer.set_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">set_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tensor</span></div>

<div class="viewcode-block" id="Layer.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Layer.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Subclasses must implement for themselves&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="Layer.clone"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Layer.clone">[docs]</a>  <span class="k">def</span> <span class="nf">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a copy of this layer with different inputs.&quot;&quot;&quot;</span>
    <span class="n">saved_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">saved_tensors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">none_tensors</span><span class="p">()</span>
    <span class="n">copy</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span> <span class="o">=</span> <span class="n">saved_inputs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">set_tensors</span><span class="p">(</span><span class="n">saved_tensors</span><span class="p">)</span>
    <span class="n">copy</span><span class="o">.</span><span class="n">in_layers</span> <span class="o">=</span> <span class="n">in_layers</span>
    <span class="k">return</span> <span class="n">copy</span></div>

<div class="viewcode-block" id="Layer.shared"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Layer.shared">[docs]</a>  <span class="k">def</span> <span class="nf">shared</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a copy of this layer that shares variables with it.</span>

<span class="sd">    This is similar to clone(), but where clone() creates two independent layers,</span>
<span class="sd">    this causes the layers to share variables with each other.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    in_layers: list tensor</span>
<span class="sd">    List in tensors for the shared layer</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">variable_scope</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> does not implement shared()&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">in_layers</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_tensor</span><span class="p">(</span><span class="n">in_layers</span><span class="o">=</span><span class="n">in_layers</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get the shape of this Layer&#39;s output.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s1">&#39;_shape&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
          <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">: shape is not known&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span>

  <span class="k">def</span> <span class="nf">_get_input_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="p">,</span> <span class="n">reshape</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get the input tensors to his layer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    in_layers: list of Layers or tensors</span>
<span class="sd">      the inputs passed to create_tensor().  If None, this layer&#39;s inputs will</span>
<span class="sd">      be used instead.</span>
<span class="sd">    reshape: bool</span>
<span class="sd">      if True, try to reshape the inputs to all have the same shape</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">in_layers</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">in_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
      <span class="n">in_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">in_layers</span><span class="p">]</span>
    <span class="n">tensors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">in_layers</span><span class="p">:</span>
      <span class="n">tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">reshape</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tensors</span><span class="p">]</span>
      <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">s</span> <span class="o">!=</span> <span class="n">shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">shapes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="c1"># Reshape everything to match the input with the most dimensions.</span>

        <span class="n">shape</span> <span class="o">=</span> <span class="n">shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">shapes</span><span class="p">:</span>
          <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">s</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tensors</span><span class="p">)):</span>
          <span class="n">tensors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tensors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tensors</span>

  <span class="k">def</span> <span class="nf">_record_variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">local_scope</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Record the scope name used for creating variables.</span>

<span class="sd">    This should be called from create_tensor().  It allows the list of variables</span>
<span class="sd">    belonging to this layer to be retrieved later.&quot;&quot;&quot;</span>
    <span class="n">parent_scope</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable_scope</span><span class="p">()</span><span class="o">.</span><span class="n">name</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parent_scope</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">variable_scope</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">parent_scope</span><span class="p">,</span> <span class="n">local_scope</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">variable_scope</span> <span class="o">=</span> <span class="n">local_scope</span>

<div class="viewcode-block" id="Layer.set_variable_initial_values"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Layer.set_variable_initial_values">[docs]</a>  <span class="k">def</span> <span class="nf">set_variable_initial_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set the initial values of all variables.</span>

<span class="sd">    This takes a list, which contains the initial values to use for all of</span>
<span class="sd">    this layer&#39;s values (in the same order retured by</span>
<span class="sd">    TensorGraph.get_layer_variables()).  When this layer is used in a</span>
<span class="sd">    TensorGraph, it will automatically initialize each variable to the value</span>
<span class="sd">    specified in the list.  Note that some layers also have separate mechanisms</span>
<span class="sd">    for specifying variable initializers; this method overrides them. The</span>
<span class="sd">    purpose of this method is to let a Layer object represent a pre-trained</span>
<span class="sd">    layer, complete with trained values for its variables.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">variable_values</span> <span class="o">=</span> <span class="n">values</span></div>

<div class="viewcode-block" id="Layer.set_summary"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Layer.set_summary">[docs]</a>  <span class="k">def</span> <span class="nf">set_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">summary_op</span><span class="p">,</span> <span class="n">summary_description</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">collections</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Annotates a tensor with a tf.summary operation</span>
<span class="sd">    Collects data from self.out_tensor by default but can be changed by setting</span>
<span class="sd">    self.tb_input to another tensor in create_tensor</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    summary_op: str</span>
<span class="sd">      summary operation to annotate node</span>
<span class="sd">    summary_description: object, optional</span>
<span class="sd">      Optional summary_pb2.SummaryDescription()</span>
<span class="sd">    collections: list of graph collections keys, optional</span>
<span class="sd">      New summary op is added to these collections. Defaults to [GraphKeys.SUMMARIES]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">supported_ops</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;tensor_summary&#39;</span><span class="p">,</span> <span class="s1">&#39;scalar&#39;</span><span class="p">,</span> <span class="s1">&#39;histogram&#39;</span><span class="p">}</span>
    <span class="k">if</span> <span class="n">summary_op</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">supported_ops</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s2">&quot;Invalid summary_op arg. Only &#39;tensor_summary&#39;, &#39;scalar&#39;, &#39;histogram&#39; supported&quot;</span>
      <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">summary_op</span> <span class="o">=</span> <span class="n">summary_op</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">summary_description</span> <span class="o">=</span> <span class="n">summary_description</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">collections</span> <span class="o">=</span> <span class="n">collections</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard</span> <span class="o">=</span> <span class="bp">True</span></div>

<div class="viewcode-block" id="Layer.add_summary_to_tg"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Layer.add_summary_to_tg">[docs]</a>  <span class="k">def</span> <span class="nf">add_summary_to_tg</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Can only be called after self.create_layer to gaurentee that name is not none</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensorboard</span> <span class="o">==</span> <span class="bp">False</span><span class="p">:</span>
      <span class="k">return</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_input</span> <span class="o">==</span> <span class="bp">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">tb_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_op</span> <span class="o">==</span> <span class="s2">&quot;tensor_summary&quot;</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">tensor_summary</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_input</span><span class="p">,</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">summary_description</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">collections</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_op</span> <span class="o">==</span> <span class="s1">&#39;scalar&#39;</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">collections</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_op</span> <span class="o">==</span> <span class="s1">&#39;histogram&#39;</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tb_input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">collections</span><span class="p">)</span></div>

<div class="viewcode-block" id="Layer.copy"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Layer.copy">[docs]</a>  <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">replacements</span><span class="o">=</span><span class="p">{},</span> <span class="n">variables_graph</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">shared</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Duplicate this Layer and all its inputs.</span>

<span class="sd">    This is similar to clone(), but instead of only cloning one layer, it also</span>
<span class="sd">    recursively calls copy() on all of this layer&#39;s inputs to clone the entire</span>
<span class="sd">    hierarchy of layers.  In the process, you can optionally tell it to replace</span>
<span class="sd">    particular layers with specific existing ones.  For example, you can clone a</span>
<span class="sd">    stack of layers, while connecting the topmost ones to different inputs.</span>

<span class="sd">    For example, consider a stack of dense layers that depend on an input:</span>

<span class="sd">    &gt;&gt;&gt; input = Feature(shape=(None, 100))</span>
<span class="sd">    &gt;&gt;&gt; dense1 = Dense(100, in_layers=input)</span>
<span class="sd">    &gt;&gt;&gt; dense2 = Dense(100, in_layers=dense1)</span>
<span class="sd">    &gt;&gt;&gt; dense3 = Dense(100, in_layers=dense2)</span>

<span class="sd">    The following will clone all three dense layers, but not the input layer.</span>
<span class="sd">    Instead, the input to the first dense layer will be a different layer</span>
<span class="sd">    specified in the replacements map.</span>

<span class="sd">    &gt;&gt;&gt; new_input = Feature(shape=(None, 100))</span>
<span class="sd">    &gt;&gt;&gt; replacements = {input: new_input}</span>
<span class="sd">    &gt;&gt;&gt; dense3_copy = dense3.copy(replacements)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    replacements: map</span>
<span class="sd">      specifies existing layers, and the layers to replace them with (instead of</span>
<span class="sd">      cloning them).  This argument serves two purposes.  First, you can pass in</span>
<span class="sd">      a list of replacements to control which layers get cloned.  In addition,</span>
<span class="sd">      as each layer is cloned, it is added to this map.  On exit, it therefore</span>
<span class="sd">      contains a complete record of all layers that were copied, and a reference</span>
<span class="sd">      to the copy of each one.</span>
<span class="sd">    variables_graph: TensorGraph</span>
<span class="sd">      an optional TensorGraph from which to take variables.  If this is specified,</span>
<span class="sd">      the current value of each variable in each layer is recorded, and the copy</span>
<span class="sd">      has that value specified as its initial value.  This allows a piece of a</span>
<span class="sd">      pre-trained model to be copied to another model.</span>
<span class="sd">    shared: bool</span>
<span class="sd">      if True, create new layers by calling shared() on the input layers.</span>
<span class="sd">      This means the newly created layers will share variables with the original</span>
<span class="sd">      ones.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span> <span class="ow">in</span> <span class="n">replacements</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">replacements</span><span class="p">[</span><span class="bp">self</span><span class="p">]</span>
    <span class="n">copied_inputs</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">replacements</span><span class="p">,</span> <span class="n">variables_graph</span><span class="p">,</span> <span class="n">shared</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span>
    <span class="p">]</span>
    <span class="k">if</span> <span class="n">shared</span><span class="p">:</span>
      <span class="n">copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">copied_inputs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">copied_inputs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">variables_graph</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">shared</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot specify variables_graph when shared==True&#39;</span><span class="p">)</span>
      <span class="n">variables</span> <span class="o">=</span> <span class="n">variables_graph</span><span class="o">.</span><span class="n">get_layer_variables</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">variables_graph</span><span class="o">.</span><span class="n">_get_tf</span><span class="p">(</span><span class="s2">&quot;Graph&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
          <span class="n">values</span> <span class="o">=</span> <span class="n">variables_graph</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span>
          <span class="n">copy</span><span class="o">.</span><span class="n">set_variable_initial_values</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">copy</span></div>

  <span class="k">def</span> <span class="nf">_as_graph_element</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="s1">&#39;_as_graph_element&#39;</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="o">.</span><span class="n">_as_graph_element</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span>

  <span class="k">def</span> <span class="fm">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Layer</span><span class="p">):</span>
      <span class="n">other</span> <span class="o">=</span> <span class="n">Constant</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Add</span><span class="p">([</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">])</span>

  <span class="k">def</span> <span class="fm">__radd__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Layer</span><span class="p">):</span>
      <span class="n">other</span> <span class="o">=</span> <span class="n">Constant</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Add</span><span class="p">([</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">])</span>

  <span class="k">def</span> <span class="fm">__sub__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Layer</span><span class="p">):</span>
      <span class="n">other</span> <span class="o">=</span> <span class="n">Constant</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Add</span><span class="p">([</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">])</span>

  <span class="k">def</span> <span class="fm">__rsub__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Layer</span><span class="p">):</span>
      <span class="n">other</span> <span class="o">=</span> <span class="n">Constant</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Add</span><span class="p">([</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">])</span>

  <span class="k">def</span> <span class="fm">__mul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Layer</span><span class="p">):</span>
      <span class="n">other</span> <span class="o">=</span> <span class="n">Constant</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Multiply</span><span class="p">([</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">])</span>

  <span class="k">def</span> <span class="fm">__rmul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Layer</span><span class="p">):</span>
      <span class="n">other</span> <span class="o">=</span> <span class="n">Constant</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Multiply</span><span class="p">([</span><span class="n">other</span><span class="p">,</span> <span class="bp">self</span><span class="p">])</span>

  <span class="k">def</span> <span class="fm">__neg__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">Multiply</span><span class="p">([</span><span class="bp">self</span><span class="p">,</span> <span class="n">Constant</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">)])</span>

  <span class="k">def</span> <span class="fm">__div__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Layer</span><span class="p">):</span>
      <span class="n">other</span> <span class="o">=</span> <span class="n">Constant</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Divide</span><span class="p">([</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">])</span>

  <span class="k">def</span> <span class="fm">__truediv__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Layer</span><span class="p">):</span>
      <span class="n">other</span> <span class="o">=</span> <span class="n">Constant</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Divide</span><span class="p">([</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">])</span></div>


<span class="k">def</span> <span class="nf">_convert_layer_to_tensor</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">as_ref</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>


<span class="n">tf</span><span class="o">.</span><span class="n">register_tensor_conversion_function</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="n">_convert_layer_to_tensor</span><span class="p">)</span>


<div class="viewcode-block" id="TensorWrapper"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.TensorWrapper">[docs]</a><span class="k">class</span> <span class="nc">TensorWrapper</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Used to wrap a tensorflow tensor.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">out_tensor</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">TensorWrapper</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">out_tensor</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>

<div class="viewcode-block" id="TensorWrapper.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.TensorWrapper.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Take no actions.&quot;&quot;&quot;</span>
    <span class="k">pass</span></div></div>


<div class="viewcode-block" id="convert_to_layers"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.convert_to_layers">[docs]</a><span class="k">def</span> <span class="nf">convert_to_layers</span><span class="p">(</span><span class="n">in_layers</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Wrap all inputs into tensors if necessary.&quot;&quot;&quot;</span>
  <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">in_layer</span> <span class="ow">in</span> <span class="n">in_layers</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">in_layer</span><span class="p">,</span> <span class="n">Layer</span><span class="p">):</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">in_layer</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">in_layer</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">TensorWrapper</span><span class="p">(</span><span class="n">in_layer</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;convert_to_layers must be invoked on layers or tensors&quot;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">layers</span></div>


<div class="viewcode-block" id="SharedVariableScope"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.SharedVariableScope">[docs]</a><span class="k">class</span> <span class="nc">SharedVariableScope</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A Layer that can share variables with another layer via name scope.</span>

<span class="sd">  This abstract class can be used as a parent for any layer that implements</span>
<span class="sd">  shared() by means of the variable name scope.  It exists to avoid duplicated</span>
<span class="sd">  code.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">SharedVariableScope</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reuse</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_shared_with</span> <span class="o">=</span> <span class="bp">None</span>

<div class="viewcode-block" id="SharedVariableScope.shared"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.SharedVariableScope.shared">[docs]</a>  <span class="k">def</span> <span class="nf">shared</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="p">):</span>
    <span class="n">copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reuse</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">copy</span><span class="o">.</span><span class="n">_reuse</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">copy</span><span class="o">.</span><span class="n">_shared_with</span> <span class="o">=</span> <span class="bp">self</span>
    <span class="k">return</span> <span class="n">copy</span></div>

  <span class="k">def</span> <span class="nf">_get_scope_name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shared_with</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shared_with</span><span class="o">.</span><span class="n">_get_scope_name</span><span class="p">()</span></div>


<div class="viewcode-block" id="Conv1D"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Conv1D">[docs]</a><span class="k">class</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A 1D convolution on the input.</span>

<span class="sd">  This layer expects its input to be a three dimensional tensor of shape (batch size, width, # channels).</span>
<span class="sd">  If there is only one channel, the third dimension may optionally be omitted.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">filters</span><span class="p">,</span>
               <span class="n">kernel_size</span><span class="p">,</span>
               <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">,</span>
               <span class="n">dilation_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
               <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
               <span class="n">bias_initializer</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span>
               <span class="n">kernel_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">bias_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">activity_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">kernel_constraint</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">bias_constraint</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;1D convolution layer (e.g. temporal convolution).</span>

<span class="sd">      This layer creates a convolution kernel that is convolved</span>
<span class="sd">      with the layer input over a single spatial (or temporal) dimension</span>
<span class="sd">      to produce a tensor of outputs.</span>
<span class="sd">      If `use_bias` is True, a bias vector is created and added to the outputs.</span>
<span class="sd">      Finally, if `activation` is not `None`,</span>
<span class="sd">      it is applied to the outputs as well.</span>

<span class="sd">      When using this layer as the first layer in a model,</span>
<span class="sd">      provide an `input_shape` argument</span>
<span class="sd">      (tuple of integers or `None`, e.g.</span>
<span class="sd">      `(10, 128)` for sequences of 10 vectors of 128-dimensional vectors,</span>
<span class="sd">      or `(None, 128)` for variable-length sequences of 128-dimensional vectors.</span>

<span class="sd">      TODO(LESWING): Calculate output shape at construction time</span>
<span class="sd">      Arguments:</span>
<span class="sd">          filters: Integer, the dimensionality of the output space</span>
<span class="sd">              (i.e. the number output of filters in the convolution).</span>
<span class="sd">          kernel_size: An integer or tuple/list of a single integer,</span>
<span class="sd">              specifying the length of the 1D convolution window.</span>
<span class="sd">          strides: An integer or tuple/list of a single integer,</span>
<span class="sd">              specifying the stride length of the convolution.</span>
<span class="sd">              Specifying any stride value != 1 is incompatible with specifying</span>
<span class="sd">              any `dilation_rate` value != 1.</span>
<span class="sd">          padding: One of `&quot;valid&quot;`, `&quot;causal&quot;` or `&quot;same&quot;` (case-insensitive).</span>
<span class="sd">              `&quot;causal&quot;` results in causal (dilated) convolutions, e.g. output[t]</span>
<span class="sd">              does not depend on input[t+1:]. Useful when modeling temporal data</span>
<span class="sd">              where the model should not violate the temporal order.</span>
<span class="sd">              See [WaveNet: A Generative Model for Raw Audio, section</span>
<span class="sd">                2.1](https://arxiv.org/abs/1609.03499).</span>
<span class="sd">          dilation_rate: an integer or tuple/list of a single integer, specifying</span>
<span class="sd">              the dilation rate to use for dilated convolution.</span>
<span class="sd">              Currently, specifying any `dilation_rate` value != 1 is</span>
<span class="sd">              incompatible with specifying any `strides` value != 1.</span>
<span class="sd">          activation: Activation function to use.</span>
<span class="sd">              If you don&#39;t specify anything, no activation is applied</span>
<span class="sd">              (ie. &quot;linear&quot; activation: `a(x) = x`).</span>
<span class="sd">          use_bias: Boolean, whether the layer uses a bias vector.</span>
<span class="sd">          kernel_initializer: Initializer for the `kernel` weights matrix.</span>
<span class="sd">          bias_initializer: Initializer for the bias vector.</span>
<span class="sd">          kernel_regularizer: Regularizer function applied to</span>
<span class="sd">              the `kernel` weights matrix.</span>
<span class="sd">          bias_regularizer: Regularizer function applied to the bias vector.</span>
<span class="sd">          activity_regularizer: Regularizer function applied to</span>
<span class="sd">              the output of the layer (its &quot;activation&quot;)..</span>
<span class="sd">          kernel_constraint: Constraint function applied to the kernel matrix.</span>
<span class="sd">          bias_constraint: Constraint function applied to the bias vector.</span>

<span class="sd">      Input shape:</span>
<span class="sd">          3D tensor with shape: `(batch_size, steps, input_dim)`</span>

<span class="sd">      Output shape:</span>
<span class="sd">          3D tensor with shape: `(batch_size, new_steps, filters)`</span>
<span class="sd">          `steps` value might have changed due to padding or strides.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">filters</span> <span class="o">=</span> <span class="n">filters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">strides</span> <span class="o">=</span> <span class="n">strides</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dilation_rate</span> <span class="o">=</span> <span class="n">dilation_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span> <span class="o">=</span> <span class="n">use_bias</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">kernel_initializer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias_initializer</span> <span class="o">=</span> <span class="n">bias_initializer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="n">kernel_regularizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias_regularizer</span> <span class="o">=</span> <span class="n">bias_regularizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activity_regularizer</span> <span class="o">=</span> <span class="n">activity_regularizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_constraint</span> <span class="o">=</span> <span class="n">kernel_constraint</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias_constraint</span> <span class="o">=</span> <span class="n">bias_constraint</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Conv1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="Conv1D.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Conv1D.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Conv1D layer must have exactly one parent&quot;</span><span class="p">)</span>
    <span class="n">parent</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parent</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
      <span class="n">parent</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">parent</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">parent</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Parent tensor must be (batch, width, channel)&quot;</span><span class="p">)</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span>
        <span class="n">filters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">filters</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
        <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">strides</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
        <span class="n">dilation_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dilation_rate</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
        <span class="n">use_bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">use_bias</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_initializer</span><span class="p">,</span>
        <span class="n">bias_initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_initializer</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_regularizer</span><span class="p">,</span>
        <span class="n">bias_regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_regularizer</span><span class="p">,</span>
        <span class="n">activity_regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activity_regularizer</span><span class="p">,</span>
        <span class="n">kernel_constraint</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_constraint</span><span class="p">,</span>
        <span class="n">bias_constraint</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_constraint</span><span class="p">)(</span><span class="n">parent</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_record_variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Dense"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Dense">[docs]</a><span class="k">class</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">SharedVariableScope</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
      <span class="bp">self</span><span class="p">,</span>
      <span class="n">out_channels</span><span class="p">,</span>
      <span class="n">activation_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
      <span class="n">biases_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">,</span>
      <span class="n">weights_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">variance_scaling_initializer</span><span class="p">,</span>
      <span class="n">time_series</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
      <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a dense layer.</span>

<span class="sd">    The weight and bias initializers are specified by callable objects that construct</span>
<span class="sd">    and return a Tensorflow initializer when invoked with no arguments.  This will typically</span>
<span class="sd">    be either the initializer class itself (if the constructor does not require arguments),</span>
<span class="sd">    or a TFWrapper (if it does).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    out_channels: int</span>
<span class="sd">      the number of output values</span>
<span class="sd">    activation_fn: object</span>
<span class="sd">      the Tensorflow activation function to apply to the output</span>
<span class="sd">    biases_initializer: callable object</span>
<span class="sd">      the initializer for bias values.  This may be None, in which case the layer</span>
<span class="sd">      will not include biases.</span>
<span class="sd">    weights_initializer: callable object</span>
<span class="sd">      the initializer for weight values</span>
<span class="sd">    time_series: bool</span>
<span class="sd">      if True, the dense layer is applied to each element of a batch in sequence</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Dense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">activation_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">biases_initializer</span> <span class="o">=</span> <span class="n">biases_initializer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights_initializer</span> <span class="o">=</span> <span class="n">weights_initializer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">time_series</span> <span class="o">=</span> <span class="n">time_series</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">parent_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="n">out_channels</span><span class="p">,)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Dense.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Dense.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Dense layer can only have one input&quot;</span><span class="p">)</span>
    <span class="n">parent</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases_initializer</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">biases_initializer</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">biases_initializer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases_initializer</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">reuse</span> <span class="ow">in</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_reuse</span><span class="p">,</span> <span class="bp">False</span><span class="p">):</span>
      <span class="n">dense_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>
                                                             <span class="n">num_outputs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span>
                                                             <span class="n">activation_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span><span class="p">,</span>
                                                             <span class="n">biases_initializer</span><span class="o">=</span><span class="n">biases_initializer</span><span class="p">,</span>
                                                             <span class="n">weights_initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_initializer</span><span class="p">(),</span>
                                                             <span class="n">scope</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_scope_name</span><span class="p">(),</span>
                                                             <span class="n">reuse</span><span class="o">=</span><span class="n">reuse</span><span class="p">,</span>
                                                             <span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_series</span><span class="p">:</span>
          <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">map_fn</span><span class="p">(</span><span class="n">dense_fn</span><span class="p">,</span> <span class="n">parent</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">dense_fn</span><span class="p">(</span><span class="n">parent</span><span class="p">)</span>
        <span class="k">break</span>
      <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">reuse</span><span class="p">:</span>
          <span class="c1"># This probably means the variable hasn&#39;t been created yet, so try again</span>
          <span class="c1"># with reuse set to false.</span>
          <span class="k">continue</span>
        <span class="k">raise</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_record_variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_scope_name</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Highway"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Highway">[docs]</a><span class="k">class</span> <span class="nc">Highway</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Create a highway layer. y = H(x) * T(x) + x * (1 - T(x))</span>
<span class="sd">  H(x) = activation_fn(matmul(W_H, x) + b_H) is the non-linear transformed output</span>
<span class="sd">  T(x) = sigmoid(matmul(W_T, x) + b_T) is the transform gate</span>

<span class="sd">  reference: https://arxiv.org/pdf/1505.00387.pdf</span>

<span class="sd">  This layer expects its input to be a two dimensional tensor of shape (batch size, # input features).</span>
<span class="sd">  Outputs will be in the same shape.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
      <span class="bp">self</span><span class="p">,</span>
      <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
      <span class="n">biases_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">,</span>
      <span class="n">weights_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">variance_scaling_initializer</span><span class="p">,</span>
      <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    activation_fn: object</span>
<span class="sd">      the Tensorflow activation function to apply to the output</span>
<span class="sd">    biases_initializer: callable object</span>
<span class="sd">      the initializer for bias values.  This may be None, in which case the layer</span>
<span class="sd">      will not include biases.</span>
<span class="sd">    weights_initializer: callable object</span>
<span class="sd">      the initializer for weight values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Highway</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">activation_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">biases_initializer</span> <span class="o">=</span> <span class="n">biases_initializer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights_initializer</span> <span class="o">=</span> <span class="n">weights_initializer</span>

<div class="viewcode-block" id="Highway.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Highway.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">parent</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1"># H(x), with same number of input and output channels</span>
    <span class="n">dense_H</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span>
        <span class="n">parent</span><span class="p">,</span>
        <span class="n">num_outputs</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">activation_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span><span class="p">,</span>
        <span class="n">biases_initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">biases_initializer</span><span class="p">(),</span>
        <span class="n">weights_initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_initializer</span><span class="p">(),</span>
        <span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="c1"># T(x), with same number of input and output channels</span>
    <span class="n">dense_T</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span>
        <span class="n">parent</span><span class="p">,</span>
        <span class="n">num_outputs</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">,</span>
        <span class="n">biases_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">weights_initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_initializer</span><span class="p">(),</span>
        <span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">dense_H</span><span class="p">,</span> <span class="n">dense_T</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span>
        <span class="n">parent</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">dense_T</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Flatten"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Flatten">[docs]</a><span class="k">class</span> <span class="nc">Flatten</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Flatten every dimension except the first&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Flatten</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="n">s</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">parent_shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
      <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">parent_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]:</span>
        <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*=</span> <span class="n">x</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Flatten.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Flatten.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only One Parent to Flatten&quot;</span><span class="p">)</span>
    <span class="n">parent</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">parent_shape</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
    <span class="n">vector_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">parent_shape</span><span class="p">)):</span>
      <span class="n">vector_size</span> <span class="o">*=</span> <span class="n">parent_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">parent</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">parent_tensor</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vector_size</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Reshape"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Reshape">[docs]</a><span class="k">class</span> <span class="nc">Reshape</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Reshape</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_new_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="n">s</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">None</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">)</span>
      <span class="k">if</span> <span class="bp">None</span> <span class="ow">in</span> <span class="n">parent_shape</span> <span class="ow">or</span> <span class="bp">None</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">s</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">s</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Calculate what the new shape will be.</span>
        <span class="n">t</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">parent_shape</span><span class="p">:</span>
          <span class="n">t</span> <span class="o">*=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">s</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">//=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">s</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Reshape.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Reshape.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">parent_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Cast"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Cast">[docs]</a><span class="k">class</span> <span class="nc">Cast</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Wrapper around tf.cast.  Changes the dtype of a single layer</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    dtype: tf.DType</span>
<span class="sd">      the dtype to cast the in_layer to</span>
<span class="sd">      e.x. tf.int32</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must cast to a dtype&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Cast</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">parent_shape</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Cast.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Cast.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">parent_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Squeeze"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Squeeze">[docs]</a><span class="k">class</span> <span class="nc">Squeeze</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">squeeze_dims</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">squeeze_dims</span> <span class="o">=</span> <span class="n">squeeze_dims</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Squeeze</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="k">if</span> <span class="n">squeeze_dims</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">parent_shape</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">parent_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parent_shape</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">squeeze_dims</span>
        <span class="p">]</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Squeeze.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Squeeze.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">parent_tensor</span><span class="p">,</span> <span class="n">squeeze_dims</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">squeeze_dims</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Transpose"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Transpose">[docs]</a><span class="k">class</span> <span class="nc">Transpose</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">perm</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Transpose</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">perm</span> <span class="o">=</span> <span class="n">perm</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">parent_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">perm</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Transpose.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Transpose.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only One Parent to Transpose over&quot;</span><span class="p">)</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">perm</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="CombineMeanStd"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.CombineMeanStd">[docs]</a><span class="k">class</span> <span class="nc">CombineMeanStd</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Generate Gaussian nose.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">training_only</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
               <span class="n">noise_epsilon</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a CombineMeanStd layer.</span>

<span class="sd">    This layer should have two inputs with the same shape, and its output also has the</span>
<span class="sd">    same shape.  Each element of the output is a Gaussian distributed random number</span>
<span class="sd">    whose mean is the corresponding element of the first input, and whose standard</span>
<span class="sd">    deviation is the corresponding element of the second input.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    in_layers: list</span>
<span class="sd">      the input layers.  The first one specifies the mean, and the second one specifies</span>
<span class="sd">      the standard deviation.</span>
<span class="sd">    training_only: bool</span>
<span class="sd">      if True, noise is only generated during training.  During prediction, the output</span>
<span class="sd">      is simply equal to the first input (that is, the mean of the distribution used</span>
<span class="sd">      during training).</span>
<span class="sd">    noise_epsilon: float</span>
<span class="sd">      The standard deviation of the random noise</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CombineMeanStd</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">training_only</span> <span class="o">=</span> <span class="n">training_only</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">noise_epsilon</span> <span class="o">=</span> <span class="n">noise_epsilon</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="CombineMeanStd.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.CombineMeanStd.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must have two in_layers&quot;</span><span class="p">)</span>
    <span class="n">mean_parent</span><span class="p">,</span> <span class="n">std_parent</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">sample_noise</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span>
        <span class="n">mean_parent</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_epsilon</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_only</span><span class="p">:</span>
      <span class="n">sample_noise</span> <span class="o">*=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;training&#39;</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">mean_parent</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">std_parent</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="n">sample_noise</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Repeat"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Repeat">[docs]</a><span class="k">class</span> <span class="nc">Repeat</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_times</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_times</span> <span class="o">=</span> <span class="n">n_times</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Repeat</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">s</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="n">s</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_times</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Repeat.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Repeat.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must have one parent&quot;</span><span class="p">)</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">parent_tensor</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pattern</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_times</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">pattern</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Gather"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Gather">[docs]</a><span class="k">class</span> <span class="nc">Gather</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Gather elements or slices from the input.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a Gather layer.</span>

<span class="sd">    The indices can be viewed as a list of element identifiers, where each</span>
<span class="sd">    identifier is itself a length N array specifying the indices of the</span>
<span class="sd">    first N dimensions of the input tensor.  Those elements (or slices, depending</span>
<span class="sd">    on the shape of the input) are then stacked together.  For example,</span>
<span class="sd">    indices=[[0],[2],[4]] will produce [input[0], input[2], input[4]], while</span>
<span class="sd">    indices=[[1,2]] will produce [input[1,2]].</span>

<span class="sd">    The indices may be specified in two ways.  If they are constants, you can pass</span>
<span class="sd">    them to this constructor as a list or array.  Alternatively, the indices can</span>
<span class="sd">    be calculated by another layer.  In that case, pass None for indices, and</span>
<span class="sd">    instead provide them as the second input layer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    in_layers: list</span>
<span class="sd">      the input layers.  If indices is not None, this should be of length 1.  If indices</span>
<span class="sd">      is None, this should be of length 2, with the first entry calculating the tensor</span>
<span class="sd">      from which to take slices, and the second entry calculating the slice indices.</span>
<span class="sd">    indices: array</span>
<span class="sd">      the slice indices (if they are constants) or None (if the indices are provided by</span>
<span class="sd">      an input)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">indices</span> <span class="o">=</span> <span class="n">indices</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Gather</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">s</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">indices</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">s2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">s2</span><span class="p">[</span><span class="mi">0</span><span class="p">],)</span> <span class="o">+</span> <span class="n">s</span><span class="p">[</span><span class="n">s2</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">),)</span> <span class="o">+</span> <span class="n">s</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:]</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Gather.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Gather.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">indices</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must have two parents&quot;</span><span class="p">)</span>
      <span class="n">indices</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must have one parent&quot;</span><span class="p">)</span>
      <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">indices</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">parent_tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="GRU"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GRU">[docs]</a><span class="k">class</span> <span class="nc">GRU</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A Gated Recurrent Unit.</span>

<span class="sd">  This layer expects its input to be of shape (batch_size, sequence_length, ...).</span>
<span class="sd">  It consists of a set of independent sequences (one for each element in the batch),</span>
<span class="sd">  that are each propagated independently through the GRU.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a Gated Recurrent Unit.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_hidden: int</span>
<span class="sd">      the size of the GRU&#39;s hidden state, which also determines the size of its output</span>
<span class="sd">    batch_size: int</span>
<span class="sd">      the batch size that will be used with this layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span> <span class="o">=</span> <span class="n">n_hidden</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">GRU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">parent_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_hidden</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="GRU.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GRU.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must have one parent&quot;</span><span class="p">)</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">gru_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">)</span>
    <span class="n">zero_state</span> <span class="o">=</span> <span class="n">gru_cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="n">initial_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">zero_state</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">initial_state</span> <span class="o">=</span> <span class="n">zero_state</span>
    <span class="n">out_tensor</span><span class="p">,</span> <span class="n">final_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span>
        <span class="n">gru_cell</span><span class="p">,</span> <span class="n">parent_tensor</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="n">initial_state</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_record_variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">rnn_initial_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">initial_state</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">rnn_final_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_state</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">rnn_zero_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">zero_state</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span> <span class="o">=</span> <span class="p">[</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">zero_state</span>
      <span class="p">]</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="GRU.none_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GRU.none_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">none_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">saved_tensors</span> <span class="o">=</span> <span class="p">[</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_initial_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_final_states</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn_zero_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span>
    <span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn_initial_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn_final_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn_zero_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">return</span> <span class="n">saved_tensors</span></div>

<div class="viewcode-block" id="GRU.set_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GRU.set_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">set_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_initial_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_final_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_zero_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span> <span class="o">=</span> <span class="n">tensor</span></div></div>


<div class="viewcode-block" id="LSTM"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.LSTM">[docs]</a><span class="k">class</span> <span class="nc">LSTM</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A Long Short Term Memory.</span>

<span class="sd">  This layer expects its input to be of shape (batch_size, sequence_length, ...).</span>
<span class="sd">  It consists of a set of independent sequences (one for each element in the batch),</span>
<span class="sd">  that are each propagated independently through the LSTM.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a Long Short Term Memory.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_hidden: int</span>
<span class="sd">      the size of the LSTM&#39;s hidden state, which also determines the size of its output</span>
<span class="sd">    batch_size: int</span>
<span class="sd">      the batch size that will be used with this layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span> <span class="o">=</span> <span class="n">n_hidden</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">LSTM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">parent_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_hidden</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="LSTM.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.LSTM.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must have one parent&quot;</span><span class="p">)</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">lstm_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">)</span>
    <span class="n">zero_state</span> <span class="o">=</span> <span class="n">lstm_cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="n">initial_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMStateTuple</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">zero_state</span><span class="o">.</span><span class="n">c</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">zero_state</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">initial_state</span> <span class="o">=</span> <span class="n">zero_state</span>
    <span class="n">out_tensor</span><span class="p">,</span> <span class="n">final_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span>
        <span class="n">lstm_cell</span><span class="p">,</span> <span class="n">parent_tensor</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="n">initial_state</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_record_variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">rnn_initial_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">initial_state</span><span class="o">.</span><span class="n">c</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">rnn_initial_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">initial_state</span><span class="o">.</span><span class="n">h</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">rnn_final_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_state</span><span class="o">.</span><span class="n">c</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">rnn_final_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_state</span><span class="o">.</span><span class="n">h</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">rnn_zero_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">zero_state</span><span class="o">.</span><span class="n">c</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">rnn_zero_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">zero_state</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="LSTM.none_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.LSTM.none_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">none_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">saved_tensors</span> <span class="o">=</span> <span class="p">[</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_initial_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_final_states</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn_zero_states</span>
    <span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn_initial_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn_final_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn_zero_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">return</span> <span class="n">saved_tensors</span></div>

<div class="viewcode-block" id="LSTM.set_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.LSTM.set_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">set_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_initial_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_final_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_zero_states</span> <span class="o">=</span> <span class="n">tensor</span></div></div>


<div class="viewcode-block" id="TimeSeriesDense"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.TimeSeriesDense">[docs]</a><span class="k">class</span> <span class="nc">TimeSeriesDense</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">TimeSeriesDense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="TimeSeriesDense.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.TimeSeriesDense.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must have one parent&quot;</span><span class="p">)</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">dense_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span>
      <span class="n">x</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span>
      <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">)</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">map_fn</span><span class="p">(</span><span class="n">dense_fn</span><span class="p">,</span> <span class="n">parent_tensor</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Input"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Input">[docs]</a><span class="k">class</span> <span class="nc">Input</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Input</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">op_type</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>

<div class="viewcode-block" id="Input.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Input.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">in_layers</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">in_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span>
    <span class="n">in_layers</span> <span class="o">=</span> <span class="n">convert_to_layers</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">queue</span> <span class="o">=</span> <span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">placeholder</span> <span class="o">=</span> <span class="n">queue</span><span class="o">.</span><span class="n">out_tensors</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">get_pre_q_name</span><span class="p">()]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder_with_default</span><span class="p">(</span><span class="n">placeholder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="Input.create_pre_q"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Input.create_pre_q">[docs]</a>  <span class="k">def</span> <span class="nf">create_pre_q</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">q_shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">None</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="k">return</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">q_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">_pre_q&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span></div>

<div class="viewcode-block" id="Input.get_pre_q_name"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Input.get_pre_q_name">[docs]</a>  <span class="k">def</span> <span class="nf">get_pre_q_name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">_pre_q&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span></div></div>


<div class="viewcode-block" id="Feature"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Feature">[docs]</a><span class="k">class</span> <span class="nc">Feature</span><span class="p">(</span><span class="n">Input</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Feature</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="Label"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Label">[docs]</a><span class="k">class</span> <span class="nc">Label</span><span class="p">(</span><span class="n">Input</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Label</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="Weights"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Weights">[docs]</a><span class="k">class</span> <span class="nc">Weights</span><span class="p">(</span><span class="n">Input</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Weights</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="L1Loss"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.L1Loss">[docs]</a><span class="k">class</span> <span class="nc">L1Loss</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Compute the mean absolute difference between the elements of the inputs.</span>

<span class="sd">  This layer should have two or three inputs.  If there is a third input, the</span>
<span class="sd">  difference between the first two inputs is multiplied by the third one to</span>
<span class="sd">  produce a weighted error.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">L1Loss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="L1Loss.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.L1Loss.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
    <span class="n">guess</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">l1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">guess</span> <span class="o">-</span> <span class="n">label</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
      <span class="n">l1</span> <span class="o">*=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">l1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">label</span><span class="o">.</span><span class="n">shape</span><span class="p">))))</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="L2Loss"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.L2Loss">[docs]</a><span class="k">class</span> <span class="nc">L2Loss</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Compute the mean squared difference between the elements of the inputs.</span>

<span class="sd">  This layer should have two or three inputs.  If there is a third input, the</span>
<span class="sd">  squared difference between the first two inputs is multiplied by the third one to</span>
<span class="sd">  produce a weighted error.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">L2Loss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">shape1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="n">shape2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="k">if</span> <span class="n">shape1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape2</span><span class="p">[</span><span class="mi">0</span><span class="p">],)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">shape1</span><span class="p">[</span><span class="mi">0</span><span class="p">],)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="L2Loss.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.L2Loss.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
    <span class="n">guess</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">l2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">guess</span> <span class="o">-</span> <span class="n">label</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
      <span class="n">l2</span> <span class="o">*=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">l2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">label</span><span class="o">.</span><span class="n">_shape</span><span class="p">))))</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="SoftMax"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.SoftMax">[docs]</a><span class="k">class</span> <span class="nc">SoftMax</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">SoftMax</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="SoftMax.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.SoftMax.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Softmax must have a single input layer.&quot;</span><span class="p">)</span>
    <span class="n">parent</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">parent</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Sigmoid"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Sigmoid">[docs]</a><span class="k">class</span> <span class="nc">Sigmoid</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Compute the sigmoid of input: f(x) = sigmoid(x)</span>
<span class="sd">  Only one input is allowed, output will have the same shape as input</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Sigmoid</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Sigmoid.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Sigmoid.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Sigmoid must have a single input layer.&quot;</span><span class="p">)</span>
    <span class="n">parent</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">parent</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="ReLU"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ReLU">[docs]</a><span class="k">class</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Compute the relu activation of input: f(x) = relu(x)</span>
<span class="sd">  Only one input is allowed, output will have the same shape as input</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ReLU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="ReLU.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ReLU.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;ReLU must have a single input layer.&quot;</span><span class="p">)</span>
    <span class="n">parent</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">parent</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Concat"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Concat">[docs]</a><span class="k">class</span> <span class="nc">Concat</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Concat</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">s</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">parent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
        <span class="k">if</span> <span class="n">s</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">parent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
          <span class="n">s</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">s</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">+=</span> <span class="n">parent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Concat.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Concat.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span>

    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Stack"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Stack">[docs]</a><span class="k">class</span> <span class="nc">Stack</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Stack</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">s</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="n">s</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Stack.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Stack.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Constant"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Constant">[docs]</a><span class="k">class</span> <span class="nc">Constant</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Output a constant value.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Construct a constant layer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    value: array</span>
<span class="sd">      the value the layer should output</span>
<span class="sd">    dtype: tf.DType</span>
<span class="sd">      the data type of the output value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
      <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">value</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Constant</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="Constant.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Constant.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Variable"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Variable">[docs]</a><span class="k">class</span> <span class="nc">Variable</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Output a trainable value.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Construct a variable layer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    initial_value: array</span>
<span class="sd">      the initial value the layer should output</span>
<span class="sd">    dtype: tf.DType</span>
<span class="sd">      the data type of the output value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">initial_value</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
      <span class="n">initial_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">initial_value</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">initial_value</span> <span class="o">=</span> <span class="n">initial_value</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">initial_value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Variable</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="Variable.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Variable.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_record_variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="StopGradient"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.StopGradient">[docs]</a><span class="k">class</span> <span class="nc">StopGradient</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Block the flow of gradients.</span>

<span class="sd">  This layer copies its input directly to its output, but reports that all</span>
<span class="sd">  gradients of its output are zero.  This means, for example, that optimizers</span>
<span class="sd">  will not try to optimize anything &quot;upstream&quot; of this layer.</span>

<span class="sd">  For example, suppose you have pre-trained a stack of layers to perform a</span>
<span class="sd">  calculation.  You want to use the result of that calculation as the input to</span>
<span class="sd">  another layer, but because they are already pre-trained, you do not want the</span>
<span class="sd">  optimizer to modify them.  You can wrap the output in a StopGradient layer,</span>
<span class="sd">  then use that as the input to the next layer.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">StopGradient</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="StopGradient.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.StopGradient.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only one layer supported.&quot;</span><span class="p">)</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<span class="k">def</span> <span class="nf">_max_dimension</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">y</span>
  <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">x</span>
  <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>


<div class="viewcode-block" id="Add"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Add">[docs]</a><span class="k">class</span> <span class="nc">Add</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Compute the (optionally weighted) sum of the input layers.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create an Add layer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    weights: array</span>
<span class="sd">      an array of length equal to the number of input layers, giving the weight</span>
<span class="sd">      to multiply each input by.  If None, all weights are set to 1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Add</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">shape1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="n">shape2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape2</span><span class="p">):</span>
        <span class="n">shape2</span><span class="p">,</span> <span class="n">shape1</span> <span class="o">=</span> <span class="n">shape1</span><span class="p">,</span> <span class="n">shape2</span>
      <span class="n">offset</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape1</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape2</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shape2</span><span class="p">)):</span>
        <span class="n">shape1</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">offset</span><span class="p">]</span> <span class="o">=</span> <span class="n">_max_dimension</span><span class="p">(</span><span class="n">shape1</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">offset</span><span class="p">],</span> <span class="n">shape2</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape1</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Add.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Add.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">out_tensor</span> <span class="o">*=</span> <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">layer</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
      <span class="k">if</span> <span class="n">weight</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">out_tensor</span> <span class="o">+=</span> <span class="n">layer</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">out_tensor</span> <span class="o">+=</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">layer</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Multiply"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Multiply">[docs]</a><span class="k">class</span> <span class="nc">Multiply</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Compute the product of the input layers.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Multiply</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">shape1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="n">shape2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape2</span><span class="p">):</span>
        <span class="n">shape2</span><span class="p">,</span> <span class="n">shape1</span> <span class="o">=</span> <span class="n">shape1</span><span class="p">,</span> <span class="n">shape2</span>
      <span class="n">offset</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape1</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape2</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shape2</span><span class="p">)):</span>
        <span class="n">shape1</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">offset</span><span class="p">]</span> <span class="o">=</span> <span class="n">_max_dimension</span><span class="p">(</span><span class="n">shape1</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">offset</span><span class="p">],</span> <span class="n">shape2</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape1</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Multiply.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Multiply.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
      <span class="n">out_tensor</span> <span class="o">*=</span> <span class="n">layer</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Divide"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Divide">[docs]</a><span class="k">class</span> <span class="nc">Divide</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Compute the ratio of the input layers.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Divide</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">shape1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="n">shape2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape2</span><span class="p">):</span>
        <span class="n">shape2</span><span class="p">,</span> <span class="n">shape1</span> <span class="o">=</span> <span class="n">shape1</span><span class="p">,</span> <span class="n">shape2</span>
      <span class="n">offset</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape1</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape2</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shape2</span><span class="p">)):</span>
        <span class="n">shape1</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">offset</span><span class="p">]</span> <span class="o">=</span> <span class="n">_max_dimension</span><span class="p">(</span><span class="n">shape1</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">offset</span><span class="p">],</span> <span class="n">shape2</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape1</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Divide.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Divide.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Log"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Log">[docs]</a><span class="k">class</span> <span class="nc">Log</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Compute the natural log of the input.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Log</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Log.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Log.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Log must have a single parent&#39;</span><span class="p">)</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Exp"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Exp">[docs]</a><span class="k">class</span> <span class="nc">Exp</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Compute the exponential of the input.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Exp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Exp.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Exp.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Exp must have a single parent&#39;</span><span class="p">)</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="InteratomicL2Distances"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.InteratomicL2Distances">[docs]</a><span class="k">class</span> <span class="nc">InteratomicL2Distances</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Compute (squared) L2 Distances between atoms given neighbors.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N_atoms</span><span class="p">,</span> <span class="n">M_nbrs</span><span class="p">,</span> <span class="n">ndim</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">N_atoms</span> <span class="o">=</span> <span class="n">N_atoms</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">M_nbrs</span> <span class="o">=</span> <span class="n">M_nbrs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="n">ndim</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">InteratomicL2Distances</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="InteratomicL2Distances.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.InteratomicL2Distances.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;InteratomicDistances requires coords,nbr_list&quot;</span><span class="p">)</span>
    <span class="n">coords</span><span class="p">,</span> <span class="n">nbr_list</span> <span class="o">=</span> <span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">N_atoms</span><span class="p">,</span> <span class="n">M_nbrs</span><span class="p">,</span> <span class="n">ndim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_atoms</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">M_nbrs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span>
    <span class="c1"># Shape (N_atoms, M_nbrs, ndim)</span>
    <span class="n">nbr_coords</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">coords</span><span class="p">,</span> <span class="n">nbr_list</span><span class="p">)</span>
    <span class="c1"># Shape (N_atoms, M_nbrs, ndim)</span>
    <span class="n">tiled_coords</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">coords</span><span class="p">,</span> <span class="p">(</span><span class="n">N_atoms</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ndim</span><span class="p">)),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">M_nbrs</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># Shape (N_atoms, M_nbrs)</span>
    <span class="n">dists</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">((</span><span class="n">tiled_coords</span> <span class="o">-</span> <span class="n">nbr_coords</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">dists</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="SparseSoftMaxCrossEntropy"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.SparseSoftMaxCrossEntropy">[docs]</a><span class="k">class</span> <span class="nc">SparseSoftMaxCrossEntropy</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">SparseSoftMaxCrossEntropy</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="SparseSoftMaxCrossEntropy.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.SparseSoftMaxCrossEntropy.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>
    <span class="n">labels</span><span class="p">,</span> <span class="n">logits</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sparse_softmax_cross_entropy_with_logits</span><span class="p">(</span>
        <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="SoftMaxCrossEntropy"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.SoftMaxCrossEntropy">[docs]</a><span class="k">class</span> <span class="nc">SoftMaxCrossEntropy</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">SoftMaxCrossEntropy</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="SoftMaxCrossEntropy.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.SoftMaxCrossEntropy.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>
    <span class="n">labels</span><span class="p">,</span> <span class="n">logits</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits_v2</span><span class="p">(</span>
        <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="SigmoidCrossEntropy"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.SigmoidCrossEntropy">[docs]</a><span class="k">class</span> <span class="nc">SigmoidCrossEntropy</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Compute the sigmoid cross entropy of inputs: [labels, logits]</span>
<span class="sd">  `labels` hold the binary labels(with no axis of n_classes),</span>
<span class="sd">  `logits` hold the log probabilities for positive class(label=1),</span>
<span class="sd">  `labels` and `logits` should have same shape and type.</span>
<span class="sd">  Output will have the same shape as `logits`</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">SigmoidCrossEntropy</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="SigmoidCrossEntropy.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.SigmoidCrossEntropy.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>
    <span class="n">labels</span><span class="p">,</span> <span class="n">logits</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span>
        <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="ReduceMean"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ReduceMean">[docs]</a><span class="k">class</span> <span class="nc">ReduceMean</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
      <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ReduceMean</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">parent_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parent_shape</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">axis</span>
        <span class="p">]</span>
      <span class="k">except</span><span class="p">:</span>
        <span class="k">pass</span>

<div class="viewcode-block" id="ReduceMean.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ReduceMean.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="ReduceMax"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ReduceMax">[docs]</a><span class="k">class</span> <span class="nc">ReduceMax</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
      <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ReduceMax</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">parent_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parent_shape</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">axis</span>
        <span class="p">]</span>
      <span class="k">except</span><span class="p">:</span>
        <span class="k">pass</span>

<div class="viewcode-block" id="ReduceMax.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ReduceMax.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="ToFloat"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ToFloat">[docs]</a><span class="k">class</span> <span class="nc">ToFloat</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ToFloat</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="ToFloat.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ToFloat.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only one layer supported.&quot;</span><span class="p">)</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="ReduceSum"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ReduceSum">[docs]</a><span class="k">class</span> <span class="nc">ReduceSum</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
      <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ReduceSum</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">parent_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parent_shape</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">axis</span>
        <span class="p">]</span>
      <span class="k">except</span><span class="p">:</span>
        <span class="k">pass</span>

<div class="viewcode-block" id="ReduceSum.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ReduceSum.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="ReduceSquareDifference"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ReduceSquareDifference">[docs]</a><span class="k">class</span> <span class="nc">ReduceSquareDifference</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
      <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ReduceSquareDifference</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">parent_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">parent_shape</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">axis</span>
        <span class="p">]</span>
      <span class="k">except</span><span class="p">:</span>
        <span class="k">pass</span>

<div class="viewcode-block" id="ReduceSquareDifference.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ReduceSquareDifference.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squared_difference</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Conv2D"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Conv2D">[docs]</a><span class="k">class</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="n">SharedVariableScope</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A 2D convolution on the input.</span>

<span class="sd">  This layer expects its input to be a four dimensional tensor of shape (batch size, height, width, # channels).</span>
<span class="sd">  If there is only one channel, the fourth dimension may optionally be omitted.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">num_outputs</span><span class="p">,</span>
               <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span>
               <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
               <span class="n">normalizer_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">biases_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">,</span>
               <span class="n">weights_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">,</span>
               <span class="n">scope_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a Conv2D layer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    num_outputs: int</span>
<span class="sd">      the number of outputs produced by the convolutional kernel</span>
<span class="sd">    kernel_size: int or tuple</span>
<span class="sd">      the width of the convolutional kernel.  This can be either a two element tuple, giving</span>
<span class="sd">      the kernel size along each dimension, or an integer to use the same size along both</span>
<span class="sd">      dimensions.</span>
<span class="sd">    stride: int or tuple</span>
<span class="sd">      the stride between applications of the convolutional kernel.  This can be either a two</span>
<span class="sd">      element tuple, giving the stride along each dimension, or an integer to use the same</span>
<span class="sd">      stride along both dimensions.</span>
<span class="sd">    padding: str</span>
<span class="sd">      the padding method to use, either &#39;SAME&#39; or &#39;VALID&#39;</span>
<span class="sd">    activation_fn: object</span>
<span class="sd">      the Tensorflow activation function to apply to the output</span>
<span class="sd">    normalizer_fn: object</span>
<span class="sd">      the Tensorflow normalizer function to apply to the output</span>
<span class="sd">    biases_initializer: callable object</span>
<span class="sd">      the initializer for bias values.  This may be None, in which case the layer</span>
<span class="sd">      will not include biases.</span>
<span class="sd">    weights_initializer: callable object</span>
<span class="sd">      the initializer for weight values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">=</span> <span class="n">num_outputs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">activation_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">normalizer_fn</span> <span class="o">=</span> <span class="n">normalizer_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights_initializer</span> <span class="o">=</span> <span class="n">weights_initializer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">biases_initializer</span> <span class="o">=</span> <span class="n">biases_initializer</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">scope_name</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">scope_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scope_name</span> <span class="o">=</span> <span class="n">scope_name</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="n">strides</span> <span class="o">=</span> <span class="n">stride</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">parent_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">parent_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="n">strides</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                     <span class="n">parent_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">//</span> <span class="n">strides</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_outputs</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Conv2D.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Conv2D.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parent_tensor</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
      <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">parent_tensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">reuse</span> <span class="ow">in</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_reuse</span><span class="p">,</span> <span class="bp">False</span><span class="p">):</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span>
            <span class="n">parent_tensor</span><span class="p">,</span>
            <span class="n">num_outputs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
            <span class="n">activation_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span><span class="p">,</span>
            <span class="n">normalizer_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">normalizer_fn</span><span class="p">,</span>
            <span class="n">biases_initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">biases_initializer</span><span class="p">(),</span>
            <span class="n">weights_initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_initializer</span><span class="p">(),</span>
            <span class="n">scope</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_scope_name</span><span class="p">(),</span>
            <span class="n">reuse</span><span class="o">=</span><span class="n">reuse</span><span class="p">)</span>
        <span class="k">break</span>
      <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">reuse</span><span class="p">:</span>
          <span class="c1"># This probably means the variable hasn&#39;t been created yet, so try again</span>
          <span class="c1"># with reuse set to false.</span>
          <span class="k">continue</span>
        <span class="k">raise</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_record_variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scope_name</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Conv3D"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Conv3D">[docs]</a><span class="k">class</span> <span class="nc">Conv3D</span><span class="p">(</span><span class="n">SharedVariableScope</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A 3D convolution on the input.</span>

<span class="sd">  This layer expects its input to be a five dimensional tensor of shape</span>
<span class="sd">  (batch size, height, width, depth, # channels).</span>
<span class="sd">  If there is only one channel, the fifth dimension may optionally be omitted.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">num_outputs</span><span class="p">,</span>
               <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span>
               <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
               <span class="n">normalizer_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">biases_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">,</span>
               <span class="n">weights_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">,</span>
               <span class="n">scope_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a Conv3D layer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    num_outputs: int</span>
<span class="sd">      the number of outputs produced by the convolutional kernel</span>
<span class="sd">    kernel_size: int or tuple</span>
<span class="sd">      the width of the convolutional kernel.  This can be either a three element tuple, giving</span>
<span class="sd">      the kernel size along each dimension, or an integer to use the same size along both</span>
<span class="sd">      dimensions.</span>
<span class="sd">    stride: int or tuple</span>
<span class="sd">      the stride between applications of the convolutional kernel.  This can be either a three</span>
<span class="sd">      element tuple, giving the stride along each dimension, or an integer to use the same</span>
<span class="sd">      stride along both dimensions.</span>
<span class="sd">    padding: str</span>
<span class="sd">      the padding method to use, either &#39;SAME&#39; or &#39;VALID&#39;</span>
<span class="sd">    activation_fn: object</span>
<span class="sd">      the Tensorflow activation function to apply to the output</span>
<span class="sd">    normalizer_fn: object</span>
<span class="sd">      the Tensorflow normalizer function to apply to the output</span>
<span class="sd">    biases_initializer: callable object</span>
<span class="sd">      the initializer for bias values.  This may be None, in which case the layer</span>
<span class="sd">      will not include biases.</span>
<span class="sd">    weights_initializer: callable object</span>
<span class="sd">      the initializer for weight values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">=</span> <span class="n">num_outputs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">activation_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">normalizer_fn</span> <span class="o">=</span> <span class="n">normalizer_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights_initializer</span> <span class="o">=</span> <span class="n">weights_initializer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">biases_initializer</span> <span class="o">=</span> <span class="n">biases_initializer</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Conv3D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">scope_name</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">scope_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scope_name</span> <span class="o">=</span> <span class="n">scope_name</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="n">strides</span> <span class="o">=</span> <span class="n">stride</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">parent_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">parent_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="n">strides</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                     <span class="n">parent_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">//</span> <span class="n">strides</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                     <span class="n">parent_shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">//</span> <span class="n">strides</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">num_outputs</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Conv3D.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Conv3D.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parent_tensor</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
      <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">parent_tensor</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">reuse</span> <span class="ow">in</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_reuse</span><span class="p">,</span> <span class="bp">False</span><span class="p">):</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv3d</span><span class="p">(</span>
            <span class="n">parent_tensor</span><span class="p">,</span>
            <span class="n">filters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span><span class="p">,</span>
            <span class="n">activity_regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">normalizer_fn</span><span class="p">,</span>
            <span class="n">bias_initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">biases_initializer</span><span class="p">(),</span>
            <span class="n">kernel_initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_initializer</span><span class="p">(),</span>
            <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_scope_name</span><span class="p">(),</span>
            <span class="n">reuse</span><span class="o">=</span><span class="n">reuse</span><span class="p">)</span>
        <span class="k">break</span>
      <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">reuse</span><span class="p">:</span>
          <span class="c1"># This probably means the variable hasn&#39;t been created yet, so try again</span>
          <span class="c1"># with reuse set to false.</span>
          <span class="k">continue</span>
        <span class="k">raise</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_record_variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scope_name</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Conv2DTranspose"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Conv2DTranspose">[docs]</a><span class="k">class</span> <span class="nc">Conv2DTranspose</span><span class="p">(</span><span class="n">SharedVariableScope</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A transposed 2D convolution on the input.</span>

<span class="sd">  This layer is typically used for upsampling in a deconvolutional network.  It</span>
<span class="sd">  expects its input to be a four dimensional tensor of shape (batch size, height, width, # channels).</span>
<span class="sd">  If there is only one channel, the fourth dimension may optionally be omitted.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">num_outputs</span><span class="p">,</span>
               <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span>
               <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
               <span class="n">normalizer_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">biases_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">,</span>
               <span class="n">weights_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">,</span>
               <span class="n">scope_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a Conv2DTranspose layer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    num_outputs: int</span>
<span class="sd">      the number of outputs produced by the convolutional kernel</span>
<span class="sd">    kernel_size: int or tuple</span>
<span class="sd">      the width of the convolutional kernel.  This can be either a two element tuple, giving</span>
<span class="sd">      the kernel size along each dimension, or an integer to use the same size along both</span>
<span class="sd">      dimensions.</span>
<span class="sd">    stride: int or tuple</span>
<span class="sd">      the stride between applications of the convolutional kernel.  This can be either a two</span>
<span class="sd">      element tuple, giving the stride along each dimension, or an integer to use the same</span>
<span class="sd">      stride along both dimensions.</span>
<span class="sd">    padding: str</span>
<span class="sd">      the padding method to use, either &#39;SAME&#39; or &#39;VALID&#39;</span>
<span class="sd">    activation_fn: object</span>
<span class="sd">      the Tensorflow activation function to apply to the output</span>
<span class="sd">    normalizer_fn: object</span>
<span class="sd">      the Tensorflow normalizer function to apply to the output</span>
<span class="sd">    biases_initializer: callable object</span>
<span class="sd">      the initializer for bias values.  This may be None, in which case the layer</span>
<span class="sd">      will not include biases.</span>
<span class="sd">    weights_initializer: callable object</span>
<span class="sd">      the initializer for weight values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">=</span> <span class="n">num_outputs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">activation_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">normalizer_fn</span> <span class="o">=</span> <span class="n">normalizer_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights_initializer</span> <span class="o">=</span> <span class="n">weights_initializer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">biases_initializer</span> <span class="o">=</span> <span class="n">biases_initializer</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Conv2DTranspose</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">scope_name</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">scope_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scope_name</span> <span class="o">=</span> <span class="n">scope_name</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="n">strides</span> <span class="o">=</span> <span class="n">stride</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">parent_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">parent_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">strides</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                     <span class="n">parent_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">strides</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_outputs</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Conv2DTranspose.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Conv2DTranspose.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parent_tensor</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
      <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">parent_tensor</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">reuse</span> <span class="ow">in</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_reuse</span><span class="p">,</span> <span class="bp">False</span><span class="p">):</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d_transpose</span><span class="p">(</span>
            <span class="n">parent_tensor</span><span class="p">,</span>
            <span class="n">num_outputs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
            <span class="n">activation_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span><span class="p">,</span>
            <span class="n">normalizer_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">normalizer_fn</span><span class="p">,</span>
            <span class="n">biases_initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">biases_initializer</span><span class="p">(),</span>
            <span class="n">weights_initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_initializer</span><span class="p">(),</span>
            <span class="n">scope</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_scope_name</span><span class="p">(),</span>
            <span class="n">reuse</span><span class="o">=</span><span class="n">reuse</span><span class="p">)</span>
        <span class="k">break</span>
      <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">reuse</span><span class="p">:</span>
          <span class="c1"># This probably means the variable hasn&#39;t been created yet, so try again</span>
          <span class="c1"># with reuse set to false.</span>
          <span class="k">continue</span>
        <span class="k">raise</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_record_variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scope_name</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="Conv3DTranspose"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Conv3DTranspose">[docs]</a><span class="k">class</span> <span class="nc">Conv3DTranspose</span><span class="p">(</span><span class="n">SharedVariableScope</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A transposed 3D convolution on the input.</span>

<span class="sd">  This layer is typically used for upsampling in a deconvolutional network.  It</span>
<span class="sd">  expects its input to be a five dimensional tensor of shape (batch size, height, width, depth, # channels).</span>
<span class="sd">  If there is only one channel, the fifth dimension may optionally be omitted.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">num_outputs</span><span class="p">,</span>
               <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span>
               <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
               <span class="n">normalizer_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">biases_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">,</span>
               <span class="n">weights_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">,</span>
               <span class="n">scope_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a Conv3DTranspose layer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    num_outputs: int</span>
<span class="sd">      the number of outputs produced by the convolutional kernel</span>
<span class="sd">    kernel_size: int or tuple</span>
<span class="sd">      the width of the convolutional kernel.  This can be either a three element tuple, giving</span>
<span class="sd">      the kernel size along each dimension, or an integer to use the same size along both</span>
<span class="sd">      dimensions.</span>
<span class="sd">    stride: int or tuple</span>
<span class="sd">      the stride between applications of the convolutional kernel.  This can be either a three</span>
<span class="sd">      element tuple, giving the stride along each dimension, or an integer to use the same</span>
<span class="sd">      stride along both dimensions.</span>
<span class="sd">    padding: str</span>
<span class="sd">      the padding method to use, either &#39;SAME&#39; or &#39;VALID&#39;</span>
<span class="sd">    activation_fn: object</span>
<span class="sd">      the Tensorflow activation function to apply to the output</span>
<span class="sd">    normalizer_fn: object</span>
<span class="sd">      the Tensorflow normalizer function to apply to the output</span>
<span class="sd">    biases_initializer: callable object</span>
<span class="sd">      the initializer for bias values.  This may be None, in which case the layer</span>
<span class="sd">      will not include biases.</span>
<span class="sd">    weights_initializer: callable object</span>
<span class="sd">      the initializer for weight values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">=</span> <span class="n">num_outputs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">activation_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">normalizer_fn</span> <span class="o">=</span> <span class="n">normalizer_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights_initializer</span> <span class="o">=</span> <span class="n">weights_initializer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">biases_initializer</span> <span class="o">=</span> <span class="n">biases_initializer</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Conv3DTranspose</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">scope_name</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">scope_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scope_name</span> <span class="o">=</span> <span class="n">scope_name</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="n">strides</span> <span class="o">=</span> <span class="n">stride</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">parent_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">parent_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">strides</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                     <span class="n">parent_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">strides</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">parent_shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="n">strides</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                     <span class="n">num_outputs</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Conv3DTranspose.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Conv3DTranspose.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parent_tensor</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
      <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">parent_tensor</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">reuse</span> <span class="ow">in</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_reuse</span><span class="p">,</span> <span class="bp">False</span><span class="p">):</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv3d_transpose</span><span class="p">(</span>
            <span class="n">parent_tensor</span><span class="p">,</span>
            <span class="n">filters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span><span class="p">,</span>
            <span class="n">activity_regularizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">normalizer_fn</span><span class="p">,</span>
            <span class="n">bias_initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">biases_initializer</span><span class="p">(),</span>
            <span class="n">kernel_initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_initializer</span><span class="p">(),</span>
            <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_scope_name</span><span class="p">(),</span>
            <span class="n">reuse</span><span class="o">=</span><span class="n">reuse</span><span class="p">)</span>
        <span class="k">break</span>
      <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">reuse</span><span class="p">:</span>
          <span class="c1"># This probably means the variable hasn&#39;t been created yet, so try again</span>
          <span class="c1"># with reuse set to false.</span>
          <span class="k">continue</span>
        <span class="k">raise</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_record_variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scope_name</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="MaxPool1D"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.MaxPool1D">[docs]</a><span class="k">class</span> <span class="nc">MaxPool1D</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A 1D max pooling on the input.</span>

<span class="sd">  This layer expects its input to be a three dimensional tensor of shape</span>
<span class="sd">  (batch size, width, # channels).</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">window_shape</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;SAME&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a MaxPool1D layer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    window_shape: int, optional</span>
<span class="sd">      size of the window(assuming input with only one dimension)</span>
<span class="sd">    strides: int, optional</span>
<span class="sd">      stride of the sliding window</span>
<span class="sd">    padding: str</span>
<span class="sd">      the padding method to use, either &#39;SAME&#39; or &#39;VALID&#39;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">window_shape</span> <span class="o">=</span> <span class="n">window_shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">strides</span> <span class="o">=</span> <span class="n">strides</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pooling_type</span> <span class="o">=</span> <span class="s2">&quot;MAX&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MaxPool1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
          <span class="bp">None</span> <span class="k">if</span> <span class="n">p</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">p</span> <span class="o">//</span> <span class="n">s</span> <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">parent_shape</span><span class="p">,</span> <span class="n">strides</span><span class="p">))</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="MaxPool1D.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.MaxPool1D.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">in_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span>
        <span class="n">in_tensor</span><span class="p">,</span>
        <span class="n">window_shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">window_shape</span><span class="p">],</span>
        <span class="n">pooling_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pooling_type</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
        <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">strides</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="MaxPool2D"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.MaxPool2D">[docs]</a><span class="k">class</span> <span class="nc">MaxPool2D</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">ksize</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
               <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
               <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;SAME&quot;</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ksize</span> <span class="o">=</span> <span class="n">ksize</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">strides</span> <span class="o">=</span> <span class="n">strides</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MaxPool2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
          <span class="bp">None</span> <span class="k">if</span> <span class="n">p</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">p</span> <span class="o">//</span> <span class="n">s</span> <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">parent_shape</span><span class="p">,</span> <span class="n">strides</span><span class="p">))</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="MaxPool2D.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.MaxPool2D.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">in_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span>
        <span class="n">in_tensor</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ksize</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="MaxPool3D"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.MaxPool3D">[docs]</a><span class="k">class</span> <span class="nc">MaxPool3D</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A 3D max pooling on the input.</span>

<span class="sd">  This layer expects its input to be a five dimensional tensor of shape</span>
<span class="sd">  (batch size, height, width, depth, # channels).</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">ksize</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
               <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
               <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a MaxPool3D layer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    ksize: list</span>
<span class="sd">      size of the window for each dimension of the input tensor. Must have</span>
<span class="sd">      length of 5 and ksize[0] = ksize[4] = 1.</span>
<span class="sd">    strides: list</span>
<span class="sd">      stride of the sliding window for each dimension of input. Must have</span>
<span class="sd">      length of 5 and strides[0] = strides[4] = 1.</span>
<span class="sd">    padding: str</span>
<span class="sd">      the padding method to use, either &#39;SAME&#39; or &#39;VALID&#39;</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">ksize</span> <span class="o">=</span> <span class="n">ksize</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">strides</span> <span class="o">=</span> <span class="n">strides</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MaxPool3D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
          <span class="bp">None</span> <span class="k">if</span> <span class="n">p</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">p</span> <span class="o">//</span> <span class="n">s</span> <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">parent_shape</span><span class="p">,</span> <span class="n">strides</span><span class="p">))</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="MaxPool3D.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.MaxPool3D.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">in_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool3d</span><span class="p">(</span>
        <span class="n">in_tensor</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ksize</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="InputFifoQueue"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.InputFifoQueue">[docs]</a><span class="k">class</span> <span class="nc">InputFifoQueue</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  This Queue Is used to allow asynchronous batching of inputs</span>
<span class="sd">  During the fitting process</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shapes</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">capacity</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">shapes</span> <span class="o">=</span> <span class="n">shapes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">names</span> <span class="o">=</span> <span class="n">names</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="o">=</span> <span class="n">capacity</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">InputFifoQueue</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="InputFifoQueue.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.InputFifoQueue.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="c1"># TODO(rbharath): Note sure if this layer can be called with __call__</span>
    <span class="c1"># meaningfully, so not going to support that functionality for now.</span>
    <span class="k">if</span> <span class="n">in_layers</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">in_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span>
    <span class="n">in_layers</span> <span class="o">=</span> <span class="n">convert_to_layers</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">out_tensor</span><span class="o">.</span><span class="n">dtype</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">in_layers</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">queue</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">FIFOQueue</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">capacity</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
    <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">out_tensor</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">in_layers</span><span class="p">}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">feed_dict</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">close_op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">dequeue</span><span class="p">()</span></div>

<div class="viewcode-block" id="InputFifoQueue.none_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.InputFifoQueue.none_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">none_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">queue</span><span class="p">,</span> <span class="n">out_tensors</span><span class="p">,</span> <span class="n">out_tensor</span><span class="p">,</span> <span class="n">close_op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">close_op</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">close_op</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
    <span class="k">return</span> <span class="n">queue</span><span class="p">,</span> <span class="n">out_tensors</span><span class="p">,</span> <span class="n">out_tensor</span><span class="p">,</span> <span class="n">close_op</span></div>

<div class="viewcode-block" id="InputFifoQueue.set_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.InputFifoQueue.set_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">set_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensors</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">close_op</span> <span class="o">=</span> <span class="n">tensors</span></div></div>


<div class="viewcode-block" id="GraphConv"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphConv">[docs]</a><span class="k">class</span> <span class="nc">GraphConv</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">out_channel</span><span class="p">,</span>
               <span class="n">min_deg</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">max_deg</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
               <span class="n">activation_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_channel</span> <span class="o">=</span> <span class="n">out_channel</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_degree</span> <span class="o">=</span> <span class="n">min_deg</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_degree</span> <span class="o">=</span> <span class="n">max_deg</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_deg</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">max_deg</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">min_deg</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">activation_fn</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">GraphConv</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="GraphConv.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphConv.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="c1"># in_layers = [atom_features, deg_slice, membership, deg_adj_list placeholders...]</span>
    <span class="n">in_channels</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>

    <span class="c1"># Generate the nb_affine weights and biases</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W_list</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">initializations</span><span class="o">.</span><span class="n">glorot_uniform</span><span class="p">([</span><span class="n">in_channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_channel</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_deg</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">b_list</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">model_ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_channel</span><span class="p">,</span>
        <span class="p">])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_deg</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="c1"># Extract atom_features</span>
    <span class="n">atom_features</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Extract graph topology</span>
    <span class="n">deg_slice</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">deg_adj_lists</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">3</span><span class="p">:]</span>

    <span class="c1"># Perform the mol conv</span>
    <span class="c1"># atom_features = graph_conv(atom_features, deg_adj_lists, deg_slice,</span>
    <span class="c1">#                            self.max_deg, self.min_deg, self.W_list,</span>
    <span class="c1">#                            self.b_list)</span>

    <span class="n">W</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_list</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b_list</span><span class="p">)</span>

    <span class="c1"># Sum all neighbors using adjacency matrix</span>
    <span class="n">deg_summed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sum_neigh</span><span class="p">(</span><span class="n">atom_features</span><span class="p">,</span> <span class="n">deg_adj_lists</span><span class="p">)</span>

    <span class="c1"># Get collection of modified atom features</span>
    <span class="n">new_rel_atoms_collection</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_degree</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_degree</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">deg</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
      <span class="c1"># Obtain relevant atoms for this degree</span>
      <span class="n">rel_atoms</span> <span class="o">=</span> <span class="n">deg_summed</span><span class="p">[</span><span class="n">deg</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>

      <span class="c1"># Get self atoms</span>
      <span class="n">begin</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">deg_slice</span><span class="p">[</span><span class="n">deg</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_degree</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">])</span>
      <span class="n">size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">deg_slice</span><span class="p">[</span><span class="n">deg</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_degree</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
      <span class="n">self_atoms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">atom_features</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>

      <span class="c1"># Apply hidden affine to relevant atoms and append</span>
      <span class="n">rel_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">rel_atoms</span><span class="p">,</span> <span class="nb">next</span><span class="p">(</span><span class="n">W</span><span class="p">))</span> <span class="o">+</span> <span class="nb">next</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
      <span class="n">self_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">self_atoms</span><span class="p">,</span> <span class="nb">next</span><span class="p">(</span><span class="n">W</span><span class="p">))</span> <span class="o">+</span> <span class="nb">next</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
      <span class="n">out</span> <span class="o">=</span> <span class="n">rel_out</span> <span class="o">+</span> <span class="n">self_out</span>

      <span class="n">new_rel_atoms_collection</span><span class="p">[</span><span class="n">deg</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_degree</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span>

    <span class="c1"># Determine the min_deg=0 case</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_degree</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">deg</span> <span class="o">=</span> <span class="mi">0</span>

      <span class="n">begin</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">deg_slice</span><span class="p">[</span><span class="n">deg</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_degree</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">])</span>
      <span class="n">size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">deg_slice</span><span class="p">[</span><span class="n">deg</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_degree</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
      <span class="n">self_atoms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">atom_features</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>

      <span class="c1"># Only use the self layer</span>
      <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">self_atoms</span><span class="p">,</span> <span class="nb">next</span><span class="p">(</span><span class="n">W</span><span class="p">))</span> <span class="o">+</span> <span class="nb">next</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

      <span class="n">new_rel_atoms_collection</span><span class="p">[</span><span class="n">deg</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_degree</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span>

    <span class="c1"># Combine all atoms back into the list</span>
    <span class="n">atom_features</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">new_rel_atoms_collection</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">atom_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span><span class="p">(</span><span class="n">atom_features</span><span class="p">)</span>

    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">atom_features</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_record_variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="GraphConv.sum_neigh"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphConv.sum_neigh">[docs]</a>  <span class="k">def</span> <span class="nf">sum_neigh</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">atoms</span><span class="p">,</span> <span class="n">deg_adj_lists</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Store the summed atoms by degree&quot;&quot;&quot;</span>
    <span class="n">deg_summed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_degree</span> <span class="o">*</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span>

    <span class="c1"># Tensorflow correctly processes empty lists when using concat</span>
    <span class="k">for</span> <span class="n">deg</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
      <span class="n">gathered_atoms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">atoms</span><span class="p">,</span> <span class="n">deg_adj_lists</span><span class="p">[</span><span class="n">deg</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
      <span class="c1"># Sum along neighbors as well as self, and store</span>
      <span class="n">summed_atoms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">gathered_atoms</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">deg_summed</span><span class="p">[</span><span class="n">deg</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">summed_atoms</span>

    <span class="k">return</span> <span class="n">deg_summed</span></div>

<div class="viewcode-block" id="GraphConv.none_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphConv.none_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">none_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">out_tensor</span><span class="p">,</span> <span class="n">W_list</span><span class="p">,</span> <span class="n">b_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_list</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_list</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
    <span class="k">return</span> <span class="n">out_tensor</span><span class="p">,</span> <span class="n">W_list</span><span class="p">,</span> <span class="n">b_list</span></div>

<div class="viewcode-block" id="GraphConv.set_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphConv.set_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">set_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensors</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_list</span> <span class="o">=</span> <span class="n">tensors</span></div></div>


<div class="viewcode-block" id="GraphPool"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphPool">[docs]</a><span class="k">class</span> <span class="nc">GraphPool</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">min_degree</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_degree</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_degree</span> <span class="o">=</span> <span class="n">min_degree</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_degree</span> <span class="o">=</span> <span class="n">max_degree</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">GraphPool</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="GraphPool.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphPool.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">atom_features</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">deg_slice</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">deg_adj_lists</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">3</span><span class="p">:]</span>

    <span class="c1"># Perform the mol gather</span>
    <span class="c1"># atom_features = graph_pool(atom_features, deg_adj_lists, deg_slice,</span>
    <span class="c1">#                            self.max_degree, self.min_degree)</span>

    <span class="n">deg_maxed</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_degree</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_degree</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span>

    <span class="c1"># Tensorflow correctly processes empty lists when using concat</span>

    <span class="k">for</span> <span class="n">deg</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
      <span class="c1"># Get self atoms</span>
      <span class="n">begin</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">deg_slice</span><span class="p">[</span><span class="n">deg</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_degree</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">])</span>
      <span class="n">size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">deg_slice</span><span class="p">[</span><span class="n">deg</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_degree</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
      <span class="n">self_atoms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">atom_features</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>

      <span class="c1"># Expand dims</span>
      <span class="n">self_atoms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">self_atoms</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

      <span class="c1"># always deg-1 for deg_adj_lists</span>
      <span class="n">gathered_atoms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">atom_features</span><span class="p">,</span> <span class="n">deg_adj_lists</span><span class="p">[</span><span class="n">deg</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
      <span class="n">gathered_atoms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">self_atoms</span><span class="p">,</span> <span class="n">gathered_atoms</span><span class="p">])</span>

      <span class="n">maxed_atoms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">gathered_atoms</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">deg_maxed</span><span class="p">[</span><span class="n">deg</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_degree</span><span class="p">]</span> <span class="o">=</span> <span class="n">maxed_atoms</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_degree</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">begin</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">deg_slice</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">])</span>
      <span class="n">size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">deg_slice</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
      <span class="n">self_atoms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">atom_features</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
      <span class="n">deg_maxed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">self_atoms</span>

    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">deg_maxed</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="GraphGather"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphGather">[docs]</a><span class="k">class</span> <span class="nc">GraphGather</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">activation_fn</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">GraphGather</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="GraphGather.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphGather.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;/cpu&#39;</span><span class="p">):</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>

      <span class="c1"># x = [atom_features, deg_slice, membership, deg_adj_list placeholders...]</span>
      <span class="n">atom_features</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

      <span class="c1"># Extract graph topology</span>
      <span class="n">membership</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

      <span class="c1"># Perform the mol gather</span>

      <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;graph_gather requires batches larger than 1&quot;</span>

      <span class="c1"># Obtain the partitions for each of the molecules</span>
      <span class="n">activated_par</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">dynamic_partition</span><span class="p">(</span><span class="n">atom_features</span><span class="p">,</span> <span class="n">membership</span><span class="p">,</span>
                                           <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

      <span class="c1"># Sum over atoms for each molecule</span>
      <span class="n">sparse_reps</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">activated</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
          <span class="k">for</span> <span class="n">activated</span> <span class="ow">in</span> <span class="n">activated_par</span>
      <span class="p">]</span>
      <span class="n">max_reps</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">activated</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
          <span class="k">for</span> <span class="n">activated</span> <span class="ow">in</span> <span class="n">activated_par</span>
      <span class="p">]</span>

      <span class="c1"># Get the final sparse representations</span>
      <span class="n">sparse_reps</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">sparse_reps</span><span class="p">)</span>
      <span class="n">max_reps</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">max_reps</span><span class="p">)</span>
      <span class="n">mol_features</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">sparse_reps</span><span class="p">,</span> <span class="n">max_reps</span><span class="p">])</span>

      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">mol_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_fn</span><span class="p">(</span><span class="n">mol_features</span><span class="p">)</span>
      <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">mol_features</span>
      <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
      <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="LSTMStep"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.LSTMStep">[docs]</a><span class="k">class</span> <span class="nc">LSTMStep</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Layer that performs a single step LSTM update.</span>

<span class="sd">  This layer performs a single step LSTM update. Note that it is *not*</span>
<span class="sd">  a full LSTM recurrent network. The LSTMStep layer is useful as a</span>
<span class="sd">  primitive for designing layers such as the AttnLSTMEmbedding or the</span>
<span class="sd">  IterRefLSTMEmbedding below.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">output_dim</span><span class="p">,</span>
               <span class="n">input_dim</span><span class="p">,</span>
               <span class="n">init_fn</span><span class="o">=</span><span class="n">initializations</span><span class="o">.</span><span class="n">glorot_uniform</span><span class="p">,</span>
               <span class="n">inner_init_fn</span><span class="o">=</span><span class="n">initializations</span><span class="o">.</span><span class="n">orthogonal</span><span class="p">,</span>
               <span class="n">activation_fn</span><span class="o">=</span><span class="n">activations</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span>
               <span class="n">inner_activation_fn</span><span class="o">=</span><span class="n">activations</span><span class="o">.</span><span class="n">hard_sigmoid</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    output_dim: int</span>
<span class="sd">      Dimensionality of output vectors.</span>
<span class="sd">    input_dim: int</span>
<span class="sd">      Dimensionality of input vectors.</span>
<span class="sd">    init_fn: object</span>
<span class="sd">      TensorFlow initialization to use for W.</span>
<span class="sd">    inner_init_fn: object</span>
<span class="sd">      TensorFlow initialization to use for U.</span>
<span class="sd">    activation_fn: object</span>
<span class="sd">      TensorFlow activation to use for output.</span>
<span class="sd">    inner_activation_fn: object</span>
<span class="sd">      TensorFlow activation to use for inner steps.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">LSTMStep</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">init</span> <span class="o">=</span> <span class="n">init_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">inner_init</span> <span class="o">=</span> <span class="n">inner_init_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>

    <span class="c1"># No other forget biases supported right now.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">inner_activation</span> <span class="o">=</span> <span class="n">inner_activation_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>

<div class="viewcode-block" id="LSTMStep.get_initial_states"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.LSTMStep.get_initial_states">[docs]</a>  <span class="k">def</span> <span class="nf">get_initial_states</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">model_ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">input_shape</span><span class="p">),</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)]</span></div>

<div class="viewcode-block" id="LSTMStep.build"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.LSTMStep.build">[docs]</a>  <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs learnable weights for this layer.&quot;&quot;&quot;</span>
    <span class="n">init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span>
    <span class="n">inner_init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_init</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">init</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">U</span> <span class="o">=</span> <span class="n">inner_init</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">),</span>
                   <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">))),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trainable_weights</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">U</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">]</span></div>

<div class="viewcode-block" id="LSTMStep.none_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.LSTMStep.none_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">none_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Zeros out stored tensors for pickling.&quot;&quot;&quot;</span>
    <span class="n">W</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">U</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">c</span>
    <span class="n">trainable_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_weights</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">U</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trainable_weights</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">return</span> <span class="n">W</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">out_tensor</span><span class="p">,</span> <span class="n">trainable_weights</span></div>

<div class="viewcode-block" id="LSTMStep.set_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.LSTMStep.set_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">set_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets all stored tensors.&quot;&quot;&quot;</span>
    <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">U</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">c</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span>
     <span class="bp">self</span><span class="o">.</span><span class="n">trainable_weights</span><span class="p">)</span> <span class="o">=</span> <span class="n">tensor</span></div>

<div class="viewcode-block" id="LSTMStep.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.LSTMStep.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Execute this layer on input tensors.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    in_layers: list</span>
<span class="sd">      List of three tensors (x, h_tm1, c_tm1). h_tm1 means &quot;h, t-1&quot;.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list</span>
<span class="sd">      Returns h, [h + c]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">activation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span>
    <span class="n">inner_activation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_activation</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">h_tm1</span><span class="p">,</span> <span class="n">c_tm1</span> <span class="o">=</span> <span class="n">inputs</span>

    <span class="c1"># Taken from Keras code [citation needed]</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">h_tm1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">U</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>

    <span class="n">z0</span> <span class="o">=</span> <span class="n">z</span><span class="p">[:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">]</span>
    <span class="n">z1</span> <span class="o">=</span> <span class="n">z</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">:</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">]</span>
    <span class="n">z2</span> <span class="o">=</span> <span class="n">z</span><span class="p">[:,</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">:</span><span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">]</span>
    <span class="n">z3</span> <span class="o">=</span> <span class="n">z</span><span class="p">[:,</span> <span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span><span class="p">:]</span>

    <span class="n">i</span> <span class="o">=</span> <span class="n">inner_activation</span><span class="p">(</span><span class="n">z0</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">inner_activation</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">f</span> <span class="o">*</span> <span class="n">c_tm1</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">activation</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>
    <span class="n">o</span> <span class="o">=</span> <span class="n">inner_activation</span><span class="p">(</span><span class="n">z3</span><span class="p">)</span>

    <span class="n">h</span> <span class="o">=</span> <span class="n">o</span> <span class="o">*</span> <span class="n">activation</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">h</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">c</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">h</span>
    <span class="k">return</span> <span class="n">h</span><span class="p">,</span> <span class="p">[</span><span class="n">h</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span></div></div>


<span class="k">def</span> <span class="nf">_cosine_dist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes the inner product (cosine distance) between two tensors.</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  x: tf.Tensor</span>
<span class="sd">    Input Tensor</span>
<span class="sd">  y: tf.Tensor</span>
<span class="sd">    Input Tensor</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">denom</span> <span class="o">=</span> <span class="p">(</span>
      <span class="n">model_ops</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">model_ops</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">*</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span>
      <span class="o">+</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">epsilon</span><span class="p">())</span>
  <span class="k">return</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="o">/</span> <span class="n">denom</span>


<div class="viewcode-block" id="AttnLSTMEmbedding"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AttnLSTMEmbedding">[docs]</a><span class="k">class</span> <span class="nc">AttnLSTMEmbedding</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Implements AttnLSTM as in matching networks paper.</span>

<span class="sd">  The AttnLSTM embedding adjusts two sets of vectors, the &quot;test&quot; and</span>
<span class="sd">  &quot;support&quot; sets. The &quot;support&quot; consists of a set of evidence vectors.</span>
<span class="sd">  Think of these as the small training set for low-data machine</span>
<span class="sd">  learning.  The &quot;test&quot; consists of the queries we wish to answer with</span>
<span class="sd">  the small amounts ofavailable data. The AttnLSTMEmbdding allows us to</span>
<span class="sd">  modify the embedding of the &quot;test&quot; set depending on the contents of</span>
<span class="sd">  the &quot;support&quot;.  The AttnLSTMEmbedding is thus a type of learnable</span>
<span class="sd">  metric that allows a network to modify its internal notion of</span>
<span class="sd">  distance.</span>

<span class="sd">  References:</span>
<span class="sd">  Matching Networks for One Shot Learning</span>
<span class="sd">  https://arxiv.org/pdf/1606.04080v1.pdf</span>

<span class="sd">  Order Matters: Sequence to sequence for sets</span>
<span class="sd">  https://arxiv.org/abs/1511.06391</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_test</span><span class="p">,</span> <span class="n">n_support</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">,</span> <span class="n">max_depth</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_support: int</span>
<span class="sd">      Size of support set.</span>
<span class="sd">    n_test: int</span>
<span class="sd">      Size of test set.</span>
<span class="sd">    n_feat: int</span>
<span class="sd">      Number of features per atom</span>
<span class="sd">    max_depth: int</span>
<span class="sd">      Number of &quot;processing steps&quot; used by sequence-to-sequence for sets model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AttnLSTMEmbedding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_test</span> <span class="o">=</span> <span class="n">n_test</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_support</span> <span class="o">=</span> <span class="n">n_support</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_feat</span> <span class="o">=</span> <span class="n">n_feat</span>

<div class="viewcode-block" id="AttnLSTMEmbedding.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AttnLSTMEmbedding.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Execute this layer on input tensors.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    in_layers: list</span>
<span class="sd">      List of two tensors (X, Xp). X should be of shape (n_test,</span>
<span class="sd">      n_feat) and Xp should be of shape (n_support, n_feat) where</span>
<span class="sd">      n_test is the size of the test set, n_support that of the support</span>
<span class="sd">      set, and n_feat is the number of per-atom features.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list</span>
<span class="sd">      Returns two tensors of same shape as input. Namely the output</span>
<span class="sd">      shape will be [(n_test, n_feat), (n_support, n_feat)]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;AttnLSTMEmbedding layer must have exactly two parents&quot;</span><span class="p">)</span>
    <span class="c1"># x is test set, xp is support set.</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">xp</span> <span class="o">=</span> <span class="n">inputs</span>

    <span class="c1">## Initializes trainable weights.</span>
    <span class="n">n_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_feat</span>

    <span class="n">lstm</span> <span class="o">=</span> <span class="n">LSTMStep</span><span class="p">(</span><span class="n">n_feat</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">n_feat</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q_init</span> <span class="o">=</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_test</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">r_init</span> <span class="o">=</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_test</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">states_init</span> <span class="o">=</span> <span class="n">lstm</span><span class="o">.</span><span class="n">get_initial_states</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_test</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">])</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">trainable_weights</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">q_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">r_init</span><span class="p">]</span>

    <span class="c1">### Performs computations</span>

    <span class="c1"># Get initializations</span>
    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_init</span>
    <span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">states_init</span>

    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span><span class="p">):</span>
      <span class="c1"># Process using attention</span>
      <span class="c1"># Eqn (4), appendix A.1 of Matching Networks paper</span>
      <span class="n">e</span> <span class="o">=</span> <span class="n">_cosine_dist</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">q</span><span class="p">,</span> <span class="n">xp</span><span class="p">)</span>
      <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
      <span class="n">r</span> <span class="o">=</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">xp</span><span class="p">)</span>

      <span class="c1"># Generate new attention states</span>
      <span class="n">y</span> <span class="o">=</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">q</span><span class="p">,</span> <span class="n">r</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">q</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">lstm</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">states</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">xp</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">xq</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">q</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">xp</span> <span class="o">=</span> <span class="n">xp</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">x</span> <span class="o">+</span> <span class="n">q</span><span class="p">,</span> <span class="n">xp</span><span class="p">]</span></div>

<div class="viewcode-block" id="AttnLSTMEmbedding.none_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AttnLSTMEmbedding.none_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">none_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">q_init</span><span class="p">,</span> <span class="n">r_init</span><span class="p">,</span> <span class="n">states_init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">r_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">states_init</span>
    <span class="n">xq</span><span class="p">,</span> <span class="n">xp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xp</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span>
    <span class="n">trainable_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_weights</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">r_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">states_init</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">xq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xp</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trainable_weights</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">return</span> <span class="n">q_init</span><span class="p">,</span> <span class="n">r_init</span><span class="p">,</span> <span class="n">states_init</span><span class="p">,</span> <span class="n">xq</span><span class="p">,</span> <span class="n">xp</span><span class="p">,</span> <span class="n">out_tensor</span><span class="p">,</span> <span class="n">trainable_weights</span></div>

<div class="viewcode-block" id="AttnLSTMEmbedding.set_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AttnLSTMEmbedding.set_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">set_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
    <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">r_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">states_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xp</span><span class="p">,</span>
     <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_weights</span><span class="p">)</span> <span class="o">=</span> <span class="n">tensor</span></div></div>


<div class="viewcode-block" id="IterRefLSTMEmbedding"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.IterRefLSTMEmbedding">[docs]</a><span class="k">class</span> <span class="nc">IterRefLSTMEmbedding</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Implements the Iterative Refinement LSTM.</span>

<span class="sd">  Much like AttnLSTMEmbedding, the IterRefLSTMEmbedding is another type</span>
<span class="sd">  of learnable metric which adjusts &quot;test&quot; and &quot;support.&quot; Recall that</span>
<span class="sd">  &quot;support&quot; is the small amount of data available in a low data machine</span>
<span class="sd">  learning problem, and that &quot;test&quot; is the query. The AttnLSTMEmbedding</span>
<span class="sd">  only modifies the &quot;test&quot; based on the contents of the support.</span>
<span class="sd">  However, the IterRefLSTM modifies both the &quot;support&quot; and &quot;test&quot; based</span>
<span class="sd">  on each other. This allows the learnable metric to be more malleable</span>
<span class="sd">  than that from AttnLSTMEmbeding.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_test</span><span class="p">,</span> <span class="n">n_support</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">,</span> <span class="n">max_depth</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Unlike the AttnLSTM model which only modifies the test vectors</span>
<span class="sd">    additively, this model allows for an additive update to be</span>
<span class="sd">    performed to both test and support using information from each</span>
<span class="sd">    other.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_support: int</span>
<span class="sd">      Size of support set.</span>
<span class="sd">    n_test: int</span>
<span class="sd">      Size of test set.</span>
<span class="sd">    n_feat: int</span>
<span class="sd">      Number of input atom features</span>
<span class="sd">    max_depth: int</span>
<span class="sd">      Number of LSTM Embedding layers.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">IterRefLSTMEmbedding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_test</span> <span class="o">=</span> <span class="n">n_test</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_support</span> <span class="o">=</span> <span class="n">n_support</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_feat</span> <span class="o">=</span> <span class="n">n_feat</span>

<div class="viewcode-block" id="IterRefLSTMEmbedding.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.IterRefLSTMEmbedding.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Execute this layer on input tensors.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    in_layers: list</span>
<span class="sd">      List of two tensors (X, Xp). X should be of shape (n_test, n_feat) and</span>
<span class="sd">      Xp should be of shape (n_support, n_feat) where n_test is the size of</span>
<span class="sd">      the test set, n_support that of the support set, and n_feat is the number</span>
<span class="sd">      of per-atom features.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list</span>
<span class="sd">      Returns two tensors of same shape as input. Namely the output shape will</span>
<span class="sd">      be [(n_test, n_feat), (n_support, n_feat)]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_feat</span>

    <span class="c1"># Support set lstm</span>
    <span class="n">support_lstm</span> <span class="o">=</span> <span class="n">LSTMStep</span><span class="p">(</span><span class="n">n_feat</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">n_feat</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q_init</span> <span class="o">=</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_support</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">support_states_init</span> <span class="o">=</span> <span class="n">support_lstm</span><span class="o">.</span><span class="n">get_initial_states</span><span class="p">(</span>
        <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_support</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">])</span>

    <span class="c1"># Test lstm</span>
    <span class="n">test_lstm</span> <span class="o">=</span> <span class="n">LSTMStep</span><span class="p">(</span><span class="n">n_feat</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">n_feat</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p_init</span> <span class="o">=</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_test</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">test_states_init</span> <span class="o">=</span> <span class="n">test_lstm</span><span class="o">.</span><span class="n">get_initial_states</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_test</span><span class="p">,</span> <span class="n">n_feat</span><span class="p">])</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">trainable_weights</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># self.build()</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s2">&quot;IterRefLSTMEmbedding layer must have exactly two parents&quot;</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">xp</span> <span class="o">=</span> <span class="n">inputs</span>

    <span class="c1"># Get initializations</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_init</span>
    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_init</span>
    <span class="c1"># Rename support</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">xp</span>
    <span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_states_init</span>
    <span class="n">x_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_states_init</span>

    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span><span class="p">):</span>
      <span class="c1"># Process support xp using attention</span>
      <span class="n">e</span> <span class="o">=</span> <span class="n">_cosine_dist</span><span class="p">(</span><span class="n">z</span> <span class="o">+</span> <span class="n">q</span><span class="p">,</span> <span class="n">xp</span><span class="p">)</span>
      <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
      <span class="c1"># Get linear combination of support set</span>
      <span class="n">r</span> <span class="o">=</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">xp</span><span class="p">)</span>

      <span class="c1"># Process test x using attention</span>
      <span class="n">x_e</span> <span class="o">=</span> <span class="n">_cosine_dist</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">p</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
      <span class="n">x_a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x_e</span><span class="p">)</span>
      <span class="n">s</span> <span class="o">=</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>

      <span class="c1"># Generate new support attention states</span>
      <span class="n">qr</span> <span class="o">=</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">q</span><span class="p">,</span> <span class="n">r</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">q</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">support_lstm</span><span class="p">(</span><span class="n">qr</span><span class="p">,</span> <span class="o">*</span><span class="n">states</span><span class="p">)</span>

      <span class="c1"># Generate new test attention states</span>
      <span class="n">ps</span> <span class="o">=</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">p</span><span class="p">,</span> <span class="n">s</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">p</span><span class="p">,</span> <span class="n">x_states</span> <span class="o">=</span> <span class="n">test_lstm</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="o">*</span><span class="n">x_states</span><span class="p">)</span>

      <span class="c1"># Redefine</span>
      <span class="n">z</span> <span class="o">=</span> <span class="n">r</span>

    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">xp</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">p</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">xpq</span> <span class="o">=</span> <span class="n">xp</span> <span class="o">+</span> <span class="n">q</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xp</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">x</span> <span class="o">+</span> <span class="n">p</span><span class="p">,</span> <span class="n">xp</span> <span class="o">+</span> <span class="n">q</span><span class="p">]</span></div>

<div class="viewcode-block" id="IterRefLSTMEmbedding.none_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.IterRefLSTMEmbedding.none_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">none_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">p_init</span><span class="p">,</span> <span class="n">q_init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_init</span><span class="p">,</span>
    <span class="n">support_states_init</span><span class="p">,</span> <span class="n">test_states_init</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">support_states_init</span><span class="p">,</span>
                                             <span class="bp">self</span><span class="o">.</span><span class="n">test_states_init</span><span class="p">)</span>
    <span class="n">xp</span><span class="p">,</span> <span class="n">xpq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">xp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpq</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span>
    <span class="n">trainable_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_weights</span>
    <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_states_init</span><span class="p">,</span>
     <span class="bp">self</span><span class="o">.</span><span class="n">test_states_init</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">xp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpq</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">trainable_weights</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">p_init</span><span class="p">,</span> <span class="n">q_init</span><span class="p">,</span> <span class="n">support_states_init</span><span class="p">,</span> <span class="n">test_states_init</span><span class="p">,</span> <span class="n">xp</span><span class="p">,</span> <span class="n">xpq</span><span class="p">,</span>
            <span class="n">out_tensor</span><span class="p">,</span> <span class="n">trainable_weights</span><span class="p">)</span></div>

<div class="viewcode-block" id="IterRefLSTMEmbedding.set_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.IterRefLSTMEmbedding.set_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">set_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
    <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">support_states_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_states_init</span><span class="p">,</span>
     <span class="bp">self</span><span class="o">.</span><span class="n">xp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xpq</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_weights</span><span class="p">)</span> <span class="o">=</span> <span class="n">tensor</span></div></div>


<div class="viewcode-block" id="BatchNorm"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.BatchNorm">[docs]</a><span class="k">class</span> <span class="nc">BatchNorm</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BatchNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">parent_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="BatchNorm.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.BatchNorm.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">(</span><span class="n">parent_tensor</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="BatchNormalization"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.BatchNormalization">[docs]</a><span class="k">class</span> <span class="nc">BatchNormalization</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
               <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">momentum</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span>
               <span class="n">beta_init</span><span class="o">=</span><span class="s1">&#39;zero&#39;</span><span class="p">,</span>
               <span class="n">gamma_init</span><span class="o">=</span><span class="s1">&#39;one&#39;</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">beta_init</span> <span class="o">=</span> <span class="n">initializations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">beta_init</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gamma_init</span> <span class="o">=</span> <span class="n">initializations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">gamma_init</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="BatchNormalization.add_weight"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.BatchNormalization.add_weight">[docs]</a>  <span class="k">def</span> <span class="nf">add_weight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">initializer</span> <span class="o">=</span> <span class="n">initializations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">initializer</span><span class="p">)</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">initializer</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">weight</span></div>

<div class="viewcode-block" id="BatchNormalization.build"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.BatchNormalization.build">[docs]</a>  <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">axis</span><span class="p">],)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span>
        <span class="n">shape</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma_init</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;{}_gamma&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span>
        <span class="n">shape</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">beta_init</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;{}_beta&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">))</span></div>

<div class="viewcode-block" id="BatchNormalization.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.BatchNormalization.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
        <span class="n">model_ops</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>
    <span class="n">x_normed</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">m</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">std</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>
    <span class="n">x_normed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">x_normed</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">x_normed</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="BatchNormalization.none_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.BatchNormalization.none_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">none_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
    <span class="k">return</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="BatchNormalization.set_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.BatchNormalization.set_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">set_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tensor</span></div></div>


<div class="viewcode-block" id="WeightedError"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.WeightedError">[docs]</a><span class="k">class</span> <span class="nc">WeightedError</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">WeightedError</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">()</span>

<div class="viewcode-block" id="WeightedError.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.WeightedError.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">entropy</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">entropy</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="VinaFreeEnergy"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.VinaFreeEnergy">[docs]</a><span class="k">class</span> <span class="nc">VinaFreeEnergy</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes free-energy as defined by Autodock Vina.</span>

<span class="sd">  TODO(rbharath): Make this layer support batching.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">N_atoms</span><span class="p">,</span>
               <span class="n">M_nbrs</span><span class="p">,</span>
               <span class="n">ndim</span><span class="p">,</span>
               <span class="n">nbr_cutoff</span><span class="p">,</span>
               <span class="n">start</span><span class="p">,</span>
               <span class="n">stop</span><span class="p">,</span>
               <span class="n">stddev</span><span class="o">=.</span><span class="mi">3</span><span class="p">,</span>
               <span class="n">Nrot</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stddev</span> <span class="o">=</span> <span class="n">stddev</span>
    <span class="c1"># Number of rotatable bonds</span>
    <span class="c1"># TODO(rbharath): Vina actually sets this per-molecule. See if makes</span>
    <span class="c1"># a difference.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Nrot</span> <span class="o">=</span> <span class="n">Nrot</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">N_atoms</span> <span class="o">=</span> <span class="n">N_atoms</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">M_nbrs</span> <span class="o">=</span> <span class="n">M_nbrs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="n">ndim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nbr_cutoff</span> <span class="o">=</span> <span class="n">nbr_cutoff</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">start</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stop</span> <span class="o">=</span> <span class="n">stop</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">VinaFreeEnergy</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="VinaFreeEnergy.cutoff"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.VinaFreeEnergy.cutoff">[docs]</a>  <span class="k">def</span> <span class="nf">cutoff</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">d</span> <span class="o">&lt;</span> <span class="mi">8</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="VinaFreeEnergy.nonlinearity"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.VinaFreeEnergy.nonlinearity">[docs]</a>  <span class="k">def</span> <span class="nf">nonlinearity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes non-linearity used in Vina.&quot;&quot;&quot;</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">stddev</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stddev</span><span class="p">))</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">c</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">w</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nrot</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">w</span><span class="p">,</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="VinaFreeEnergy.repulsion"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.VinaFreeEnergy.repulsion">[docs]</a>  <span class="k">def</span> <span class="nf">repulsion</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes Autodock Vina&#39;s repulsion interaction term.&quot;&quot;&quot;</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">d</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">d</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="VinaFreeEnergy.hydrophobic"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.VinaFreeEnergy.hydrophobic">[docs]</a>  <span class="k">def</span> <span class="nf">hydrophobic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes Autodock Vina&#39;s hydrophobic interaction term.&quot;&quot;&quot;</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">d</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">d</span><span class="p">),</span>
                          <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">d</span> <span class="o">&lt;</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.5</span> <span class="o">-</span> <span class="n">d</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">d</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="VinaFreeEnergy.hydrogen_bond"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.VinaFreeEnergy.hydrogen_bond">[docs]</a>  <span class="k">def</span> <span class="nf">hydrogen_bond</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes Autodock Vina&#39;s hydrogen bond interaction term.&quot;&quot;&quot;</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">d</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">d</span><span class="p">),</span>
                          <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">d</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">0</span> <span class="o">-</span> <span class="n">d</span><span class="p">),</span>
                                   <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">d</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="VinaFreeEnergy.gaussian_first"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.VinaFreeEnergy.gaussian_first">[docs]</a>  <span class="k">def</span> <span class="nf">gaussian_first</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes Autodock Vina&#39;s first Gaussian interaction term.&quot;&quot;&quot;</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">d</span> <span class="o">/</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="VinaFreeEnergy.gaussian_second"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.VinaFreeEnergy.gaussian_second">[docs]</a>  <span class="k">def</span> <span class="nf">gaussian_second</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes Autodock Vina&#39;s second Gaussian interaction term.&quot;&quot;&quot;</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">d</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="VinaFreeEnergy.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.VinaFreeEnergy.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: tf.Tensor of shape (N, d)</span>
<span class="sd">      Coordinates/features.</span>
<span class="sd">    Z: tf.Tensor of shape (N)</span>
<span class="sd">      Atomic numbers of neighbor atoms.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    layer: tf.Tensor of shape (B)</span>
<span class="sd">      The free energy of each complex in batch</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># TODO(rbharath): This layer shouldn&#39;t be neighbor-listing. Make</span>
    <span class="c1"># neighbors lists an argument instead of a part of this layer.</span>
    <span class="n">nbr_list</span> <span class="o">=</span> <span class="n">NeighborList</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_atoms</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">M_nbrs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">nbr_cutoff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1"># Shape (N, M)</span>
    <span class="n">dists</span> <span class="o">=</span> <span class="n">InteratomicL2Distances</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_atoms</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">M_nbrs</span><span class="p">,</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">)(</span><span class="n">X</span><span class="p">,</span> <span class="n">nbr_list</span><span class="p">)</span>

    <span class="n">repulsion</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">repulsion</span><span class="p">(</span><span class="n">dists</span><span class="p">)</span>
    <span class="n">hydrophobic</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hydrophobic</span><span class="p">(</span><span class="n">dists</span><span class="p">)</span>
    <span class="n">hbond</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hydrogen_bond</span><span class="p">(</span><span class="n">dists</span><span class="p">)</span>
    <span class="n">gauss_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gaussian_first</span><span class="p">(</span><span class="n">dists</span><span class="p">)</span>
    <span class="n">gauss_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gaussian_second</span><span class="p">(</span><span class="n">dists</span><span class="p">)</span>

    <span class="c1"># Shape (N, M)</span>
    <span class="n">weighted_combo</span> <span class="o">=</span> <span class="n">WeightedLinearCombo</span><span class="p">()</span>
    <span class="n">interactions</span> <span class="o">=</span> <span class="n">weighted_combo</span><span class="p">(</span><span class="n">repulsion</span><span class="p">,</span> <span class="n">hydrophobic</span><span class="p">,</span> <span class="n">hbond</span><span class="p">,</span> <span class="n">gauss_1</span><span class="p">,</span>
                                  <span class="n">gauss_2</span><span class="p">)</span>

    <span class="c1"># Shape (N, M)</span>
    <span class="n">thresholded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">(</span><span class="n">dists</span><span class="p">,</span> <span class="n">interactions</span><span class="p">)</span>

    <span class="n">weight</span><span class="p">,</span> <span class="n">free_energies</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nonlinearity</span><span class="p">(</span><span class="n">thresholded</span><span class="p">)</span>
    <span class="n">free_energy</span> <span class="o">=</span> <span class="n">ReduceSum</span><span class="p">()(</span><span class="n">free_energies</span><span class="p">)</span>

    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">free_energy</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_record_variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="WeightedLinearCombo"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.WeightedLinearCombo">[docs]</a><span class="k">class</span> <span class="nc">WeightedLinearCombo</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes a weighted linear combination of input layers, with the weights defined by trainable variables.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">std</span><span class="o">=.</span><span class="mi">3</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">std</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">WeightedLinearCombo</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="WeightedLinearCombo.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.WeightedLinearCombo.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">for</span> <span class="n">in_tensor</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
      <span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span>
          <span class="mi">1</span><span class="p">,</span>
      <span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">))</span>
      <span class="k">if</span> <span class="n">out_tensor</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">in_tensor</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">out_tensor</span> <span class="o">+=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">in_tensor</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_record_variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="NeighborList"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.NeighborList">[docs]</a><span class="k">class</span> <span class="nc">NeighborList</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes a neighbor-list in Tensorflow.</span>

<span class="sd">  Neighbor-lists (also called Verlet Lists) are a tool for grouping atoms which</span>
<span class="sd">  are close to each other spatially</span>

<span class="sd">  TODO(rbharath): Make this layer support batching.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N_atoms</span><span class="p">,</span> <span class="n">M_nbrs</span><span class="p">,</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">nbr_cutoff</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    N_atoms: int</span>
<span class="sd">      Maximum number of atoms this layer will neighbor-list.</span>
<span class="sd">    M_nbrs: int</span>
<span class="sd">      Maximum number of spatial neighbors possible for atom.</span>
<span class="sd">    ndim: int</span>
<span class="sd">      Dimensionality of space atoms live in. (Typically 3D, but sometimes will</span>
<span class="sd">      want to use higher dimensional descriptors for atoms).</span>
<span class="sd">    nbr_cutoff: float</span>
<span class="sd">      Length in Angstroms (?) at which atom boxes are gridded.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">N_atoms</span> <span class="o">=</span> <span class="n">N_atoms</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">M_nbrs</span> <span class="o">=</span> <span class="n">M_nbrs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="n">ndim</span>
    <span class="c1"># Number of grid cells</span>
    <span class="n">n_cells</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(((</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">/</span> <span class="n">nbr_cutoff</span><span class="p">)</span><span class="o">**</span><span class="n">ndim</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span> <span class="o">=</span> <span class="n">n_cells</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nbr_cutoff</span> <span class="o">=</span> <span class="n">nbr_cutoff</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">start</span> <span class="o">=</span> <span class="n">start</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stop</span> <span class="o">=</span> <span class="n">stop</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">NeighborList</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="NeighborList.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.NeighborList.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates tensors associated with neighbor-listing.&quot;&quot;&quot;</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;NeighborList can only have one input&quot;</span><span class="p">)</span>
    <span class="n">parent</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parent</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
      <span class="c1"># TODO(rbharath): Support batching</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Parent tensor must be (num_atoms, ndum)&quot;</span><span class="p">)</span>
    <span class="n">coords</span> <span class="o">=</span> <span class="n">parent</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_nbr_list</span><span class="p">(</span><span class="n">coords</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="NeighborList.compute_nbr_list"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.NeighborList.compute_nbr_list">[docs]</a>  <span class="k">def</span> <span class="nf">compute_nbr_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coords</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get closest neighbors for atoms.</span>

<span class="sd">    Needs to handle padding for atoms with no neighbors.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coords: tf.Tensor</span>
<span class="sd">      Shape (N_atoms, ndim)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    nbr_list: tf.Tensor</span>
<span class="sd">      Shape (N_atoms, M_nbrs) of atom indices</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Shape (n_cells, ndim)</span>
    <span class="n">cells</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_cells</span><span class="p">()</span>

    <span class="c1"># List of length N_atoms, each element of different length uniques_i</span>
    <span class="n">nbrs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_atoms_in_nbrs</span><span class="p">(</span><span class="n">coords</span><span class="p">,</span> <span class="n">cells</span><span class="p">)</span>
    <span class="n">padding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">M_nbrs</span><span class="p">,),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">padded_nbrs</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">unique_nbrs</span><span class="p">,</span> <span class="n">padding</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">unique_nbrs</span> <span class="ow">in</span> <span class="n">nbrs</span><span class="p">]</span>

    <span class="c1"># List of length N_atoms, each element of different length uniques_i</span>
    <span class="c1"># List of length N_atoms, each a tensor of shape</span>
    <span class="c1"># (uniques_i, ndim)</span>
    <span class="n">nbr_coords</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">coords</span><span class="p">,</span> <span class="n">atom_nbrs</span><span class="p">)</span> <span class="k">for</span> <span class="n">atom_nbrs</span> <span class="ow">in</span> <span class="n">nbrs</span><span class="p">]</span>

    <span class="c1"># Add phantom atoms that exist far outside the box</span>
    <span class="n">coord_padding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">M_nbrs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">),</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop</span><span class="p">))</span>
    <span class="n">padded_nbr_coords</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">nbr_coord</span><span class="p">,</span> <span class="n">coord_padding</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">nbr_coord</span> <span class="ow">in</span> <span class="n">nbr_coords</span>
    <span class="p">]</span>

    <span class="c1"># List of length N_atoms, each of shape (1, ndim)</span>
    <span class="n">atom_coords</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">coords</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_atoms</span><span class="p">)</span>
    <span class="c1"># TODO(rbharath): How does distance need to be modified here to</span>
    <span class="c1"># account for periodic boundary conditions?</span>
    <span class="c1"># List of length N_atoms each of shape (M_nbrs)</span>
    <span class="n">padded_dists</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">((</span><span class="n">atom_coord</span> <span class="o">-</span> <span class="n">padded_nbr_coord</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">atom_coord</span><span class="p">,</span>
             <span class="n">padded_nbr_coord</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">atom_coords</span><span class="p">,</span> <span class="n">padded_nbr_coords</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">padded_closest_nbrs</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="o">-</span><span class="n">padded_dist</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">M_nbrs</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">padded_dist</span> <span class="ow">in</span> <span class="n">padded_dists</span>
    <span class="p">]</span>

    <span class="c1"># N_atoms elts of size (M_nbrs,) each</span>
    <span class="n">padded_neighbor_list</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">padded_atom_nbrs</span><span class="p">,</span> <span class="n">padded_closest_nbr</span><span class="p">)</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">padded_atom_nbrs</span><span class="p">,</span>
             <span class="n">padded_closest_nbr</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">padded_nbrs</span><span class="p">,</span> <span class="n">padded_closest_nbrs</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">neighbor_list</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">padded_neighbor_list</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">neighbor_list</span></div>

<div class="viewcode-block" id="NeighborList.get_atoms_in_nbrs"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.NeighborList.get_atoms_in_nbrs">[docs]</a>  <span class="k">def</span> <span class="nf">get_atoms_in_nbrs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coords</span><span class="p">,</span> <span class="n">cells</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get the atoms in neighboring cells for each cells.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    atoms_in_nbrs = (N_atoms, n_nbr_cells, M_nbrs)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Shape (N_atoms, 1)</span>
    <span class="n">cells_for_atoms</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_cells_for_atoms</span><span class="p">(</span><span class="n">coords</span><span class="p">,</span> <span class="n">cells</span><span class="p">)</span>

    <span class="c1"># Find M_nbrs atoms closest to each cell</span>
    <span class="c1"># Shape (n_cells, M_nbrs)</span>
    <span class="n">closest_atoms</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_closest_atoms</span><span class="p">(</span><span class="n">coords</span><span class="p">,</span> <span class="n">cells</span><span class="p">)</span>

    <span class="c1"># Associate each cell with its neighbor cells. Assumes periodic boundary</span>
    <span class="c1"># conditions, so does wrapround. O(constant)</span>
    <span class="c1"># Shape (n_cells, n_nbr_cells)</span>
    <span class="n">neighbor_cells</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_neighbor_cells</span><span class="p">(</span><span class="n">cells</span><span class="p">)</span>

    <span class="c1"># Shape (N_atoms, n_nbr_cells)</span>
    <span class="n">neighbor_cells</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">neighbor_cells</span><span class="p">,</span> <span class="n">cells_for_atoms</span><span class="p">))</span>

    <span class="c1"># Shape (N_atoms, n_nbr_cells, M_nbrs)</span>
    <span class="n">atoms_in_nbrs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">closest_atoms</span><span class="p">,</span> <span class="n">neighbor_cells</span><span class="p">)</span>

    <span class="c1"># Shape (N_atoms, n_nbr_cells*M_nbrs)</span>
    <span class="n">atoms_in_nbrs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">atoms_in_nbrs</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">N_atoms</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># List of length N_atoms, each element length uniques_i</span>
    <span class="n">nbrs_per_atom</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">atoms_in_nbrs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_atoms</span><span class="p">)</span>
    <span class="n">uniques</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">atom_nbrs</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">atom_nbrs</span> <span class="ow">in</span> <span class="n">nbrs_per_atom</span>
    <span class="p">]</span>

    <span class="c1"># TODO(rbharath): FRAGILE! Uses fact that identity seems to be the first</span>
    <span class="c1"># element removed to remove self from list of neighbors. Need to verify</span>
    <span class="c1"># this holds more broadly or come up with robust alternative.</span>
    <span class="n">uniques</span> <span class="o">=</span> <span class="p">[</span><span class="n">unique</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="k">for</span> <span class="n">unique</span> <span class="ow">in</span> <span class="n">uniques</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">uniques</span></div>

<div class="viewcode-block" id="NeighborList.get_closest_atoms"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.NeighborList.get_closest_atoms">[docs]</a>  <span class="k">def</span> <span class="nf">get_closest_atoms</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coords</span><span class="p">,</span> <span class="n">cells</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;For each cell, find M_nbrs closest atoms.</span>

<span class="sd">    Let N_atoms be the number of atoms.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coords: tf.Tensor</span>
<span class="sd">      (N_atoms, ndim) shape.</span>
<span class="sd">    cells: tf.Tensor</span>
<span class="sd">      (n_cells, ndim) shape.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    closest_inds: tf.Tensor</span>
<span class="sd">      Of shape (n_cells, M_nbrs)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">N_atoms</span><span class="p">,</span> <span class="n">n_cells</span><span class="p">,</span> <span class="n">ndim</span><span class="p">,</span> <span class="n">M_nbrs</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_atoms</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span>
                                      <span class="bp">self</span><span class="o">.</span><span class="n">M_nbrs</span><span class="p">)</span>
    <span class="c1"># Tile both cells and coords to form arrays of size (N_atoms*n_cells, ndim)</span>
    <span class="n">tiled_cells</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">cells</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N_atoms</span><span class="p">)),</span> <span class="p">(</span><span class="n">N_atoms</span> <span class="o">*</span> <span class="n">n_cells</span><span class="p">,</span> <span class="n">ndim</span><span class="p">))</span>

    <span class="c1"># Shape (N_atoms*n_cells, ndim) after tile</span>
    <span class="n">tiled_coords</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">coords</span><span class="p">,</span> <span class="p">(</span><span class="n">n_cells</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Shape (N_atoms*n_cells)</span>
    <span class="n">coords_vec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">((</span><span class="n">tiled_coords</span> <span class="o">-</span> <span class="n">tiled_cells</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Shape (n_cells, N_atoms)</span>
    <span class="n">coords_norm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">coords_vec</span><span class="p">,</span> <span class="p">(</span><span class="n">n_cells</span><span class="p">,</span> <span class="n">N_atoms</span><span class="p">))</span>

    <span class="c1"># Find k atoms closest to this cell. Notice negative sign since</span>
    <span class="c1"># tf.nn.top_k returns *largest* not smallest.</span>
    <span class="c1"># Tensor of shape (n_cells, M_nbrs)</span>
    <span class="n">closest_inds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="o">-</span><span class="n">coords_norm</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">M_nbrs</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">closest_inds</span></div>

<div class="viewcode-block" id="NeighborList.get_cells_for_atoms"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.NeighborList.get_cells_for_atoms">[docs]</a>  <span class="k">def</span> <span class="nf">get_cells_for_atoms</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coords</span><span class="p">,</span> <span class="n">cells</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the cells each atom belongs to.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coords: tf.Tensor</span>
<span class="sd">      Shape (N_atoms, ndim)</span>
<span class="sd">    cells: tf.Tensor</span>
<span class="sd">      (n_cells, ndim) shape.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    cells_for_atoms: tf.Tensor</span>
<span class="sd">      Shape (N_atoms, 1)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">N_atoms</span><span class="p">,</span> <span class="n">n_cells</span><span class="p">,</span> <span class="n">ndim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_atoms</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span>
    <span class="n">n_cells</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_cells</span><span class="p">)</span>
    <span class="c1"># Tile both cells and coords to form arrays of size (N_atoms*n_cells, ndim)</span>
    <span class="n">tiled_cells</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">cells</span><span class="p">,</span> <span class="p">(</span><span class="n">N_atoms</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Shape (N_atoms*n_cells, 1) after tile</span>
    <span class="n">tiled_coords</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">coords</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_cells</span><span class="p">)),</span> <span class="p">(</span><span class="n">n_cells</span> <span class="o">*</span> <span class="n">N_atoms</span><span class="p">,</span> <span class="n">ndim</span><span class="p">))</span>
    <span class="n">coords_vec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">((</span><span class="n">tiled_coords</span> <span class="o">-</span> <span class="n">tiled_cells</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">coords_norm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">coords_vec</span><span class="p">,</span> <span class="p">(</span><span class="n">N_atoms</span><span class="p">,</span> <span class="n">n_cells</span><span class="p">))</span>

    <span class="n">closest_inds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="o">-</span><span class="n">coords_norm</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">closest_inds</span></div>

  <span class="k">def</span> <span class="nf">_get_num_nbrs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get number of neighbors in current dimensionality space.&quot;&quot;&quot;</span>
    <span class="n">ndim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span>
    <span class="k">if</span> <span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">n_nbr_cells</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="k">elif</span> <span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
      <span class="c1"># 9 neighbors in 2-space</span>
      <span class="n">n_nbr_cells</span> <span class="o">=</span> <span class="mi">9</span>
    <span class="c1"># TODO(rbharath): Shoddy handling of higher dimensions...</span>
    <span class="k">elif</span> <span class="n">ndim</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
      <span class="c1"># Number of cells for cube in 3-space is</span>
      <span class="n">n_nbr_cells</span> <span class="o">=</span> <span class="mi">27</span>  <span class="c1"># (26 faces on Rubik&#39;s cube for example)</span>
    <span class="k">return</span> <span class="n">n_nbr_cells</span>

<div class="viewcode-block" id="NeighborList.get_neighbor_cells"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.NeighborList.get_neighbor_cells">[docs]</a>  <span class="k">def</span> <span class="nf">get_neighbor_cells</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cells</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute neighbors of cells in grid.</span>

<span class="sd">    # TODO(rbharath): Do we need to handle periodic boundary conditions</span>
<span class="sd">    properly here?</span>
<span class="sd">    # TODO(rbharath): This doesn&#39;t handle boundaries well. We hard-code</span>
<span class="sd">    # looking for n_nbr_cells neighbors, which isn&#39;t right for boundary cells in</span>
<span class="sd">    # the cube.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cells: tf.Tensor</span>
<span class="sd">      (n_cells, ndim) shape.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    nbr_cells: tf.Tensor</span>
<span class="sd">      (n_cells, n_nbr_cells)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ndim</span><span class="p">,</span> <span class="n">n_cells</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span>
    <span class="n">n_nbr_cells</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_num_nbrs</span><span class="p">()</span>
    <span class="c1"># Tile cells to form arrays of size (n_cells*n_cells, ndim)</span>
    <span class="c1"># Two tilings (a, b, c, a, b, c, ...) vs. (a, a, a, b, b, b, etc.)</span>
    <span class="c1"># Tile (a, a, a, b, b, b, etc.)</span>
    <span class="n">tiled_centers</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">cells</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_cells</span><span class="p">)),</span> <span class="p">(</span><span class="n">n_cells</span> <span class="o">*</span> <span class="n">n_cells</span><span class="p">,</span> <span class="n">ndim</span><span class="p">))</span>
    <span class="c1"># Tile (a, b, c, a, b, c, ...)</span>
    <span class="n">tiled_cells</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">cells</span><span class="p">,</span> <span class="p">(</span><span class="n">n_cells</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">coords_vec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">((</span><span class="n">tiled_centers</span> <span class="o">-</span> <span class="n">tiled_cells</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">coords_norm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">coords_vec</span><span class="p">,</span> <span class="p">(</span><span class="n">n_cells</span><span class="p">,</span> <span class="n">n_cells</span><span class="p">))</span>
    <span class="n">closest_inds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="o">-</span><span class="n">coords_norm</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">n_nbr_cells</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">closest_inds</span></div>

<div class="viewcode-block" id="NeighborList.get_cells"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.NeighborList.get_cells">[docs]</a>  <span class="k">def</span> <span class="nf">get_cells</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the locations of all grid points in box.</span>

<span class="sd">    Suppose start is -10 Angstrom, stop is 10 Angstrom, nbr_cutoff is 1.</span>
<span class="sd">    Then would return a list of length 20^3 whose entries would be</span>
<span class="sd">    [(-10, -10, -10), (-10, -10, -9), ..., (9, 9, 9)]</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    cells: tf.Tensor</span>
<span class="sd">      (n_cells, ndim) shape.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">nbr_cutoff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nbr_cutoff</span>
    <span class="n">mesh_args</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">nbr_cutoff</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="o">*</span><span class="n">mesh_args</span><span class="p">))),</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">)))</span></div></div>


<div class="viewcode-block" id="Dropout"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Dropout">[docs]</a><span class="k">class</span> <span class="nc">Dropout</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dropout_prob</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout_prob</span> <span class="o">=</span> <span class="n">dropout_prob</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Dropout</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="Dropout.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.Dropout.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_prob</span> <span class="o">*</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;training&#39;</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">parent_tensor</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="WeightDecay"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.WeightDecay">[docs]</a><span class="k">class</span> <span class="nc">WeightDecay</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Apply a weight decay penalty.</span>

<span class="sd">  The input should be the loss value.  This layer adds a weight decay penalty to it</span>
<span class="sd">  and outputs the sum.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">penalty</span><span class="p">,</span> <span class="n">penalty_type</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create a weight decay penalty layer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    penalty: float</span>
<span class="sd">      magnitude of the penalty term</span>
<span class="sd">    penalty_type: str</span>
<span class="sd">      type of penalty to compute, either &#39;l1&#39; or &#39;l2&#39;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">penalty</span> <span class="o">=</span> <span class="n">penalty</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">penalty_type</span> <span class="o">=</span> <span class="n">penalty_type</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">WeightDecay</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
      <span class="k">pass</span>

<div class="viewcode-block" id="WeightDecay.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.WeightDecay.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">parent_tensor</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">parent_tensor</span> <span class="o">+</span> <span class="n">model_ops</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">penalty_type</span><span class="p">,</span>
                                                        <span class="bp">self</span><span class="o">.</span><span class="n">penalty</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="AtomicConvolution"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AtomicConvolution">[docs]</a><span class="k">class</span> <span class="nc">AtomicConvolution</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">atom_types</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="n">radial_params</span><span class="o">=</span><span class="nb">list</span><span class="p">(),</span>
               <span class="n">boxsize</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Atomic convoluation layer</span>

<span class="sd">    N = max_num_atoms, M = max_num_neighbors, B = batch_size, d = num_features</span>
<span class="sd">    l = num_radial_filters * num_atom_types</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    atom_types: list or None</span>
<span class="sd">      Of length a, where a is number of atom types for filtering.</span>
<span class="sd">    radial_params: list</span>
<span class="sd">      Of length l, where l is number of radial filters learned.</span>
<span class="sd">    boxsize: float or None</span>
<span class="sd">      Simulation box length [Angstrom].</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">boxsize</span> <span class="o">=</span> <span class="n">boxsize</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">radial_params</span> <span class="o">=</span> <span class="n">radial_params</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">atom_types</span> <span class="o">=</span> <span class="n">atom_types</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AtomicConvolution</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="AtomicConvolution.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AtomicConvolution.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: tf.Tensor of shape (B, N, d)</span>
<span class="sd">      Coordinates/features.</span>
<span class="sd">    Nbrs: tf.Tensor of shape (B, N, M)</span>
<span class="sd">      Neighbor list.</span>
<span class="sd">    Nbrs_Z: tf.Tensor of shape (B, N, M)</span>
<span class="sd">      Atomic numbers of neighbor atoms.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    layer: tf.Tensor of shape (B, N, l)</span>
<span class="sd">      A new tensor representing the output of the atomic conv layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">Nbrs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_int32</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">Nbrs_Z</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

    <span class="c1"># N: Maximum number of atoms</span>
    <span class="c1"># M: Maximum number of neighbors</span>
    <span class="c1"># d: Number of coordinates/features/filters</span>
    <span class="c1"># B: Batch Size</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">Nbrs</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>

    <span class="n">D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distance_tensor</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Nbrs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">boxsize</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
    <span class="n">R</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distance_matrix</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
    <span class="n">sym</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">rsf_zeros</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">radial_params</span><span class="p">:</span>

      <span class="c1"># We apply the radial pooling filter before atom type conv</span>
      <span class="c1"># to reduce computation</span>
      <span class="n">param_variables</span><span class="p">,</span> <span class="n">rsf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">radial_symmetry_function</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="o">*</span><span class="n">param</span><span class="p">)</span>

      <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">atom_types</span><span class="p">:</span>
        <span class="n">cond</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">not_equal</span><span class="p">(</span><span class="n">Nbrs_Z</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="n">sym</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">rsf</span><span class="p">,</span> <span class="n">rsf_zeros</span><span class="p">),</span> <span class="mi">2</span><span class="p">))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">atom_types</span><span class="p">)):</span>
          <span class="n">cond</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">Nbrs_Z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">atom_types</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
          <span class="n">sym</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">rsf</span><span class="p">,</span> <span class="n">rsf_zeros</span><span class="p">),</span> <span class="mi">2</span><span class="p">))</span>

    <span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">sym</span><span class="p">)</span>
    <span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>  <span class="c1"># (l, B, N) -&gt; (B, N, l)</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">moments</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_record_variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="AtomicConvolution.radial_symmetry_function"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AtomicConvolution.radial_symmetry_function">[docs]</a>  <span class="k">def</span> <span class="nf">radial_symmetry_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">rc</span><span class="p">,</span> <span class="n">rs</span><span class="p">,</span> <span class="n">e</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates radial symmetry function.</span>

<span class="sd">    B = batch_size, N = max_num_atoms, M = max_num_neighbors, d = num_filters</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    R: tf.Tensor of shape (B, N, M)</span>
<span class="sd">      Distance matrix.</span>
<span class="sd">    rc: float</span>
<span class="sd">      Interaction cutoff [Angstrom].</span>
<span class="sd">    rs: float</span>
<span class="sd">      Gaussian distance matrix mean.</span>
<span class="sd">    e: float</span>
<span class="sd">      Gaussian distance matrix width.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    retval: tf.Tensor of shape (B, N, M)</span>
<span class="sd">      Radial symmetry function (before summation)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="s2">&quot;NbrRadialSymmetryFunction&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">rc</span><span class="p">,</span> <span class="n">rs</span><span class="p">,</span> <span class="n">e</span><span class="p">]):</span>
      <span class="n">rc</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">rc</span><span class="p">)</span>
      <span class="n">rs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">rs</span><span class="p">)</span>
      <span class="n">e</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
      <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gaussian_distance_matrix</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">rs</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
      <span class="n">FC</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">radial_cutoff</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">rc</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">rc</span><span class="p">,</span> <span class="n">rs</span><span class="p">,</span> <span class="n">e</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">FC</span><span class="p">)</span></div>

<div class="viewcode-block" id="AtomicConvolution.radial_cutoff"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AtomicConvolution.radial_cutoff">[docs]</a>  <span class="k">def</span> <span class="nf">radial_cutoff</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">rc</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates radial cutoff matrix.</span>

<span class="sd">    B = batch_size, N = max_num_atoms, M = max_num_neighbors</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">      R [B, N, M]: tf.Tensor</span>
<span class="sd">        Distance matrix.</span>
<span class="sd">      rc: tf.Variable</span>
<span class="sd">        Interaction cutoff [Angstrom].</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">      FC [B, N, M]: tf.Tensor</span>
<span class="sd">        Radial cutoff matrix.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">T</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">R</span> <span class="o">/</span> <span class="p">(</span><span class="n">rc</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">E</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
    <span class="n">cond</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">rc</span><span class="p">)</span>
    <span class="n">FC</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">E</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">FC</span></div>

<div class="viewcode-block" id="AtomicConvolution.gaussian_distance_matrix"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AtomicConvolution.gaussian_distance_matrix">[docs]</a>  <span class="k">def</span> <span class="nf">gaussian_distance_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">rs</span><span class="p">,</span> <span class="n">e</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates gaussian distance matrix.</span>

<span class="sd">    B = batch_size, N = max_num_atoms, M = max_num_neighbors</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">      R [B, N, M]: tf.Tensor</span>
<span class="sd">        Distance matrix.</span>
<span class="sd">      rs: tf.Variable</span>
<span class="sd">        Gaussian distance matrix mean.</span>
<span class="sd">      e: tf.Variable</span>
<span class="sd">        Gaussian distance matrix width (e = .5/std**2).</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">      retval [B, N, M]: tf.Tensor</span>
<span class="sd">        Gaussian distance matrix.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">e</span> <span class="o">*</span> <span class="p">(</span><span class="n">R</span> <span class="o">-</span> <span class="n">rs</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span></div>

<div class="viewcode-block" id="AtomicConvolution.distance_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AtomicConvolution.distance_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">distance_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Nbrs</span><span class="p">,</span> <span class="n">boxsize</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates distance tensor for batch of molecules.</span>

<span class="sd">    B = batch_size, N = max_num_atoms, M = max_num_neighbors, d = num_features</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: tf.Tensor of shape (B, N, d)</span>
<span class="sd">      Coordinates/features tensor.</span>
<span class="sd">    Nbrs: tf.Tensor of shape (B, N, M)</span>
<span class="sd">      Neighbor list tensor.</span>
<span class="sd">    boxsize: float or None</span>
<span class="sd">      Simulation box length [Angstrom].</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    D: tf.Tensor of shape (B, N, M, d)</span>
<span class="sd">      Coordinates/features distance tensor.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">atom_tensors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">nbr_tensors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">Nbrs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">D</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">boxsize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">atom</span><span class="p">,</span> <span class="n">atom_tensor</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">atom_tensors</span><span class="p">):</span>
        <span class="n">nbrs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gather_neighbors</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">nbr_tensors</span><span class="p">[</span><span class="n">atom</span><span class="p">],</span> <span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
        <span class="n">nbrs_tensors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">nbrs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">nbr</span><span class="p">,</span> <span class="n">nbr_tensor</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nbrs_tensors</span><span class="p">):</span>
          <span class="n">_D</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">nbr_tensor</span><span class="p">,</span> <span class="n">atom_tensor</span><span class="p">)</span>
          <span class="n">_D</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">_D</span><span class="p">,</span> <span class="n">boxsize</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">_D</span><span class="p">,</span> <span class="n">boxsize</span><span class="p">)))</span>
          <span class="n">D</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_D</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">atom</span><span class="p">,</span> <span class="n">atom_tensor</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">atom_tensors</span><span class="p">):</span>
        <span class="n">nbrs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gather_neighbors</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">nbr_tensors</span><span class="p">[</span><span class="n">atom</span><span class="p">],</span> <span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
        <span class="n">nbrs_tensors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">nbrs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">nbr</span><span class="p">,</span> <span class="n">nbr_tensor</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">nbrs_tensors</span><span class="p">):</span>
          <span class="n">_D</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">nbr_tensor</span><span class="p">,</span> <span class="n">atom_tensor</span><span class="p">)</span>
          <span class="n">D</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_D</span><span class="p">)</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="p">[</span><span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">d</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">D</span></div>

<div class="viewcode-block" id="AtomicConvolution.gather_neighbors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AtomicConvolution.gather_neighbors">[docs]</a>  <span class="k">def</span> <span class="nf">gather_neighbors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">nbr_indices</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Gathers the neighbor subsets of the atoms in X.</span>

<span class="sd">    B = batch_size, N = max_num_atoms, M = max_num_neighbors, d = num_features</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: tf.Tensor of shape (B, N, d)</span>
<span class="sd">      Coordinates/features tensor.</span>
<span class="sd">    atom_indices: tf.Tensor of shape (B, M)</span>
<span class="sd">      Neighbor list for single atom.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    neighbors: tf.Tensor of shape (B, M, d)</span>
<span class="sd">      Neighbor coordinates/features tensor for single atom.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">example_tensors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">example_nbrs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">nbr_indices</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">all_nbr_coords</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">example</span><span class="p">,</span> <span class="p">(</span><span class="n">example_tensor</span><span class="p">,</span> <span class="n">example_nbr</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
        <span class="nb">zip</span><span class="p">(</span><span class="n">example_tensors</span><span class="p">,</span> <span class="n">example_nbrs</span><span class="p">)):</span>
      <span class="n">nbr_coords</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">example_tensor</span><span class="p">,</span> <span class="n">example_nbr</span><span class="p">)</span>
      <span class="n">all_nbr_coords</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nbr_coords</span><span class="p">)</span>
    <span class="n">neighbors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">all_nbr_coords</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">neighbors</span></div>

<div class="viewcode-block" id="AtomicConvolution.distance_matrix"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AtomicConvolution.distance_matrix">[docs]</a>  <span class="k">def</span> <span class="nf">distance_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">D</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calcuates the distance matrix from the distance tensor</span>

<span class="sd">    B = batch_size, N = max_num_atoms, M = max_num_neighbors, d = num_features</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    D: tf.Tensor of shape (B, N, M, d)</span>
<span class="sd">      Distance tensor.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    R: tf.Tensor of shape (B, N, M)</span>
<span class="sd">       Distance matrix.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">R</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">D</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">R</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">R</span></div></div>


<div class="viewcode-block" id="AlphaShare"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AlphaShare">[docs]</a><span class="k">def</span> <span class="nf">AlphaShare</span><span class="p">(</span><span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  This method should be used when constructing AlphaShare layers from Sluice Networks</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  in_layers: list of Layers or tensors</span>
<span class="sd">    tensors in list must be the same size and list must include two or more tensors</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  output_layers: list of Layers or tensors with same size as in_layers</span>
<span class="sd">    Distance matrix.</span>

<span class="sd">  References:</span>
<span class="sd">  Sluice networks: Learning what to share between loosely related tasks</span>
<span class="sd">  https://arxiv.org/abs/1705.08142</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">output_layers</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">alpha_share</span> <span class="o">=</span> <span class="n">AlphaShareLayer</span><span class="p">(</span><span class="n">in_layers</span><span class="o">=</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="n">num_outputs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
  <span class="k">return</span> <span class="p">[</span><span class="n">LayerSplitter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">alpha_share</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">)]</span></div>


<div class="viewcode-block" id="AlphaShareLayer"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AlphaShareLayer">[docs]</a><span class="k">class</span> <span class="nc">AlphaShareLayer</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Part of a sluice network. Adds alpha parameters to control</span>
<span class="sd">  sharing between the main and auxillary tasks</span>

<span class="sd">  Factory method AlphaShare should be used for construction</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  in_layers: list of Layers or tensors</span>
<span class="sd">    tensors in list must be the same size and list must include two or more tensors</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  out_tensor: a tensor with shape [len(in_layers), x, y] where x, y were the original layer dimensions</span>
<span class="sd">  Distance matrix.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AlphaShareLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="AlphaShareLayer.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AlphaShareLayer.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="c1"># check that there isnt just one or zero inputs</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;AlphaShare must have more than one input&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="c1"># create subspaces</span>
    <span class="n">subspaces</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">original_cols</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
    <span class="n">subspace_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">original_cols</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">input_tensor</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
      <span class="n">subspaces</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">[:,</span> <span class="p">:</span><span class="n">subspace_size</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
      <span class="n">subspaces</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">[:,</span> <span class="n">subspace_size</span><span class="p">:],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">n_alphas</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">subspaces</span><span class="p">)</span>
    <span class="n">subspaces</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">subspaces</span><span class="p">),</span> <span class="p">[</span><span class="n">n_alphas</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># create the alpha learnable parameters</span>
    <span class="n">alphas</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">n_alphas</span><span class="p">,</span> <span class="n">n_alphas</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;alphas&#39;</span><span class="p">)</span>

    <span class="n">subspaces</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">subspaces</span><span class="p">)</span>

    <span class="c1"># concatenate subspaces, reshape to size of original input, then stack</span>
    <span class="c1"># such that out_tensor has shape (2,?,original_cols)</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">tmp_tensor</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_alphas</span><span class="p">):</span>
      <span class="n">tmp_tensor</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">subspaces</span><span class="p">[</span><span class="n">row</span><span class="p">,],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">subspace_size</span><span class="p">]))</span>
      <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">count</span> <span class="o">==</span> <span class="mi">2</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">tmp_tensor</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">tmp_tensor</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span> <span class="o">=</span> <span class="n">alphas</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span></div>

<div class="viewcode-block" id="AlphaShareLayer.none_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AlphaShareLayer.none_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">none_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">num_outputs</span><span class="p">,</span> <span class="n">out_tensor</span><span class="p">,</span> <span class="n">out_tensors</span><span class="p">,</span> <span class="n">alphas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">return</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span><span class="p">,</span> <span class="n">alphas</span></div>

<div class="viewcode-block" id="AlphaShareLayer.set_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.AlphaShareLayer.set_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">set_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_outputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span> <span class="o">=</span> <span class="n">tensor</span></div></div>


<div class="viewcode-block" id="SluiceLoss"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.SluiceLoss">[docs]</a><span class="k">class</span> <span class="nc">SluiceLoss</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Calculates the loss in a Sluice Network</span>
<span class="sd">  Every input into an AlphaShare should be used in SluiceLoss</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">SluiceLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="SluiceLoss.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.SluiceLoss.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">subspaces</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># creates subspaces the same way it was done in AlphaShare</span>
    <span class="k">for</span> <span class="n">input_tensor</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
      <span class="n">subspace_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
      <span class="n">subspaces</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">[:,</span> <span class="p">:</span><span class="n">subspace_size</span><span class="p">])</span>
      <span class="n">subspaces</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">[:,</span> <span class="n">subspace_size</span><span class="p">:])</span>
      <span class="n">product</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">subspaces</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">subspaces</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
      <span class="n">subspaces</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="c1"># calculate squared Frobenius norm</span>
      <span class="n">temp</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">product</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="BetaShare"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.BetaShare">[docs]</a><span class="k">class</span> <span class="nc">BetaShare</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Part of a sluice network. Adds beta params to control which layer</span>
<span class="sd">  outputs are used for prediction</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  in_layers: list of Layers or tensors</span>
<span class="sd">    tensors in list must be the same size and list must include two or more tensors</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  output_layers: list of Layers or tensors with same size as in_layers</span>
<span class="sd">    Distance matrix.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BetaShare</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="BetaShare.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.BetaShare.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Size of input layers must all be the same</span>
<span class="sd">        &quot;&quot;&quot;</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="n">subspaces</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">original_cols</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">input_tensor</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
      <span class="n">subspaces</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">n_betas</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">subspaces</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">subspaces</span><span class="p">),</span> <span class="p">[</span><span class="n">n_betas</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">betas</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_betas</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;betas&#39;</span><span class="p">)</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">betas</span><span class="p">,</span> <span class="n">subspaces</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">betas</span> <span class="o">=</span> <span class="n">betas</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">out_tensor</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">original_cols</span><span class="p">])</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span></div>

<div class="viewcode-block" id="BetaShare.none_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.BetaShare.none_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">none_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">out_tensor</span><span class="p">,</span> <span class="n">betas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">betas</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">betas</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">return</span> <span class="n">out_tensor</span><span class="p">,</span> <span class="n">betas</span></div>

<div class="viewcode-block" id="BetaShare.set_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.BetaShare.set_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">set_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">betas</span> <span class="o">=</span> <span class="n">tensor</span></div></div>


<div class="viewcode-block" id="ANIFeat"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ANIFeat">[docs]</a><span class="k">class</span> <span class="nc">ANIFeat</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Performs transform from 3D coordinates to ANI symmetry functions</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">in_layers</span><span class="p">,</span>
               <span class="n">max_atoms</span><span class="o">=</span><span class="mi">23</span><span class="p">,</span>
               <span class="n">radial_cutoff</span><span class="o">=</span><span class="mf">4.6</span><span class="p">,</span>
               <span class="n">angular_cutoff</span><span class="o">=</span><span class="mf">3.1</span><span class="p">,</span>
               <span class="n">radial_length</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
               <span class="n">angular_length</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
               <span class="n">atom_cases</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span>
               <span class="n">atomic_number_differentiated</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
               <span class="n">coordinates_in_bohr</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Only X can be transformed</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_atoms</span> <span class="o">=</span> <span class="n">max_atoms</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">radial_cutoff</span> <span class="o">=</span> <span class="n">radial_cutoff</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">angular_cutoff</span> <span class="o">=</span> <span class="n">angular_cutoff</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">radial_length</span> <span class="o">=</span> <span class="n">radial_length</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">angular_length</span> <span class="o">=</span> <span class="n">angular_length</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">atom_cases</span> <span class="o">=</span> <span class="n">atom_cases</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">atomic_number_differentiated</span> <span class="o">=</span> <span class="n">atomic_number_differentiated</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">coordinates_in_bohr</span> <span class="o">=</span> <span class="n">coordinates_in_bohr</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ANIFeat</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="ANIFeat.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ANIFeat.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    In layers should be of shape dtype tf.float32, (None, self.max_atoms, 4)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">atom_numbers</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">inputs</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">flags</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">atom_numbers</span><span class="p">)</span>
    <span class="n">flags</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">flags</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">flags</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">coordinates</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">:]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">coordinates_in_bohr</span><span class="p">:</span>
      <span class="n">coordinates</span> <span class="o">=</span> <span class="n">coordinates</span> <span class="o">*</span> <span class="mf">0.52917721092</span>

    <span class="n">d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distance_matrix</span><span class="p">(</span><span class="n">coordinates</span><span class="p">,</span> <span class="n">flags</span><span class="p">)</span>

    <span class="n">d_radial_cutoff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distance_cutoff</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">radial_cutoff</span><span class="p">,</span> <span class="n">flags</span><span class="p">)</span>
    <span class="n">d_angular_cutoff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distance_cutoff</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">angular_cutoff</span><span class="p">,</span> <span class="n">flags</span><span class="p">)</span>

    <span class="n">radial_sym</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">radial_symmetry</span><span class="p">(</span><span class="n">d_radial_cutoff</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">atom_numbers</span><span class="p">)</span>
    <span class="n">angular_sym</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">angular_symmetry</span><span class="p">(</span><span class="n">d_angular_cutoff</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">atom_numbers</span><span class="p">,</span>
                                        <span class="n">coordinates</span><span class="p">)</span>

    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
        <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">atom_numbers</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">radial_sym</span><span class="p">,</span> <span class="n">angular_sym</span><span class="p">],</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>

    <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="ANIFeat.distance_matrix"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ANIFeat.distance_matrix">[docs]</a>  <span class="k">def</span> <span class="nf">distance_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coordinates</span><span class="p">,</span> <span class="n">flags</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Generate distance matrix &quot;&quot;&quot;</span>
    <span class="c1"># (TODO YTZ:) faster, less memory intensive way</span>
    <span class="c1"># r = tf.reduce_sum(tf.square(coordinates), 2)</span>
    <span class="c1"># r = tf.expand_dims(r, -1)</span>
    <span class="c1"># inner = 2*tf.matmul(coordinates, tf.transpose(coordinates, perm=[0,2,1]))</span>
    <span class="c1"># # inner = 2*tf.matmul(coordinates, coordinates, transpose_b=True)</span>

    <span class="c1"># d = r - inner + tf.transpose(r, perm=[0,2,1])</span>
    <span class="c1"># d = tf.nn.relu(d) # fix numerical instabilities about diagonal</span>
    <span class="c1"># d = tf.sqrt(d) # does this have negative elements? may be unstable for diagonals</span>

    <span class="n">max_atoms</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_atoms</span>
    <span class="n">tensor1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">coordinates</span><span class="p">]</span> <span class="o">*</span> <span class="n">max_atoms</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">tensor2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">coordinates</span><span class="p">]</span> <span class="o">*</span> <span class="n">max_atoms</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Calculate pairwise distance</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squared_difference</span><span class="p">(</span><span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-7</span><span class="p">)</span>

    <span class="n">d</span> <span class="o">=</span> <span class="n">d</span> <span class="o">*</span> <span class="n">flags</span>
    <span class="k">return</span> <span class="n">d</span></div>

<div class="viewcode-block" id="ANIFeat.distance_cutoff"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ANIFeat.distance_cutoff">[docs]</a>  <span class="k">def</span> <span class="nf">distance_cutoff</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">cutoff</span><span class="p">,</span> <span class="n">flags</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Generate distance matrix with trainable cutoff &quot;&quot;&quot;</span>
    <span class="c1"># Cutoff with threshold Rc</span>
    <span class="n">d_flag</span> <span class="o">=</span> <span class="n">flags</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">cutoff</span> <span class="o">-</span> <span class="n">d</span><span class="p">)</span>
    <span class="n">d_flag</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">d_flag</span><span class="p">)</span>
    <span class="n">d_flag</span> <span class="o">=</span> <span class="n">d_flag</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_atoms</span><span class="p">)),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">d</span> <span class="o">/</span> <span class="n">cutoff</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">d</span> <span class="o">*</span> <span class="n">d_flag</span></div>
    <span class="c1"># return d</span>

<div class="viewcode-block" id="ANIFeat.radial_symmetry"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ANIFeat.radial_symmetry">[docs]</a>  <span class="k">def</span> <span class="nf">radial_symmetry</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_cutoff</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">atom_numbers</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Radial Symmetry Function &quot;&quot;&quot;</span>
    <span class="n">embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">atom_cases</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">atom_numbers_embedded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">atom_numbers</span><span class="p">)</span>

    <span class="n">Rs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">radial_cutoff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">radial_length</span><span class="p">)</span>
    <span class="n">ita</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">Rs</span><span class="p">)</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">/</span> <span class="p">(</span><span class="n">Rs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Rs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">Rs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Rs</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">ita</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ita</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">length</span> <span class="o">=</span> <span class="n">ita</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">d_cutoff</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">d_cutoff</span><span class="p">]</span> <span class="o">*</span> <span class="n">length</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">d</span><span class="p">]</span> <span class="o">*</span> <span class="n">length</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">ita</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">d</span> <span class="o">-</span> <span class="n">Rs</span><span class="p">))</span> <span class="o">*</span> <span class="n">d_cutoff</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">atomic_number_differentiated</span><span class="p">:</span>
      <span class="n">out_tensors</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">atom_type</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">atom_cases</span><span class="p">:</span>
        <span class="n">selected_atoms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">atom_numbers_embedded</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">atom_type</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">out_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">out</span> <span class="o">*</span> <span class="n">selected_atoms</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">out_tensors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span></div>

<div class="viewcode-block" id="ANIFeat.angular_symmetry"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ANIFeat.angular_symmetry">[docs]</a>  <span class="k">def</span> <span class="nf">angular_symmetry</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_cutoff</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">atom_numbers</span><span class="p">,</span> <span class="n">coordinates</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Angular Symmetry Function &quot;&quot;&quot;</span>

    <span class="n">max_atoms</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_atoms</span>
    <span class="n">embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">atom_cases</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">atom_numbers_embedded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">atom_numbers</span><span class="p">)</span>

    <span class="n">Rs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">angular_cutoff</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">angular_length</span><span class="p">)</span>
    <span class="n">ita</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">/</span> <span class="p">(</span><span class="n">Rs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Rs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">angular_length</span><span class="p">)</span>
    <span class="n">zeta</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">angular_length</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">ita</span><span class="p">,</span> <span class="n">zeta</span><span class="p">,</span> <span class="n">Rs</span><span class="p">,</span> <span class="n">thetas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">ita</span><span class="p">,</span> <span class="n">zeta</span><span class="p">,</span> <span class="n">Rs</span><span class="p">,</span> <span class="n">thetas</span><span class="p">)</span>
    <span class="n">zeta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">zeta</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">ita</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">ita</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">Rs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Rs</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">thetas</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">length</span> <span class="o">=</span> <span class="n">zeta</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># tf.stack issues again...</span>
    <span class="n">vector_distances</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">coordinates</span><span class="p">]</span> <span class="o">*</span> <span class="n">max_atoms</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
        <span class="p">[</span><span class="n">coordinates</span><span class="p">]</span> <span class="o">*</span> <span class="n">max_atoms</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">R_ij</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">d</span><span class="p">]</span> <span class="o">*</span> <span class="n">max_atoms</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">R_ik</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">d</span><span class="p">]</span> <span class="o">*</span> <span class="n">max_atoms</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">f_R_ij</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">d_cutoff</span><span class="p">]</span> <span class="o">*</span> <span class="n">max_atoms</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">f_R_ik</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">d_cutoff</span><span class="p">]</span> <span class="o">*</span> <span class="n">max_atoms</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Define angle theta = arccos(R_ij(Vector) dot R_ik(Vector)/R_ij(distance)/R_ik(distance))</span>
    <span class="n">vector_mul</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">vector_distances</span><span class="p">]</span> <span class="o">*</span> <span class="n">max_atoms</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="o">*</span> \
                               <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">vector_distances</span><span class="p">]</span> <span class="o">*</span> <span class="n">max_atoms</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">vector_mul</span> <span class="o">=</span> <span class="n">vector_mul</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">f_R_ij</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">f_R_ik</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">acos</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">vector_mul</span><span class="p">,</span> <span class="n">R_ij</span> <span class="o">*</span> <span class="n">R_ik</span> <span class="o">+</span> <span class="mf">1e-5</span><span class="p">))</span>

    <span class="n">R_ij</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">R_ij</span><span class="p">]</span> <span class="o">*</span> <span class="n">length</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">R_ik</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">R_ik</span><span class="p">]</span> <span class="o">*</span> <span class="n">length</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">f_R_ij</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">f_R_ij</span><span class="p">]</span> <span class="o">*</span> <span class="n">length</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">f_R_ik</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">f_R_ik</span><span class="p">]</span> <span class="o">*</span> <span class="n">length</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">theta</span><span class="p">]</span> <span class="o">*</span> <span class="n">length</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">((</span><span class="mf">1.</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span> <span class="o">-</span> <span class="n">thetas</span><span class="p">))</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">,</span> <span class="n">zeta</span><span class="p">)</span> <span class="o">*</span> \
                 <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">ita</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">((</span><span class="n">R_ij</span> <span class="o">+</span> <span class="n">R_ik</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.</span> <span class="o">-</span> <span class="n">Rs</span><span class="p">))</span> <span class="o">*</span> <span class="n">f_R_ij</span> <span class="o">*</span> <span class="n">f_R_ik</span> <span class="o">*</span> <span class="mi">2</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">atomic_number_differentiated</span><span class="p">:</span>
      <span class="n">out_tensors</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">id_j</span><span class="p">,</span> <span class="n">atom_type_j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">atom_cases</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">atom_type_k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">atom_cases</span><span class="p">[</span><span class="n">id_j</span><span class="p">:]:</span>
          <span class="n">selected_atoms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">atom_numbers_embedded</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">atom_type_j</span><span class="p">]]</span> <span class="o">*</span> <span class="n">max_atoms</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> \
                           <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">atom_numbers_embedded</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">atom_type_k</span><span class="p">]]</span> <span class="o">*</span> <span class="n">max_atoms</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
          <span class="n">selected_atoms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">selected_atoms</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
          <span class="n">out_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">out_tensor</span> <span class="o">*</span> <span class="n">selected_atoms</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">out_tensors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">out_tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span></div>

<div class="viewcode-block" id="ANIFeat.get_num_feats"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.ANIFeat.get_num_feats">[docs]</a>  <span class="k">def</span> <span class="nf">get_num_feats</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">n_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">n_feat</span></div></div>


<div class="viewcode-block" id="LayerSplitter"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.LayerSplitter">[docs]</a><span class="k">class</span> <span class="nc">LayerSplitter</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Layer which takes a tensor from in_tensor[0].out_tensors at an index</span>
<span class="sd">  Only layers which need to output multiple layers set and use the variable</span>
<span class="sd">  self.out_tensors.</span>
<span class="sd">  This is a utility for those special layers which set self.out_tensors</span>
<span class="sd">  to return a layer wrapping a specific tensor in in_layers[0].out_tensors</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_num</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    output_num: int</span>
<span class="sd">      The index which to use as this layers out_tensor from in_layers[0]</span>
<span class="sd">    kwargs</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_num</span> <span class="o">=</span> <span class="n">output_num</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">LayerSplitter</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="LayerSplitter.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.LayerSplitter.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">out_tensors</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_num</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">out_tensor</span>
    <span class="k">return</span> <span class="n">out_tensor</span></div></div>


<div class="viewcode-block" id="GraphEmbedPoolLayer"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphEmbedPoolLayer">[docs]</a><span class="k">class</span> <span class="nc">GraphEmbedPoolLayer</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  GraphCNNPool Layer from Robust Spatial Filtering with Graph Convolutional Neural Networks</span>
<span class="sd">  https://arxiv.org/abs/1703.00792</span>

<span class="sd">  This is a learnable pool operation</span>
<span class="sd">  It constructs a new adjacency matrix for a graph of specified number of nodes.</span>

<span class="sd">  This differs from our other pool opertions which set vertices to a function value</span>
<span class="sd">  without altering the adjacency matrix.</span>

<span class="sd">  $V_{emb} = SpatialGraphCNN({V_{in}})$\\</span>
<span class="sd">  $V_{out} = \sigma(V_{emb})^{T} * V_{in}$</span>
<span class="sd">  $A_{out} = V_{emb}^{T} * A_{in} * V_{emb}$</span>

<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_vertices</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_vertices</span> <span class="o">=</span> <span class="n">num_vertices</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">GraphEmbedPoolLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="GraphEmbedPoolLayer.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphEmbedPoolLayer.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    num_filters: int</span>
<span class="sd">      Number of filters to have in the output</span>

<span class="sd">    in_layers: list of Layers or tensors</span>
<span class="sd">      [V, A, mask]</span>
<span class="sd">      V are the vertex features must be of shape (batch, vertex, channel)</span>

<span class="sd">      A are the adjacency matrixes for each graph</span>
<span class="sd">        Shape (batch, from_vertex, adj_matrix, to_vertex)</span>

<span class="sd">      mask is optional, to be used when not every graph has the</span>
<span class="sd">      same number of vertices</span>

<span class="sd">    Returns: tf.tensor</span>
<span class="sd">    Returns a tf.tensor with a graph convolution applied</span>
<span class="sd">    The shape will be (batch, vertex, self.num_filters)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">in_tensors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_tensors</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
      <span class="n">V</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">in_tensors</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">V</span><span class="p">,</span> <span class="n">A</span> <span class="o">=</span> <span class="n">in_tensors</span>
      <span class="n">mask</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">factors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_factors</span><span class="p">(</span>
        <span class="n">V</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_vertices</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_Factors&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">factors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">factors</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
    <span class="n">factors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax_factors</span><span class="p">(</span><span class="n">factors</span><span class="p">)</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">factors</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="n">result_A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">A</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">A</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">result_A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">result_A</span><span class="p">,</span> <span class="n">factors</span><span class="p">)</span>
    <span class="n">result_A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">result_A</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">A</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">A</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">result_A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">factors</span><span class="p">,</span> <span class="n">result_A</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">result_A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">result_A</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">A</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_vertices</span><span class="p">,</span>
                                     <span class="n">A</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_vertices</span><span class="p">))</span>
    <span class="c1"># We do not need the mask because every graph has self.num_vertices vertices now</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">result</span><span class="p">,</span> <span class="n">result_A</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">result</span><span class="p">,</span> <span class="n">result_A</span></div>

<div class="viewcode-block" id="GraphEmbedPoolLayer.embedding_factors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphEmbedPoolLayer.embedding_factors">[docs]</a>  <span class="k">def</span> <span class="nf">embedding_factors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">no_filters</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">):</span>
    <span class="n">no_features</span> <span class="o">=</span> <span class="n">V</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
        <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_weights&#39;</span> <span class="o">%</span> <span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">no_features</span><span class="p">,</span> <span class="n">no_filters</span><span class="p">],</span>
        <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span>
            <span class="n">stddev</span><span class="o">=</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">no_features</span><span class="p">)),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
        <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_bias&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">no_filters</span><span class="p">],</span>
        <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">V_reshape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">no_features</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">V</span><span class="p">),</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">V</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">s</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">no_filters</span><span class="p">])],</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">V_reshape</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="GraphEmbedPoolLayer.softmax_factors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphEmbedPoolLayer.softmax_factors">[docs]</a>  <span class="k">def</span> <span class="nf">softmax_factors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">max_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">exp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">max_value</span><span class="p">))</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">exp</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">exp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">prob</span></div>

<div class="viewcode-block" id="GraphEmbedPoolLayer.none_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphEmbedPoolLayer.none_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">none_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">out_tensors</span><span class="p">,</span> <span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">return</span> <span class="n">out_tensors</span><span class="p">,</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="GraphEmbedPoolLayer.set_tensors"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphEmbedPoolLayer.set_tensors">[docs]</a>  <span class="k">def</span> <span class="nf">set_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_tensors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">tensor</span></div></div>


<div class="viewcode-block" id="GraphCNNPool"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphCNNPool">[docs]</a><span class="k">def</span> <span class="nf">GraphCNNPool</span><span class="p">(</span><span class="n">num_vertices</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="n">gcnnpool_layer</span> <span class="o">=</span> <span class="n">GraphEmbedPoolLayer</span><span class="p">(</span><span class="n">num_vertices</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="k">return</span> <span class="p">[</span><span class="n">LayerSplitter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">gcnnpool_layer</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)]</span></div>


<div class="viewcode-block" id="GraphCNN"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphCNN">[docs]</a><span class="k">class</span> <span class="nc">GraphCNN</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  GraphCNN Layer from Robust Spatial Filtering with Graph Convolutional Neural Networks</span>
<span class="sd">  https://arxiv.org/abs/1703.00792</span>

<span class="sd">  Spatial-domain convolutions can be defined as</span>
<span class="sd">  H = h_0I + h_1A + h_2A^2 + ... + hkAk, H ∈ R**(N×N)</span>

<span class="sd">  We approximate it by</span>
<span class="sd">  H ≈ h_0I + h_1A</span>

<span class="sd">  We can define a convolution as applying multiple these linear filters</span>
<span class="sd">  over edges of different types (think up, down, left, right, diagonal in images)</span>
<span class="sd">  Where each edge type has its own adjacency matrix</span>
<span class="sd">  H ≈ h_0I + h_1A_1 + h_2A_2 + . . . h_(L−1)A_(L−1)</span>

<span class="sd">  V_out = \sum_{c=1}^{C} H^{c} V^{c} + b</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_filters</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    num_filters: int</span>
<span class="sd">      Number of filters to have in the output</span>

<span class="sd">    in_layers: list of Layers or tensors</span>
<span class="sd">      [V, A, mask]</span>
<span class="sd">      V are the vertex features must be of shape (batch, vertex, channel)</span>

<span class="sd">      A are the adjacency matrixes for each graph</span>
<span class="sd">        Shape (batch, from_vertex, adj_matrix, to_vertex)</span>

<span class="sd">      mask is optional, to be used when not every graph has the</span>
<span class="sd">      same number of vertices</span>

<span class="sd">    Returns: tf.tensor</span>
<span class="sd">    Returns a tf.tensor with a graph convolution applied</span>
<span class="sd">    The shape will be (batch, vertex, self.num_filters)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_filters</span> <span class="o">=</span> <span class="n">num_filters</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">GraphCNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="GraphCNN.create_tensor"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphCNN.create_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">create_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">set_tensors</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_input_tensors</span><span class="p">(</span><span class="n">in_layers</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
      <span class="n">V</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">inputs</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">V</span><span class="p">,</span> <span class="n">A</span> <span class="o">=</span> <span class="n">inputs</span>
    <span class="n">no_A</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
    <span class="n">no_features</span> <span class="o">=</span> <span class="n">V</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
        <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_weights&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">no_features</span> <span class="o">*</span> <span class="n">no_A</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_filters</span><span class="p">],</span>
        <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span>
            <span class="n">stddev</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">no_features</span> <span class="o">*</span> <span class="p">(</span><span class="n">no_A</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">))),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">W_I</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
        <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_weights_I&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="n">no_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_filters</span><span class="p">],</span>
        <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span>
            <span class="n">stddev</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">no_features</span> <span class="o">*</span> <span class="p">(</span><span class="n">no_A</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">))),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
        <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_bias&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_filters</span><span class="p">],</span>
        <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graphConvolution</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
    <span class="n">A_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">A_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">no_A</span> <span class="o">*</span> <span class="n">no_features</span><span class="p">])</span>
    <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_mat_mult</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_mat_mult</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">W_I</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
    <span class="k">if</span> <span class="n">set_tensors</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">out_tensor</span> <span class="o">=</span> <span class="n">result</span>
    <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="GraphCNN.graphConvolution"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphCNN.graphConvolution">[docs]</a>  <span class="k">def</span> <span class="nf">graphConvolution</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">A</span><span class="p">):</span>
    <span class="n">no_A</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
    <span class="n">no_features</span> <span class="o">=</span> <span class="n">V</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>

    <span class="n">A_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="n">A_reshape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">A_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">no_A</span><span class="p">,</span> <span class="n">A_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A_reshape</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">A_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">no_A</span><span class="p">,</span> <span class="n">no_features</span><span class="p">])</span></div>

<div class="viewcode-block" id="GraphCNN.batch_mat_mult"><a class="viewcode-back" href="../../../../deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.IRV.GraphCNN.batch_mat_mult">[docs]</a>  <span class="k">def</span> <span class="nf">batch_mat_mult</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">):</span>
    <span class="n">A_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="n">A_reshape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">A_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>

    <span class="c1"># So the Tensor has known dimensions</span>
    <span class="k">if</span> <span class="n">B</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">axis_2</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">axis_2</span> <span class="o">=</span> <span class="n">B</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A_reshape</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">A_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">A_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis_2</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">result</span></div></div>
</pre></div>

    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
      
    </p>
    <p>
        &copy; Copyright 2016, Stanford University and the Authors.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>