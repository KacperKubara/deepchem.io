<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

    <title>deepchem package &mdash; deepchem 1.3.1 documentation</title>

    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.3.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="deepchem 1.3.1 documentation" href="index.html" />
    <link rel="next" title="deepchem.data package" href="deepchem.data.html" />
    <link rel="prev" title="DeepChem" href="index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-inverse navbar-default ">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html"><span><img src="_static/logo.png"></span>
          deepchem</a>
        <span class="navbar-text navbar-version pull-left"><b>1.3.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">

                <li><a href="/docs/notebooks/index.html">Tutorials</a></li>


              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="/docs/deepchem.html">master</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="/docs/2.0.0/deepchem.html">2.0.0</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="/docs/1.3.1/deepchem.html">1.3.1</a></li>
</ul>
</ul>
</li>
</ul>
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>

        </div>
    </div>
  </div>    </div>
  </div>  </div><div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="deepchem-models-tensorgraph-models-package">
<h1>deepchem.models.tensorgraph.models package<a class="headerlink" href="#deepchem-models-tensorgraph-models-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.atomic_conv">
<span id="deepchem-models-tensorgraph-models-atomic-conv-module"></span><h2>deepchem.models.tensorgraph.models.atomic_conv module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.atomic_conv" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.atomic_conv.</code><code class="descname">AtomicConvScore</code><span class="sig-paren">(</span><em>atom_types</em>, <em>layer_sizes</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/atomic_conv.html#AtomicConvScore"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.layers.Layer" title="deepchem.models.tensorgraph.layers.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.layers.Layer</span></code></a></p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.add_summary_to_tg">
<code class="descname">add_summary_to_tg</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.add_summary_to_tg" title="Permalink to this definition">¶</a></dt>
<dd><p>Can only be called after self.create_layer to gaurentee that name is not none</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.clone">
<code class="descname">clone</code><span class="sig-paren">(</span><em>in_layers</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.clone" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of this layer with different inputs.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.copy">
<code class="descname">copy</code><span class="sig-paren">(</span><em>replacements={}</em>, <em>variables_graph=None</em>, <em>shared=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Duplicate this Layer and all its inputs.</p>
<p>This is similar to clone(), but instead of only cloning one layer, it also
recursively calls copy() on all of this layer&#8217;s inputs to clone the entire
hierarchy of layers.  In the process, you can optionally tell it to replace
particular layers with specific existing ones.  For example, you can clone a
stack of layers, while connecting the topmost ones to different inputs.</p>
<p>For example, consider a stack of dense layers that depend on an input:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense3</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense2</span><span class="p">)</span>
</pre></div>
</div>
<p>The following will clone all three dense layers, but not the input layer.
Instead, the input to the first dense layer will be a different layer
specified in the replacements map.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">replacements</span> <span class="o">=</span> <span class="p">{</span><span class="nb">input</span><span class="p">:</span> <span class="n">new_input</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense3_copy</span> <span class="o">=</span> <span class="n">dense3</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">replacements</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>replacements</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#map" title="(in Python v3.6)"><em>map</em></a>) &#8211; specifies existing layers, and the layers to replace them with (instead of
cloning them).  This argument serves two purposes.  First, you can pass in
a list of replacements to control which layers get cloned.  In addition,
as each layer is cloned, it is added to this map.  On exit, it therefore
contains a complete record of all layers that were copied, and a reference
to the copy of each one.</li>
<li><strong>variables_graph</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><em>TensorGraph</em></a>) &#8211; an optional TensorGraph from which to take variables.  If this is specified,
the current value of each variable in each layer is recorded, and the copy
has that value specified as its initial value.  This allows a piece of a
pre-trained model to be copied to another model.</li>
<li><strong>shared</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, create new layers by calling shared() on the input layers.
This means the newly created layers will share variables with the original
ones.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.create_tensor">
<code class="descname">create_tensor</code><span class="sig-paren">(</span><em>in_layers=None</em>, <em>set_tensors=True</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/atomic_conv.html#AtomicConvScore.create_tensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.create_tensor" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.layer_number_dict">
<code class="descname">layer_number_dict</code><em class="property"> = {}</em><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.layer_number_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.none_tensors">
<code class="descname">none_tensors</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.none_tensors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_summary">
<code class="descname">set_summary</code><span class="sig-paren">(</span><em>summary_op</em>, <em>summary_description=None</em>, <em>collections=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Annotates a tensor with a tf.summary operation
Collects data from self.out_tensor by default but can be changed by setting
self.tb_input to another tensor in create_tensor</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>summary_op</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) &#8211; summary operation to annotate node</li>
<li><strong>summary_description</strong> (<em>object, optional</em>) &#8211; Optional summary_pb2.SummaryDescription()</li>
<li><strong>collections</strong> (<em>list of graph collections keys, optional</em>) &#8211; New summary op is added to these collections. Defaults to [GraphKeys.SUMMARIES]</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_tensors">
<code class="descname">set_tensors</code><span class="sig-paren">(</span><em>tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_tensors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_variable_initial_values">
<code class="descname">set_variable_initial_values</code><span class="sig-paren">(</span><em>values</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_variable_initial_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the initial values of all variables.</p>
<p>This takes a list, which contains the initial values to use for all of
this layer&#8217;s values (in the same order retured by
TensorGraph.get_layer_variables()).  When this layer is used in a
TensorGraph, it will automatically initialize each variable to the value
specified in the list.  Note that some layers also have separate mechanisms
for specifying variable initializers; this method overrides them. The
purpose of this method is to let a Layer object represent a pre-trained
layer, complete with trained values for its variables.</p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.shape">
<code class="descname">shape</code><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shape of this Layer&#8217;s output.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.shared">
<code class="descname">shared</code><span class="sig-paren">(</span><em>in_layers</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.shared" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of this layer that shares variables with it.</p>
<p>This is similar to clone(), but where clone() creates two independent layers,
this causes the layers to share variables with each other.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>in_layers</strong> (<em>list tensor</em>) &#8211; </li>
<li><strong>in tensors for the shared layer</strong> (<em>List</em>) &#8211; </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer">Layer</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.InitializeWeightsBiases">
<code class="descclassname">deepchem.models.tensorgraph.models.atomic_conv.</code><code class="descname">InitializeWeightsBiases</code><span class="sig-paren">(</span><em>prev_layer_size</em>, <em>size</em>, <em>weights=None</em>, <em>biases=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/atomic_conv.html#InitializeWeightsBiases"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.InitializeWeightsBiases" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes weights and biases to be used in a fully-connected layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>prev_layer_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; Number of features in previous layer.</li>
<li><strong>size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; Number of nodes in this layer.</li>
<li><strong>weights</strong> (<em>tf.Tensor, optional (Default None)</em>) &#8211; Weight tensor.</li>
<li><strong>biases</strong> (<em>tf.Tensor, optional (Default None)</em>) &#8211; Bias tensor.</li>
<li><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) &#8211; Name for this op, optional (Defaults to &#8216;fully_connected&#8217; if None)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>weights</strong> (<em>tf.Variable</em>) &#8211;
Initialized weights.</li>
<li><strong>biases</strong> (<em>tf.Variable</em>) &#8211;
Initialized biases.</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.atomic_conv_model">
<code class="descclassname">deepchem.models.tensorgraph.models.atomic_conv.</code><code class="descname">atomic_conv_model</code><span class="sig-paren">(</span><em>frag1_num_atoms=70, frag2_num_atoms=634, complex_num_atoms=701, max_num_neighbors=12, batch_size=24, at=[6, 7.0, 8.0, 9.0, 11.0, 12.0, 15.0, 16.0, 17.0, 20.0, 25.0, 30.0, 35.0, 53.0, -1.0], radial=[[1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0, 10.5, 11.0, 11.5, 12.0], [0.0, 4.0, 8.0], [0.4]], layer_sizes=[32, 32, 16], learning_rate=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/atomic_conv.html#atomic_conv_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.atomic_conv_model" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.gan">
<span id="deepchem-models-tensorgraph-models-gan-module"></span><h2>deepchem.models.tensorgraph.models.gan module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.gan" title="Permalink to this headline">¶</a></h2>
<p>Generative Adversarial Networks.</p>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.gan.GAN">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.gan.</code><code class="descname">GAN</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p>Implements Generative Adversarial Networks.</p>
<p>A Generative Adversarial Network (GAN) is a type of generative model.  It
consists of two parts called the &#8220;generator&#8221; and the &#8220;discriminator&#8221;.  The
generator takes random noise as input and transforms it into an output that
(hopefully) resembles the training data.  The discriminator takes a set of
samples as input and tries to distinguish the real training samples from the
ones created by the generator.  Both of them are trained together.  The
discriminator tries to get better and better at telling real from false data,
while the generator tries to get better and better at fooling the discriminator.</p>
<p>In many cases there also are additional inputs to the generator and
discriminator.  In that case it is known as a Conditional GAN (CGAN), since it
learns a distribution that is conditional on the values of those inputs.  They
are referred to as &#8220;conditional inputs&#8221;.</p>
<p>Many variations on this idea have been proposed, and new varieties of GANs are
constantly being proposed.  This class tries to make it very easy to implement
straightforward GANs of the most conventional types.  At the same time, it
tries to be flexible enough that it can be used to implement many (but
certainly not all) variations on the concept.</p>
<p>To define a GAN, you must create a subclass that provides implementations of
the following methods:</p>
<p>get_noise_input_shape()
get_data_input_shapes()
create_generator()
create_discriminator()</p>
<p>If you want your GAN to have any conditional inputs you must also implement:</p>
<p>get_conditional_input_shapes()</p>
<p>The following methods have default implementations that are suitable for most
conventional GANs.  You can override them if you want to customize their
behavior:</p>
<p>create_generator_loss()
create_discriminator_loss()
get_noise_batch()</p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.create_discriminator">
<code class="descname">create_discriminator</code><span class="sig-paren">(</span><em>data_inputs</em>, <em>conditional_inputs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.create_discriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.create_discriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the discriminator.</p>
<p>Subclasses must override this to construct the discriminator and return its
output layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data_inputs</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the Input layers from which the discriminator can read the input data.
The number and shapes of these inputs will match the return value from
get_data_input_shapes().  The samples read from these layers may be either
training data or generated data.</li>
<li><strong>conditional_inputs</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the Input layers for any conditional inputs to the network.  The number
and shapes of these inputs will match the return value from
get_conditional_input_shapes().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>A Layer object that outputs the probability of each sample being a training</em></li>
<li><em>sample.  The shape of this layer must be [None].  That is, it must output a</em></li>
<li><em>one dimensional tensor whose length equals the batch size.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.create_discriminator_loss">
<code class="descname">create_discriminator_loss</code><span class="sig-paren">(</span><em>discrim_output_train</em>, <em>discrim_output_gen</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.create_discriminator_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.create_discriminator_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the loss function for the discriminator.</p>
<p>The default implementation is appropriate for most cases.  Subclasses can
override this if the need to customize it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>discrim_output_train</strong> (<a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><em>Layer</em></a>) &#8211; the output from the discriminator on a batch of generated data.  This is
its estimate of the probability that each sample is training data.</li>
<li><strong>discrim_output_gen</strong> (<a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><em>Layer</em></a>) &#8211; the output from the discriminator on a batch of training data.  This is
its estimate of the probability that each sample is training data.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>A Layer object that outputs the loss function to use for optimizing the</em></li>
<li><em>discriminator.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.create_generator">
<code class="descname">create_generator</code><span class="sig-paren">(</span><em>noise_input</em>, <em>conditional_inputs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.create_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.create_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the generator.</p>
<p>Subclasses must override this to construct the generator and return its
output layers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>noise_input</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.layers.Input" title="deepchem.models.tensorgraph.layers.Input"><em>Input</em></a>) &#8211; the Input layer from which the generator can read random noise.  The shape
will match the return value from get_noise_input_shape().</li>
<li><strong>conditional_inputs</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the Input layers for any conditional inputs to the network.  The number
and shapes of these inputs will match the return value from
get_conditional_input_shapes().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>A list of Layer objects that produce the generator&#8217;s outputs.  The number and</em></li>
<li><em>shapes of these layers must match the return value from get_data_input_shapes(),</em></li>
<li><em>since generated data must have the same form as training data.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.create_generator_loss">
<code class="descname">create_generator_loss</code><span class="sig-paren">(</span><em>discrim_output</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.create_generator_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.create_generator_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the loss function for the generator.</p>
<p>The default implementation is appropriate for most cases.  Subclasses can
override this if the need to customize it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>discrim_output</strong> (<a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><em>Layer</em></a>) &#8211; the output from the discriminator on a batch of generated data.  This is
its estimate of the probability that each sample is training data.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>A Layer object that outputs the loss function to use for optimizing the</em></li>
<li><em>generator.</em></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>layers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the list of layers to train.  If None, all layers in the model will be
trained.</li>
<li><strong>loss</strong> (<a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><em>Layer</em></a>) &#8211; the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</li>
<li><strong>optimizer</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.optimizers.Optimizer" title="deepchem.models.tensorgraph.optimizers.Optimizer"><em>Optimizer</em></a>) &#8211; the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>the newly created submodel, which can be passed to any of the fitting</em></li>
<li><em>methods.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset object.</li>
<li><strong>metric</strong> (<a class="reference internal" href="deepchem.metrics.html#deepchem.metrics.Metric" title="deepchem.metrics.Metric"><em>deepchem.metrics.Metric</em></a>) &#8211; Evaluation metric</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of deepchem.transformers.Transformer</li>
<li><strong>per_task_metrics</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; If True, return per-task scores.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Maps tasks to scores under metric.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.6)">dict</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<a class="reference internal" href="deepchem.data.html#deepchem.data.datasets.Dataset" title="deepchem.data.datasets.Dataset"><em>Dataset</em></a>) &#8211; the Dataset to train on</li>
<li><strong>nb_epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of epochs to train for</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>deterministic</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.fit_gan">
<code class="descname">fit_gan</code><span class="sig-paren">(</span><em>batches</em>, <em>generator_steps=1.0</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.fit_gan"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.fit_gan" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>batches</strong> (<em>iterable</em>) &#8211; batches of data to train the discriminator on, each represented as a dict
that maps Layers to values.  It should specify values for all members of
data_inputs and conditional_inputs.</li>
<li><strong>generator_steps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) &#8211; the number of training steps to perform for the generator for each batch.
This can be used to adjust the ratio of training steps for the generator
and discriminator.  For example, 2.0 will perform two training steps for
every batch, while 0.5 will only perform one training step for every two
batches.</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in batches.  Set
this to 0 to disable automatic checkpointing.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint before training
it.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>feed_dict_generator</strong> (<em>generator</em>) &#8211; this should generate batches, each represented as a dict that maps
Layers to values.</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_conditional_input_shapes">
<code class="descname">get_conditional_input_shapes</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.get_conditional_input_shapes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_conditional_input_shapes" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shapes of any conditional inputs.</p>
<p>Subclasses may override this to return a list of tuples, each giving the
shape of one of the conditional inputs.  The actual Input layers will be
created automatically.  The first dimension of each shape must be None,
since it will correspond to the batch size.</p>
<p>The default implementation returns an empty list, meaning there are no
conditional inputs.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_data_input_shapes">
<code class="descname">get_data_input_shapes</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.get_data_input_shapes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_data_input_shapes" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shapes of the inputs for training data.</p>
<p>Subclasses must override this to return a list of tuples, each giving the
shape of one of the inputs.  The actual Input layers will be created
automatically.  This list of shapes must also match the shapes of the
generator&#8217;s outputs.  The first dimension of each shape must be None, since
it will correspond to the batch size.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_noise_batch">
<code class="descname">get_noise_batch</code><span class="sig-paren">(</span><em>batch_size</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.get_noise_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_noise_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a batch of random noise to pass to the generator.</p>
<p>This should return a NumPy array whose shape matches the one returned by
get_noise_input_shape().  The default implementation returns normally
distributed values.  Subclasses can override this to implement a different
distribution.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_noise_input_shape">
<code class="descname">get_noise_input_shape</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.get_noise_input_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_noise_input_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shape of the generator&#8217;s noise input layer.</p>
<p>Subclasses must override this to return a tuple giving the shape of the
noise input.  The actual Input layer will be created automatically.  The
first dimension must be None, since it will correspond to the batch size.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> (<em>boolean, optional</em>) &#8211; If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong> &#8211;
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">mapping of string to any</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>results</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.predict_gan_generator">
<code class="descname">predict_gan_generator</code><span class="sig-paren">(</span><em>batch_size=1</em>, <em>noise_input=None</em>, <em>conditional_inputs=[]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.predict_gan_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_gan_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the GAN to generate a batch of samples.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of samples to generate.  If either noise_input or
conditional_inputs is specified, this argument is ignored since the batch
size is then determined by the size of that argument.</li>
<li><strong>noise_input</strong> (<a class="reference external" href="https://docs.python.org/library/array.html#module-array" title="(in Python v3.6)"><em>array</em></a>) &#8211; the value to use for the generator&#8217;s noise input.  If None (the default),
get_noise_batch() is called to generate a random input, so each call will
produce a new set of samples.</li>
<li><strong>conditional_inputs</strong> (<em>list of arrays</em>) &#8211; the values to use for all conditional inputs.  This must be specified if
the GAN has any conditional inputs.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>An array (if the generator has only one output) or list of arrays (if it has</em></li>
<li><em>multiple outputs) containing the generated samples.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>generator</strong> (<em>Generator</em>) &#8211; Generator that constructs feed dictionaries for TensorGraph.</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
<li><strong>Returns</strong> &#8211; y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">numpy ndarray of shape (n_samples, n_classes*n_tasks)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">y_pred</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.gan.</code><code class="descname">GradientPenaltyLayer</code><span class="sig-paren">(</span><em>discrim_output_train</em>, <em>gan</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GradientPenaltyLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.layers.Layer" title="deepchem.models.tensorgraph.layers.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.layers.Layer</span></code></a></p>
<p>Implements the gradient penalty loss term for WGANs.</p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.add_summary_to_tg">
<code class="descname">add_summary_to_tg</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.add_summary_to_tg" title="Permalink to this definition">¶</a></dt>
<dd><p>Can only be called after self.create_layer to gaurentee that name is not none</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.clone">
<code class="descname">clone</code><span class="sig-paren">(</span><em>in_layers</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.clone" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of this layer with different inputs.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.copy">
<code class="descname">copy</code><span class="sig-paren">(</span><em>replacements={}</em>, <em>variables_graph=None</em>, <em>shared=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Duplicate this Layer and all its inputs.</p>
<p>This is similar to clone(), but instead of only cloning one layer, it also
recursively calls copy() on all of this layer&#8217;s inputs to clone the entire
hierarchy of layers.  In the process, you can optionally tell it to replace
particular layers with specific existing ones.  For example, you can clone a
stack of layers, while connecting the topmost ones to different inputs.</p>
<p>For example, consider a stack of dense layers that depend on an input:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense3</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense2</span><span class="p">)</span>
</pre></div>
</div>
<p>The following will clone all three dense layers, but not the input layer.
Instead, the input to the first dense layer will be a different layer
specified in the replacements map.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">replacements</span> <span class="o">=</span> <span class="p">{</span><span class="nb">input</span><span class="p">:</span> <span class="n">new_input</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense3_copy</span> <span class="o">=</span> <span class="n">dense3</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">replacements</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>replacements</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#map" title="(in Python v3.6)"><em>map</em></a>) &#8211; specifies existing layers, and the layers to replace them with (instead of
cloning them).  This argument serves two purposes.  First, you can pass in
a list of replacements to control which layers get cloned.  In addition,
as each layer is cloned, it is added to this map.  On exit, it therefore
contains a complete record of all layers that were copied, and a reference
to the copy of each one.</li>
<li><strong>variables_graph</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><em>TensorGraph</em></a>) &#8211; an optional TensorGraph from which to take variables.  If this is specified,
the current value of each variable in each layer is recorded, and the copy
has that value specified as its initial value.  This allows a piece of a
pre-trained model to be copied to another model.</li>
<li><strong>shared</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, create new layers by calling shared() on the input layers.
This means the newly created layers will share variables with the original
ones.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.create_tensor">
<code class="descname">create_tensor</code><span class="sig-paren">(</span><em>in_layers=None</em>, <em>set_tensors=True</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GradientPenaltyLayer.create_tensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.create_tensor" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.layer_number_dict">
<code class="descname">layer_number_dict</code><em class="property"> = {}</em><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.layer_number_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.none_tensors">
<code class="descname">none_tensors</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.none_tensors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_summary">
<code class="descname">set_summary</code><span class="sig-paren">(</span><em>summary_op</em>, <em>summary_description=None</em>, <em>collections=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Annotates a tensor with a tf.summary operation
Collects data from self.out_tensor by default but can be changed by setting
self.tb_input to another tensor in create_tensor</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>summary_op</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) &#8211; summary operation to annotate node</li>
<li><strong>summary_description</strong> (<em>object, optional</em>) &#8211; Optional summary_pb2.SummaryDescription()</li>
<li><strong>collections</strong> (<em>list of graph collections keys, optional</em>) &#8211; New summary op is added to these collections. Defaults to [GraphKeys.SUMMARIES]</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_tensors">
<code class="descname">set_tensors</code><span class="sig-paren">(</span><em>tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_tensors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_variable_initial_values">
<code class="descname">set_variable_initial_values</code><span class="sig-paren">(</span><em>values</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_variable_initial_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the initial values of all variables.</p>
<p>This takes a list, which contains the initial values to use for all of
this layer&#8217;s values (in the same order retured by
TensorGraph.get_layer_variables()).  When this layer is used in a
TensorGraph, it will automatically initialize each variable to the value
specified in the list.  Note that some layers also have separate mechanisms
for specifying variable initializers; this method overrides them. The
purpose of this method is to let a Layer object represent a pre-trained
layer, complete with trained values for its variables.</p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.shape">
<code class="descname">shape</code><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shape of this Layer&#8217;s output.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.shared">
<code class="descname">shared</code><span class="sig-paren">(</span><em>in_layers</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.shared" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of this layer that shares variables with it.</p>
<p>This is similar to clone(), but where clone() creates two independent layers,
this causes the layers to share variables with each other.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>in_layers</strong> (<em>list tensor</em>) &#8211; </li>
<li><strong>in tensors for the shared layer</strong> (<em>List</em>) &#8211; </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer">Layer</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.gan.</code><code class="descname">WGAN</code><span class="sig-paren">(</span><em>gradient_penalty=10.0</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#WGAN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN" title="deepchem.models.tensorgraph.models.gan.GAN"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.models.gan.GAN</span></code></a></p>
<p>Implements Wasserstein Generative Adversarial Networks.</p>
<p>This class implements Wasserstein Generative Adversarial Networks (WGANs) as
described in Arjovsky et al., &#8220;Wasserstein GAN&#8221; (<a class="reference external" href="https://arxiv.org/abs/1701.07875">https://arxiv.org/abs/1701.07875</a>).
A WGAN is conceptually rather different from a conventional GAN, but in
practical terms very similar.  It reinterprets the discriminator (often called
the &#8220;critic&#8221; in this context) as learning an approximation to the Earth Mover
distance between the training and generated distributions.  The generator is
then trained to minimize that distance.  In practice, this just means using
slightly different loss functions for training the generator and discriminator.</p>
<p>WGANs have theoretical advantages over conventional GANs, and they often work
better in practice.  In addition, the discriminator&#8217;s loss function can be
directly interpreted as a measure of the quality of the model.  That is an
advantage over conventional GANs, where the loss does not directly convey
information about the quality of the model.</p>
<p>The theory WGANs are based on requires the discriminator&#8217;s gradient to be
bounded.  The original paper achieved this by clipping its weights.  This
class instead does it by adding a penalty term to the discriminator&#8217;s loss, as
described in <a class="reference external" href="https://arxiv.org/abs/1704.00028">https://arxiv.org/abs/1704.00028</a>.  This is sometimes found to
produce better results.</p>
<p>There are a few other practical differences between GANs and WGANs.  In a
conventional GAN, the discriminator&#8217;s output must be between 0 and 1 so it can
be interpreted as a probability.  In a WGAN, it should produce an unbounded
output that can be interpreted as a distance.</p>
<p>When training a WGAN, you also should usually use a smaller value for
generator_steps.  Conventional GANs rely on keeping the generator and
discriminator &#8220;in balance&#8221; with each other.  If the discriminator ever gets
too good, it becomes impossible for the generator to fool it and training
stalls.  WGANs do not have this problem, and in fact the better the
discriminator is, the easier it is for the generator to improve.  It therefore
usually works best to perform several training steps on the discriminator for
each training step on the generator.</p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.create_discriminator">
<code class="descname">create_discriminator</code><span class="sig-paren">(</span><em>data_inputs</em>, <em>conditional_inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.create_discriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the discriminator.</p>
<p>Subclasses must override this to construct the discriminator and return its
output layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data_inputs</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the Input layers from which the discriminator can read the input data.
The number and shapes of these inputs will match the return value from
get_data_input_shapes().  The samples read from these layers may be either
training data or generated data.</li>
<li><strong>conditional_inputs</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the Input layers for any conditional inputs to the network.  The number
and shapes of these inputs will match the return value from
get_conditional_input_shapes().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>A Layer object that outputs the probability of each sample being a training</em></li>
<li><em>sample.  The shape of this layer must be [None].  That is, it must output a</em></li>
<li><em>one dimensional tensor whose length equals the batch size.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.create_discriminator_loss">
<code class="descname">create_discriminator_loss</code><span class="sig-paren">(</span><em>discrim_output_train</em>, <em>discrim_output_gen</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#WGAN.create_discriminator_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.create_discriminator_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.create_generator">
<code class="descname">create_generator</code><span class="sig-paren">(</span><em>noise_input</em>, <em>conditional_inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.create_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the generator.</p>
<p>Subclasses must override this to construct the generator and return its
output layers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>noise_input</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.layers.Input" title="deepchem.models.tensorgraph.layers.Input"><em>Input</em></a>) &#8211; the Input layer from which the generator can read random noise.  The shape
will match the return value from get_noise_input_shape().</li>
<li><strong>conditional_inputs</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the Input layers for any conditional inputs to the network.  The number
and shapes of these inputs will match the return value from
get_conditional_input_shapes().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>A list of Layer objects that produce the generator&#8217;s outputs.  The number and</em></li>
<li><em>shapes of these layers must match the return value from get_data_input_shapes(),</em></li>
<li><em>since generated data must have the same form as training data.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.create_generator_loss">
<code class="descname">create_generator_loss</code><span class="sig-paren">(</span><em>discrim_output</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#WGAN.create_generator_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.create_generator_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>layers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the list of layers to train.  If None, all layers in the model will be
trained.</li>
<li><strong>loss</strong> (<a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><em>Layer</em></a>) &#8211; the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</li>
<li><strong>optimizer</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.optimizers.Optimizer" title="deepchem.models.tensorgraph.optimizers.Optimizer"><em>Optimizer</em></a>) &#8211; the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>the newly created submodel, which can be passed to any of the fitting</em></li>
<li><em>methods.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset object.</li>
<li><strong>metric</strong> (<a class="reference internal" href="deepchem.metrics.html#deepchem.metrics.Metric" title="deepchem.metrics.Metric"><em>deepchem.metrics.Metric</em></a>) &#8211; Evaluation metric</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of deepchem.transformers.Transformer</li>
<li><strong>per_task_metrics</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; If True, return per-task scores.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Maps tasks to scores under metric.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.6)">dict</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<a class="reference internal" href="deepchem.data.html#deepchem.data.datasets.Dataset" title="deepchem.data.datasets.Dataset"><em>Dataset</em></a>) &#8211; the Dataset to train on</li>
<li><strong>nb_epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of epochs to train for</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>deterministic</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.fit_gan">
<code class="descname">fit_gan</code><span class="sig-paren">(</span><em>batches</em>, <em>generator_steps=1.0</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.fit_gan" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>batches</strong> (<em>iterable</em>) &#8211; batches of data to train the discriminator on, each represented as a dict
that maps Layers to values.  It should specify values for all members of
data_inputs and conditional_inputs.</li>
<li><strong>generator_steps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) &#8211; the number of training steps to perform for the generator for each batch.
This can be used to adjust the ratio of training steps for the generator
and discriminator.  For example, 2.0 will perform two training steps for
every batch, while 0.5 will only perform one training step for every two
batches.</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in batches.  Set
this to 0 to disable automatic checkpointing.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint before training
it.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>feed_dict_generator</strong> (<em>generator</em>) &#8211; this should generate batches, each represented as a dict that maps
Layers to values.</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_conditional_input_shapes">
<code class="descname">get_conditional_input_shapes</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_conditional_input_shapes" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shapes of any conditional inputs.</p>
<p>Subclasses may override this to return a list of tuples, each giving the
shape of one of the conditional inputs.  The actual Input layers will be
created automatically.  The first dimension of each shape must be None,
since it will correspond to the batch size.</p>
<p>The default implementation returns an empty list, meaning there are no
conditional inputs.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_data_input_shapes">
<code class="descname">get_data_input_shapes</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_data_input_shapes" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shapes of the inputs for training data.</p>
<p>Subclasses must override this to return a list of tuples, each giving the
shape of one of the inputs.  The actual Input layers will be created
automatically.  This list of shapes must also match the shapes of the
generator&#8217;s outputs.  The first dimension of each shape must be None, since
it will correspond to the batch size.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_noise_batch">
<code class="descname">get_noise_batch</code><span class="sig-paren">(</span><em>batch_size</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_noise_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a batch of random noise to pass to the generator.</p>
<p>This should return a NumPy array whose shape matches the one returned by
get_noise_input_shape().  The default implementation returns normally
distributed values.  Subclasses can override this to implement a different
distribution.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_noise_input_shape">
<code class="descname">get_noise_input_shape</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_noise_input_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shape of the generator&#8217;s noise input layer.</p>
<p>Subclasses must override this to return a tuple giving the shape of the
noise input.  The actual Input layer will be created automatically.  The
first dimension must be None, since it will correspond to the batch size.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> (<em>boolean, optional</em>) &#8211; If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong> &#8211;
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">mapping of string to any</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>results</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.predict_gan_generator">
<code class="descname">predict_gan_generator</code><span class="sig-paren">(</span><em>batch_size=1</em>, <em>noise_input=None</em>, <em>conditional_inputs=[]</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_gan_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the GAN to generate a batch of samples.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of samples to generate.  If either noise_input or
conditional_inputs is specified, this argument is ignored since the batch
size is then determined by the size of that argument.</li>
<li><strong>noise_input</strong> (<a class="reference external" href="https://docs.python.org/library/array.html#module-array" title="(in Python v3.6)"><em>array</em></a>) &#8211; the value to use for the generator&#8217;s noise input.  If None (the default),
get_noise_batch() is called to generate a random input, so each call will
produce a new set of samples.</li>
<li><strong>conditional_inputs</strong> (<em>list of arrays</em>) &#8211; the values to use for all conditional inputs.  This must be specified if
the GAN has any conditional inputs.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>An array (if the generator has only one output) or list of arrays (if it has</em></li>
<li><em>multiple outputs) containing the generated samples.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>generator</strong> (<em>Generator</em>) &#8211; Generator that constructs feed dictionaries for TensorGraph.</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
<li><strong>Returns</strong> &#8211; y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">numpy ndarray of shape (n_samples, n_classes*n_tasks)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">y_pred</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.graph_models">
<span id="deepchem-models-tensorgraph-models-graph-models-module"></span><h2>deepchem.models.tensorgraph.models.graph_models module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.graph_models" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.graph_models.</code><code class="descname">DAGTensorGraph</code><span class="sig-paren">(</span><em>n_tasks</em>, <em>max_atoms=50</em>, <em>n_atom_feat=75</em>, <em>n_graph_feat=30</em>, <em>n_outputs=30</em>, <em>mode='classification'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#DAGTensorGraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#DAGTensorGraph.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Building graph structures:
Features =&gt; DAGLayer =&gt; DAGGather =&gt; Classification or Regression</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>layers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the list of layers to train.  If None, all layers in the model will be
trained.</li>
<li><strong>loss</strong> (<a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><em>Layer</em></a>) &#8211; the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</li>
<li><strong>optimizer</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.optimizers.Optimizer" title="deepchem.models.tensorgraph.optimizers.Optimizer"><em>Optimizer</em></a>) &#8211; the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>the newly created submodel, which can be passed to any of the fitting</em></li>
<li><em>methods.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#DAGTensorGraph.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.default_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>TensorGraph style implementation
similar to deepchem.models.tf_new_models.graph_topology.DAGGraphTopology.batch_to_feed_dict</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset object.</li>
<li><strong>metric</strong> (<a class="reference internal" href="deepchem.metrics.html#deepchem.metrics.Metric" title="deepchem.metrics.Metric"><em>deepchem.metrics.Metric</em></a>) &#8211; Evaluation metric</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of deepchem.transformers.Transformer</li>
<li><strong>per_task_metrics</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; If True, return per-task scores.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Maps tasks to scores under metric.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.6)">dict</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<a class="reference internal" href="deepchem.data.html#deepchem.data.datasets.Dataset" title="deepchem.data.datasets.Dataset"><em>Dataset</em></a>) &#8211; the Dataset to train on</li>
<li><strong>nb_epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of epochs to train for</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>deterministic</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>feed_dict_generator</strong> (<em>generator</em>) &#8211; this should generate batches, each represented as a dict that maps
Layers to values.</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> (<em>boolean, optional</em>) &#8211; If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong> &#8211;
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">mapping of string to any</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>results</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>generator</strong> (<em>Generator</em>) &#8211; Generator that constructs feed dictionaries for TensorGraph.</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
<li><strong>Returns</strong> &#8211; y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">numpy ndarray of shape (n_samples, n_classes*n_tasks)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">y_pred</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.graph_models.</code><code class="descname">DTNNTensorGraph</code><span class="sig-paren">(</span><em>n_tasks</em>, <em>n_embedding=30</em>, <em>n_hidden=100</em>, <em>n_distance=100</em>, <em>distance_min=-1</em>, <em>distance_max=18</em>, <em>output_activation=True</em>, <em>mode='classification'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#DTNNTensorGraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#DTNNTensorGraph.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Building graph structures:
Features =&gt; DTNNEmbedding =&gt; DTNNStep =&gt; DTNNStep =&gt; DTNNGather =&gt; Regression</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>layers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the list of layers to train.  If None, all layers in the model will be
trained.</li>
<li><strong>loss</strong> (<a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><em>Layer</em></a>) &#8211; the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</li>
<li><strong>optimizer</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.optimizers.Optimizer" title="deepchem.models.tensorgraph.optimizers.Optimizer"><em>Optimizer</em></a>) &#8211; the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>the newly created submodel, which can be passed to any of the fitting</em></li>
<li><em>methods.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#DTNNTensorGraph.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.default_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>TensorGraph style implementation
similar to deepchem.models.tf_new_models.graph_topology.DTNNGraphTopology.batch_to_feed_dict</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset object.</li>
<li><strong>metric</strong> (<a class="reference internal" href="deepchem.metrics.html#deepchem.metrics.Metric" title="deepchem.metrics.Metric"><em>deepchem.metrics.Metric</em></a>) &#8211; Evaluation metric</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of deepchem.transformers.Transformer</li>
<li><strong>per_task_metrics</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; If True, return per-task scores.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Maps tasks to scores under metric.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.6)">dict</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<a class="reference internal" href="deepchem.data.html#deepchem.data.datasets.Dataset" title="deepchem.data.datasets.Dataset"><em>Dataset</em></a>) &#8211; the Dataset to train on</li>
<li><strong>nb_epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of epochs to train for</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>deterministic</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>feed_dict_generator</strong> (<em>generator</em>) &#8211; this should generate batches, each represented as a dict that maps
Layers to values.</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> (<em>boolean, optional</em>) &#8211; If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong> &#8211;
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">mapping of string to any</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>results</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>generator</strong> (<em>Generator</em>) &#8211; Generator that constructs feed dictionaries for TensorGraph.</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
<li><strong>Returns</strong> &#8211; y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">numpy ndarray of shape (n_samples, n_classes*n_tasks)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">y_pred</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.graph_models.</code><code class="descname">GraphConvTensorGraph</code><span class="sig-paren">(</span><em>n_tasks</em>, <em>mode='classification'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.bayesian_predict">
<code class="descname">bayesian_predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>n_passes=4</em>, <em>untransform=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.bayesian_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.bayesian_predict" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Generates predictions and confidences on a dataset object</dt>
<dd><a class="reference external" href="https://arxiv.org/pdf/1506.02142.pdf">https://arxiv.org/pdf/1506.02142.pdf</a></dd>
<dt># Returns:</dt>
<dd>mu: numpy ndarray of shape (n_samples, n_tasks)
sigma: numpy ndarray of shape (n_samples, n_tasks)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.bayesian_predict_on_batch">
<code class="descname">bayesian_predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>n_passes=4</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.bayesian_predict_on_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.bayesian_predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">numpy ndarray of shape (n_samples, n_tasks)
sigma: numpy ndarray of shape (n_samples, n_tasks)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">mu</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Building graph structures:</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>layers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the list of layers to train.  If None, all layers in the model will be
trained.</li>
<li><strong>loss</strong> (<a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><em>Layer</em></a>) &#8211; the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</li>
<li><strong>optimizer</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.optimizers.Optimizer" title="deepchem.models.tensorgraph.optimizers.Optimizer"><em>Optimizer</em></a>) &#8211; the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>the newly created submodel, which can be passed to any of the fitting</em></li>
<li><em>methods.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.evaluate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<a class="reference internal" href="deepchem.data.html#deepchem.data.datasets.Dataset" title="deepchem.data.datasets.Dataset"><em>Dataset</em></a>) &#8211; the Dataset to train on</li>
<li><strong>nb_epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of epochs to train for</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>deterministic</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>feed_dict_generator</strong> (<em>generator</em>) &#8211; this should generate batches, each represented as a dict that maps
Layers to values.</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> (<em>boolean, optional</em>) &#8211; If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong> &#8211;
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">mapping of string to any</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>results</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.predict_on_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_smiles">
<code class="descname">predict_on_smiles</code><span class="sig-paren">(</span><em>smiles</em>, <em>transformers=[]</em>, <em>untransform=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.predict_on_smiles"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_smiles" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions on a numpy array of smile strings</p>
<dl class="docutils">
<dt># Returns:</dt>
<dd><a href="#id1"><span class="problematic" id="id2">y_</span></a>: numpy ndarray of shape (n_samples, n_tasks)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.predict_proba_on_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.graph_models.</code><code class="descname">MPNNTensorGraph</code><span class="sig-paren">(</span><em>n_tasks</em>, <em>n_atom_feat=70</em>, <em>n_pair_feat=8</em>, <em>n_hidden=100</em>, <em>T=5</em>, <em>M=10</em>, <em>mode='regression'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#MPNNTensorGraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p>Message Passing Neural Network,
default structures built according to <a class="reference external" href="https://arxiv.org/abs/1511.06391">https://arxiv.org/abs/1511.06391</a></p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#MPNNTensorGraph.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.build_graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>layers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the list of layers to train.  If None, all layers in the model will be
trained.</li>
<li><strong>loss</strong> (<a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><em>Layer</em></a>) &#8211; the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</li>
<li><strong>optimizer</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.optimizers.Optimizer" title="deepchem.models.tensorgraph.optimizers.Optimizer"><em>Optimizer</em></a>) &#8211; the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>the newly created submodel, which can be passed to any of the fitting</em></li>
<li><em>methods.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#MPNNTensorGraph.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.default_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Same generator as Weave models</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset object.</li>
<li><strong>metric</strong> (<a class="reference internal" href="deepchem.metrics.html#deepchem.metrics.Metric" title="deepchem.metrics.Metric"><em>deepchem.metrics.Metric</em></a>) &#8211; Evaluation metric</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of deepchem.transformers.Transformer</li>
<li><strong>per_task_metrics</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; If True, return per-task scores.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Maps tasks to scores under metric.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.6)">dict</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<a class="reference internal" href="deepchem.data.html#deepchem.data.datasets.Dataset" title="deepchem.data.datasets.Dataset"><em>Dataset</em></a>) &#8211; the Dataset to train on</li>
<li><strong>nb_epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of epochs to train for</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>deterministic</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>feed_dict_generator</strong> (<em>generator</em>) &#8211; this should generate batches, each represented as a dict that maps
Layers to values.</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> (<em>boolean, optional</em>) &#8211; If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong> &#8211;
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">mapping of string to any</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>batch_size=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#MPNNTensorGraph.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#MPNNTensorGraph.predict_on_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>batch_size=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#MPNNTensorGraph.predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#MPNNTensorGraph.predict_proba_on_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">numpy ndarray of shape (n_samples, n_classes*n_tasks)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">y_pred</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.graph_models.</code><code class="descname">PetroskiSuchTensorGraph</code><span class="sig-paren">(</span><em>n_tasks</em>, <em>max_atoms=200</em>, <em>dropout=0.0</em>, <em>mode='classification'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#PetroskiSuchTensorGraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p>Model from Robust Spatial Filtering with Graph Convolutional Neural Networks
<a class="reference external" href="https://arxiv.org/abs/1703.00792">https://arxiv.org/abs/1703.00792</a></p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#PetroskiSuchTensorGraph.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.build_graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>layers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the list of layers to train.  If None, all layers in the model will be
trained.</li>
<li><strong>loss</strong> (<a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><em>Layer</em></a>) &#8211; the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</li>
<li><strong>optimizer</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.optimizers.Optimizer" title="deepchem.models.tensorgraph.optimizers.Optimizer"><em>Optimizer</em></a>) &#8211; the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>the newly created submodel, which can be passed to any of the fitting</em></li>
<li><em>methods.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#PetroskiSuchTensorGraph.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#PetroskiSuchTensorGraph.evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.evaluate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<a class="reference internal" href="deepchem.data.html#deepchem.data.datasets.Dataset" title="deepchem.data.datasets.Dataset"><em>Dataset</em></a>) &#8211; the Dataset to train on</li>
<li><strong>nb_epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of epochs to train for</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>deterministic</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>feed_dict_generator</strong> (<em>generator</em>) &#8211; this should generate batches, each represented as a dict that maps
Layers to values.</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> (<em>boolean, optional</em>) &#8211; If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong> &#8211;
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">mapping of string to any</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>results</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>generator</strong> (<em>Generator</em>) &#8211; Generator that constructs feed dictionaries for TensorGraph.</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
<li><strong>Returns</strong> &#8211; y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#PetroskiSuchTensorGraph.predict_proba_on_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.graph_models.</code><code class="descname">WeaveTensorGraph</code><span class="sig-paren">(</span><em>n_tasks</em>, <em>n_atom_feat=75</em>, <em>n_pair_feat=14</em>, <em>n_hidden=50</em>, <em>n_graph_feat=128</em>, <em>mode='classification'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#WeaveTensorGraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#WeaveTensorGraph.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Building graph structures:
Features =&gt; WeaveLayer =&gt; WeaveLayer =&gt; Dense =&gt; WeaveGather =&gt; Classification or Regression</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>layers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the list of layers to train.  If None, all layers in the model will be
trained.</li>
<li><strong>loss</strong> (<a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><em>Layer</em></a>) &#8211; the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</li>
<li><strong>optimizer</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.optimizers.Optimizer" title="deepchem.models.tensorgraph.optimizers.Optimizer"><em>Optimizer</em></a>) &#8211; the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>the newly created submodel, which can be passed to any of the fitting</em></li>
<li><em>methods.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#WeaveTensorGraph.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.default_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>TensorGraph style implementation
similar to deepchem.models.tf_new_models.graph_topology.AlternateWeaveTopology.batch_to_feed_dict</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset object.</li>
<li><strong>metric</strong> (<a class="reference internal" href="deepchem.metrics.html#deepchem.metrics.Metric" title="deepchem.metrics.Metric"><em>deepchem.metrics.Metric</em></a>) &#8211; Evaluation metric</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of deepchem.transformers.Transformer</li>
<li><strong>per_task_metrics</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; If True, return per-task scores.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Maps tasks to scores under metric.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.6)">dict</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<a class="reference internal" href="deepchem.data.html#deepchem.data.datasets.Dataset" title="deepchem.data.datasets.Dataset"><em>Dataset</em></a>) &#8211; the Dataset to train on</li>
<li><strong>nb_epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of epochs to train for</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>deterministic</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>feed_dict_generator</strong> (<em>generator</em>) &#8211; this should generate batches, each represented as a dict that maps
Layers to values.</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> (<em>boolean, optional</em>) &#8211; If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong> &#8211;
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">mapping of string to any</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>results</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>generator</strong> (<em>Generator</em>) &#8211; Generator that constructs feed dictionaries for TensorGraph.</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
<li><strong>Returns</strong> &#8211; y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">numpy ndarray of shape (n_samples, n_classes*n_tasks)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">y_pred</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.robust_multitask">
<span id="deepchem-models-tensorgraph-models-robust-multitask-module"></span><h2>deepchem.models.tensorgraph.models.robust_multitask module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.robust_multitask" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.seqtoseq">
<span id="deepchem-models-tensorgraph-models-seqtoseq-module"></span><h2>deepchem.models.tensorgraph.models.seqtoseq module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.seqtoseq" title="Permalink to this headline">¶</a></h2>
<p>Sequence to sequence translation models.</p>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.seqtoseq.</code><code class="descname">SeqToSeq</code><span class="sig-paren">(</span><em>input_tokens</em>, <em>output_tokens</em>, <em>max_output_length</em>, <em>encoder_layers=4</em>, <em>decoder_layers=4</em>, <em>embedding_dimension=512</em>, <em>dropout=0.0</em>, <em>reverse_input=True</em>, <em>variational=False</em>, <em>annealing_start_step=5000</em>, <em>annealing_final_step=10000</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/seqtoseq.html#SeqToSeq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p>Implements sequence to sequence translation models.</p>
<p>The model is based on the description in Sutskever et al., &#8220;Sequence to
Sequence Learning with Neural Networks&#8221; (<a class="reference external" href="https://arxiv.org/abs/1409.3215">https://arxiv.org/abs/1409.3215</a>),
although this implementation uses GRUs instead of LSTMs.  The goal is to
take sequences of tokens as input, and translate each one into a different
output sequence.  The input and output sequences can both be of variable
length, and an output sequence need not have the same length as the input
sequence it was generated from.  For example, these models were originally
developed for use in natural language processing.  In that context, the
input might be a sequence of English words, and the output might be a
sequence of French words.  The goal would be to train the model to translate
sentences from English to French.</p>
<p>The model consists of two parts called the &#8220;encoder&#8221; and &#8220;decoder&#8221;.  Each one
consists of a stack of recurrent layers.  The job of the encoder is to
transform the input sequence into a single, fixed length vector called the
&#8220;embedding&#8221;.  That vector contains all relevant information from the input
sequence.  The decoder then transforms the embedding vector into the output
sequence.</p>
<p>These models can be used for various purposes.  First and most obviously,
they can be used for sequence to sequence translation.  In any case where you
have sequences of tokens, and you want to translate each one into a different
sequence, a SeqToSeq model can be trained to perform the translation.</p>
<p>Another possible use case is transforming variable length sequences into
fixed length vectors.  Many types of models require their inputs to have a
fixed shape, which makes it difficult to use them with variable sized inputs
(for example, when the input is a molecule, and different molecules have
different numbers of atoms).  In that case, you can train a SeqToSeq model as
an autoencoder, so that it tries to make the output sequence identical to the
input one.  That forces the embedding vector to contain all information from
the original sequence.  You can then use the encoder for transforming
sequences into fixed length embedding vectors, suitable to use as inputs to
other types of models.</p>
<p>Another use case is to train the decoder for use as a generative model.  Here
again you begin by training the SeqToSeq model as an autoencoder.  Once
training is complete, you can supply arbitrary embedding vectors, and
transform each one into an output sequence.  When used in this way, you
typically train it as a variational autoencoder.  This adds random noise to
the encoder, and also adds a constraint term to the loss that forces the
embedding vector to have a unit Gaussian distribution.  You can then pick
random vectors from a Gaussian distribution, and the output sequences should
follow the same distribution as the training data.</p>
<p>When training as a variational autoencoder, it is best to use KL cost
annealing, as described in <a class="reference external" href="https://arxiv.org/abs/1511.06349">https://arxiv.org/abs/1511.06349</a>.  The constraint
term in the loss is initially set to 0, so the optimizer just tries to
minimize the reconstruction loss.  Once it has made reasonable progress
toward that, the constraint term can be gradually turned back on.  The range
of steps over which this happens is configurable.</p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>layers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the list of layers to train.  If None, all layers in the model will be
trained.</li>
<li><strong>loss</strong> (<a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><em>Layer</em></a>) &#8211; the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</li>
<li><strong>optimizer</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.optimizers.Optimizer" title="deepchem.models.tensorgraph.optimizers.Optimizer"><em>Optimizer</em></a>) &#8211; the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>the newly created submodel, which can be passed to any of the fitting</em></li>
<li><em>methods.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset object.</li>
<li><strong>metric</strong> (<a class="reference internal" href="deepchem.metrics.html#deepchem.metrics.Metric" title="deepchem.metrics.Metric"><em>deepchem.metrics.Metric</em></a>) &#8211; Evaluation metric</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of deepchem.transformers.Transformer</li>
<li><strong>per_task_metrics</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; If True, return per-task scores.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Maps tasks to scores under metric.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.6)">dict</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<a class="reference internal" href="deepchem.data.html#deepchem.data.datasets.Dataset" title="deepchem.data.datasets.Dataset"><em>Dataset</em></a>) &#8211; the Dataset to train on</li>
<li><strong>nb_epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of epochs to train for</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>deterministic</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>feed_dict_generator</strong> (<em>generator</em>) &#8211; this should generate batches, each represented as a dict that maps
Layers to values.</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_sequences">
<code class="descname">fit_sequences</code><span class="sig-paren">(</span><em>sequences</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/seqtoseq.html#SeqToSeq.fit_sequences"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_sequences" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a set of sequences</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>sequences</strong> (<em>iterable</em>) &#8211; the training samples to fit to.  Each sample should be
represented as a tuple of the form (input_sequence, output_sequence).</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> (<em>boolean, optional</em>) &#8211; If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong> &#8211;
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">mapping of string to any</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>results</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_embeddings">
<code class="descname">predict_embeddings</code><span class="sig-paren">(</span><em>sequences</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/seqtoseq.html#SeqToSeq.predict_embeddings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of input sequences, compute the embedding vectors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>sequences</strong> (<em>iterable</em>) &#8211; the input sequences to generate an embedding vector for</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_from_embeddings">
<code class="descname">predict_from_embeddings</code><span class="sig-paren">(</span><em>embeddings</em>, <em>beam_width=5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/seqtoseq.html#SeqToSeq.predict_from_embeddings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_from_embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of embedding vectors, predict the output sequences.</p>
<p>The prediction is done using a beam search with length normalization.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>embeddings</strong> (<em>iterable</em>) &#8211; the embedding vectors to generate predictions for</li>
<li><strong>beam_width</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the beam width to use for searching.  Set to 1 to use a simple greedy search.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_from_sequences">
<code class="descname">predict_from_sequences</code><span class="sig-paren">(</span><em>sequences</em>, <em>beam_width=5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/seqtoseq.html#SeqToSeq.predict_from_sequences"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_from_sequences" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of input sequences, predict the output sequences.</p>
<p>The prediction is done using a beam search with length normalization.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>sequences</strong> (<em>iterable</em>) &#8211; the input sequences to generate a prediction for</li>
<li><strong>beam_width</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the beam width to use for searching.  Set to 1 to use a simple greedy search.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>generator</strong> (<em>Generator</em>) &#8211; Generator that constructs feed dictionaries for TensorGraph.</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
<li><strong>Returns</strong> &#8211; y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">numpy ndarray of shape (n_samples, n_classes*n_tasks)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">y_pred</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.sequence_end">
<code class="descname">sequence_end</code><em class="property"> = &lt;object object&gt;</em><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.sequence_end" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.symmetry_function_regression">
<span id="deepchem-models-tensorgraph-models-symmetry-function-regression-module"></span><h2>deepchem.models.tensorgraph.models.symmetry_function_regression module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.symmetry_function_regression" title="Permalink to this headline">¶</a></h2>
<p>Created on Thu Jul  6 20:31:47 2017</p>
<p>&#64;author: zqwu
&#64;contributors: ytz</p>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.symmetry_function_regression.</code><code class="descname">ANIRegression</code><span class="sig-paren">(</span><em>n_tasks, max_atoms, layer_structures=[128, 64], atom_number_cases=[1, 6, 7, 8, 16], **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build_grad">
<code class="descname">build_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.build_grad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build_grad" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build_graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.compute_grad">
<code class="descname">compute_grad</code><span class="sig-paren">(</span><em>dataset</em>, <em>upper_lim=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.compute_grad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.compute_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a batched gradients given an input dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.Dataset</em>) &#8211; dataset-like object whose X values will be used to compute
gradients from</li>
<li><strong>upper_lim</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; subset of dataset used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Gradients of the input of shape (max_atoms, 4). Note that it is up to
the end user to slice this matrix into the correct shape, since it&#8217;s very
likely the derivatives with respect to the atomic numbers are zero.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">np.array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>layers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the list of layers to train.  If None, all layers in the model will be
trained.</li>
<li><strong>loss</strong> (<a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><em>Layer</em></a>) &#8211; the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</li>
<li><strong>optimizer</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.optimizers.Optimizer" title="deepchem.models.tensorgraph.optimizers.Optimizer"><em>Optimizer</em></a>) &#8211; the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>the newly created submodel, which can be passed to any of the fitting</em></li>
<li><em>methods.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset object.</li>
<li><strong>metric</strong> (<a class="reference internal" href="deepchem.metrics.html#deepchem.metrics.Metric" title="deepchem.metrics.Metric"><em>deepchem.metrics.Metric</em></a>) &#8211; Evaluation metric</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of deepchem.transformers.Transformer</li>
<li><strong>per_task_metrics</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; If True, return per-task scores.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Maps tasks to scores under metric.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.6)">dict</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<a class="reference internal" href="deepchem.data.html#deepchem.data.datasets.Dataset" title="deepchem.data.datasets.Dataset"><em>Dataset</em></a>) &#8211; the Dataset to train on</li>
<li><strong>nb_epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of epochs to train for</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>deterministic</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>feed_dict_generator</strong> (<em>generator</em>) &#8211; this should generate batches, each represented as a dict that maps
Layers to values.</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> (<em>boolean, optional</em>) &#8211; If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong> &#8211;
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">mapping of string to any</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.grad_one">
<code class="descname">grad_one</code><span class="sig-paren">(</span><em>X</em>, <em>atomic_nums</em>, <em>constraints=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.grad_one"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.grad_one" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes gradients for that of a single structure.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>np.array</em>) &#8211; numpy array of shape (a, 3) where a &lt;= max_atoms and
dtype is float-like</li>
<li><strong>atomic_nums</strong> (<em>np.array</em>) &#8211; numpy array of shape (a,) where a is the same as that of X.</li>
<li><strong>constraints</strong> (<em>np.array</em>) &#8211; numpy array of indices of X used for constraining a subset
of the atoms of the molecule.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">derivatives of the same shape and type as input parameter X.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">np.array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.load_numpy">
<em class="property">classmethod </em><code class="descname">load_numpy</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.load_numpy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.load_numpy" title="Permalink to this definition">¶</a></dt>
<dd><p>Load from a portable numpy file.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>model_dir</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) &#8211; Location of the model directory.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.minimize_structure">
<code class="descname">minimize_structure</code><span class="sig-paren">(</span><em>X</em>, <em>atomic_nums</em>, <em>constraints=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.minimize_structure"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.minimize_structure" title="Permalink to this definition">¶</a></dt>
<dd><p>Minimizes a structure, as defined by a set of coordinates and their atomic
numbers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>np.array</em>) &#8211; numpy array of shape (a, 3) where a &lt;= max_atoms and
dtype is float-like</li>
<li><strong>atomic_nums</strong> (<em>np.array</em>) &#8211; numpy array of shape (a,) where a is the same as that of X.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">minimized coordinates of the same shape and type as input parameter X.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">np.array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.pred_one">
<code class="descname">pred_one</code><span class="sig-paren">(</span><em>X</em>, <em>atomic_nums</em>, <em>constraints=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.pred_one"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.pred_one" title="Permalink to this definition">¶</a></dt>
<dd><p>Makes an energy prediction for a set of atomic coordinates.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>np.array</em>) &#8211; numpy array of shape (a, 3) where a &lt;= max_atoms and
dtype is float-like</li>
<li><strong>atomic_nums</strong> (<em>np.array</em>) &#8211; numpy array of shape (a,) where a is the same as that of X.</li>
<li><strong>constraints</strong> (<em>unused</em>) &#8211; This parameter is mainly for compatibility purposes for scipy optimize</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Predicted energy. Note that the meaning of the returned value is
dependent on the training y-values both in semantics (relative vs absolute)
and units (kcal/mol vs Hartrees)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.6)">float</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>results</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>generator</strong> (<em>Generator</em>) &#8211; Generator that constructs feed dictionaries for TensorGraph.</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
<li><strong>Returns</strong> &#8211; y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">numpy ndarray of shape (n_samples, n_classes*n_tasks)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">y_pred</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save_numpy">
<code class="descname">save_numpy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.save_numpy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save_numpy" title="Permalink to this definition">¶</a></dt>
<dd><p>Save to a portable numpy file. Note that this relies on the names to be consistent
across different versions. The file is saved as save_pickle.npz under the model_dir.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.symmetry_function_regression.</code><code class="descname">BPSymmetryFunctionRegression</code><span class="sig-paren">(</span><em>n_tasks, max_atoms, n_feat=96, layer_structures=[128, 64], **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#BPSymmetryFunctionRegression"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#BPSymmetryFunctionRegression.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.build_graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>layers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the list of layers to train.  If None, all layers in the model will be
trained.</li>
<li><strong>loss</strong> (<a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><em>Layer</em></a>) &#8211; the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</li>
<li><strong>optimizer</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.optimizers.Optimizer" title="deepchem.models.tensorgraph.optimizers.Optimizer"><em>Optimizer</em></a>) &#8211; the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>the newly created submodel, which can be passed to any of the fitting</em></li>
<li><em>methods.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#BPSymmetryFunctionRegression.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset object.</li>
<li><strong>metric</strong> (<a class="reference internal" href="deepchem.metrics.html#deepchem.metrics.Metric" title="deepchem.metrics.Metric"><em>deepchem.metrics.Metric</em></a>) &#8211; Evaluation metric</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of deepchem.transformers.Transformer</li>
<li><strong>per_task_metrics</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; If True, return per-task scores.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Maps tasks to scores under metric.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.6)">dict</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<a class="reference internal" href="deepchem.data.html#deepchem.data.datasets.Dataset" title="deepchem.data.datasets.Dataset"><em>Dataset</em></a>) &#8211; the Dataset to train on</li>
<li><strong>nb_epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of epochs to train for</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>deterministic</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>feed_dict_generator</strong> (<em>generator</em>) &#8211; this should generate batches, each represented as a dict that maps
Layers to values.</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> (<em>boolean, optional</em>) &#8211; If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong> &#8211;
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">mapping of string to any</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>results</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>generator</strong> (<em>Generator</em>) &#8211; Generator that constructs feed dictionaries for TensorGraph.</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
<li><strong>Returns</strong> &#8211; y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">numpy ndarray of shape (n_samples, n_classes*n_tasks)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">y_pred</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.test_graph_models">
<span id="deepchem-models-tensorgraph-models-test-graph-models-module"></span><h2>deepchem.models.tensorgraph.models.test_graph_models module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.test_graph_models" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.test_graph_models.</code><code class="descname">TestGraphModels</code><span class="sig-paren">(</span><em>methodName='runTest'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_graph_models.html#TestGraphModels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">unittest.case.TestCase</span></code></p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.addCleanup">
<code class="descname">addCleanup</code><span class="sig-paren">(</span><em>function</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.addCleanup" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a function, with arguments, to be called when the test is
completed. Functions added are called on a LIFO basis and are
called after tearDown on test failure or success.</p>
<p>Cleanup items are called even if setUp fails (unlike tearDown).</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.addTypeEqualityFunc">
<code class="descname">addTypeEqualityFunc</code><span class="sig-paren">(</span><em>typeobj</em>, <em>function</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.addTypeEqualityFunc" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a type specific assertEqual style function to compare a type.</p>
<p>This method is for use by TestCase subclasses that need to register
their own type equality functions to provide nicer error messages.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>typeobj</strong> &#8211; The data type to call this function on when both values
are of the same type in assertEqual().</li>
<li><strong>function</strong> &#8211; The callable taking two arguments and an optional
msg= argument that raises self.failureException with a
useful error message when the two arguments are not equal.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertAlmostEqual">
<code class="descname">assertAlmostEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>places=None</em>, <em>msg=None</em>, <em>delta=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are unequal as determined by their
difference rounded to the given number of decimal places
(default 7) and comparing to zero, or by comparing that the
between the two objects is more than the given delta.</p>
<p>Note that decimal places (from zero) are usually not the same
as significant digits (measured from the most significant digit).</p>
<p>If the two objects compare equal then they will automatically
compare almost equal.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertAlmostEquals">
<code class="descname">assertAlmostEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertAlmostEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertCountEqual">
<code class="descname">assertCountEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertCountEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>An unordered sequence comparison asserting that the same elements,
regardless of order.  If the same element occurs more than once,
it verifies that the elements occur the same number of times.</p>
<blockquote>
<div><blockquote>
<div><dl class="docutils">
<dt>self.assertEqual(Counter(list(first)),</dt>
<dd>Counter(list(second)))</dd>
</dl>
</div></blockquote>
<dl class="docutils">
<dt>Example:</dt>
<dd><ul class="first last simple">
<li>[0, 1, 1] and [1, 0, 1] compare equal.</li>
<li>[0, 0, 1] and [0, 1] compare unequal.</li>
</ul>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertDictContainsSubset">
<code class="descname">assertDictContainsSubset</code><span class="sig-paren">(</span><em>subset</em>, <em>dictionary</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertDictContainsSubset" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks whether dictionary is a superset of subset.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertDictEqual">
<code class="descname">assertDictEqual</code><span class="sig-paren">(</span><em>d1</em>, <em>d2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertDictEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertEqual">
<code class="descname">assertEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are unequal as determined by the &#8216;==&#8217;
operator.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertEquals">
<code class="descname">assertEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertFalse">
<code class="descname">assertFalse</code><span class="sig-paren">(</span><em>expr</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertFalse" title="Permalink to this definition">¶</a></dt>
<dd><p>Check that the expression is false.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertGreater">
<code class="descname">assertGreater</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertGreater" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &gt; b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertGreaterEqual">
<code class="descname">assertGreaterEqual</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertGreaterEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &gt;= b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIn">
<code class="descname">assertIn</code><span class="sig-paren">(</span><em>member</em>, <em>container</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIn" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a in b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIs">
<code class="descname">assertIs</code><span class="sig-paren">(</span><em>expr1</em>, <em>expr2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIs" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a is b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsInstance">
<code class="descname">assertIsInstance</code><span class="sig-paren">(</span><em>obj</em>, <em>cls</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsInstance" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as self.assertTrue(isinstance(obj, cls)), with a nicer
default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNone">
<code class="descname">assertIsNone</code><span class="sig-paren">(</span><em>obj</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNone" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as self.assertTrue(obj is None), with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNot">
<code class="descname">assertIsNot</code><span class="sig-paren">(</span><em>expr1</em>, <em>expr2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNot" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a is not b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNotNone">
<code class="descname">assertIsNotNone</code><span class="sig-paren">(</span><em>obj</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNotNone" title="Permalink to this definition">¶</a></dt>
<dd><p>Included for symmetry with assertIsNone.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLess">
<code class="descname">assertLess</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLess" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &lt; b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLessEqual">
<code class="descname">assertLessEqual</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLessEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &lt;= b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertListEqual">
<code class="descname">assertListEqual</code><span class="sig-paren">(</span><em>list1</em>, <em>list2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertListEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>A list-specific equality assertion.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>list1</strong> &#8211; The first list to compare.</li>
<li><strong>list2</strong> &#8211; The second list to compare.</li>
<li><strong>msg</strong> &#8211; Optional message to use on failure instead of a list of
differences.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLogs">
<code class="descname">assertLogs</code><span class="sig-paren">(</span><em>logger=None</em>, <em>level=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLogs" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail unless a log message of level <em>level</em> or higher is emitted
on <em>logger_name</em> or its children.  If omitted, <em>level</em> defaults to
INFO and <em>logger</em> defaults to the root logger.</p>
<p>This method must be used as a context manager, and will yield
a recording object with two attributes: <cite>output</cite> and <cite>records</cite>.
At the end of the context manager, the <cite>output</cite> attribute will
be a list of the matching formatted log messages and the
<cite>records</cite> attribute will be a list of the corresponding LogRecord
objects.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertLogs</span><span class="p">(</span><span class="s1">&#39;foo&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="s1">&#39;INFO&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">cm</span><span class="p">:</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;foo&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;first message&#39;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;foo.bar&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s1">&#39;second message&#39;</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;INFO:foo:first message&#39;</span><span class="p">,</span>
                             <span class="s1">&#39;ERROR:foo.bar:second message&#39;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertMultiLineEqual">
<code class="descname">assertMultiLineEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertMultiLineEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Assert that two multi-line strings are equal.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotAlmostEqual">
<code class="descname">assertNotAlmostEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>places=None</em>, <em>msg=None</em>, <em>delta=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are equal as determined by their
difference rounded to the given number of decimal places
(default 7) and comparing to zero, or by comparing that the
between the two objects is less than the given delta.</p>
<p>Note that decimal places (from zero) are usually not the same
as significant digits (measured from the most significant digit).</p>
<p>Objects that are equal automatically fail.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotAlmostEquals">
<code class="descname">assertNotAlmostEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotAlmostEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotEqual">
<code class="descname">assertNotEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are equal as determined by the &#8216;!=&#8217;
operator.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotEquals">
<code class="descname">assertNotEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotIn">
<code class="descname">assertNotIn</code><span class="sig-paren">(</span><em>member</em>, <em>container</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotIn" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a not in b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotIsInstance">
<code class="descname">assertNotIsInstance</code><span class="sig-paren">(</span><em>obj</em>, <em>cls</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotIsInstance" title="Permalink to this definition">¶</a></dt>
<dd><p>Included for symmetry with assertIsInstance.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotRegex">
<code class="descname">assertNotRegex</code><span class="sig-paren">(</span><em>text</em>, <em>unexpected_regex</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail the test if the text matches the regular expression.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotRegexpMatches">
<code class="descname">assertNotRegexpMatches</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotRegexpMatches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaises">
<code class="descname">assertRaises</code><span class="sig-paren">(</span><em>expected_exception</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaises" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail unless an exception of class expected_exception is raised
by the callable when invoked with specified positional and
keyword arguments. If a different type of exception is
raised, it will not be caught, and the test case will be
deemed to have suffered an error, exactly as for an
unexpected exception.</p>
<p>If called with the callable and arguments omitted, will return a
context object used like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertRaises</span><span class="p">(</span><span class="n">SomeException</span><span class="p">):</span>
    <span class="n">do_something</span><span class="p">()</span>
</pre></div>
</div>
<p>An optional keyword argument &#8216;msg&#8217; can be provided when assertRaises
is used as a context object.</p>
<p>The context manager keeps a reference to the exception as
the &#8216;exception&#8217; attribute. This allows you to inspect the
exception after the assertion:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertRaises</span><span class="p">(</span><span class="n">SomeException</span><span class="p">)</span> <span class="k">as</span> <span class="n">cm</span><span class="p">:</span>
    <span class="n">do_something</span><span class="p">()</span>
<span class="n">the_exception</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">exception</span>
<span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">the_exception</span><span class="o">.</span><span class="n">error_code</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaisesRegex">
<code class="descname">assertRaisesRegex</code><span class="sig-paren">(</span><em>expected_exception</em>, <em>expected_regex</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaisesRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Asserts that the message in a raised exception matches a regex.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>expected_exception</strong> &#8211; Exception class expected to be raised.</li>
<li><strong>expected_regex</strong> &#8211; Regex (re pattern object or string) expected
to be found in error message.</li>
<li><strong>args</strong> &#8211; Function to be called and extra positional args.</li>
<li><strong>kwargs</strong> &#8211; Extra kwargs.</li>
<li><strong>msg</strong> &#8211; Optional message used in case of failure. Can only be used
when assertRaisesRegex is used as a context manager.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaisesRegexp">
<code class="descname">assertRaisesRegexp</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaisesRegexp" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRegex">
<code class="descname">assertRegex</code><span class="sig-paren">(</span><em>text</em>, <em>expected_regex</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail the test unless the text matches the regular expression.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRegexpMatches">
<code class="descname">assertRegexpMatches</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRegexpMatches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertSequenceEqual">
<code class="descname">assertSequenceEqual</code><span class="sig-paren">(</span><em>seq1</em>, <em>seq2</em>, <em>msg=None</em>, <em>seq_type=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertSequenceEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>An equality assertion for ordered sequences (like lists and tuples).</p>
<p>For the purposes of this function, a valid ordered sequence type is one
which can be indexed, has a length, and has an equality operator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>seq1</strong> &#8211; The first sequence to compare.</li>
<li><strong>seq2</strong> &#8211; The second sequence to compare.</li>
<li><strong>seq_type</strong> &#8211; The expected datatype of the sequences, or None if no
datatype should be enforced.</li>
<li><strong>msg</strong> &#8211; Optional message to use on failure instead of a list of
differences.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertSetEqual">
<code class="descname">assertSetEqual</code><span class="sig-paren">(</span><em>set1</em>, <em>set2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertSetEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>A set-specific equality assertion.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>set1</strong> &#8211; The first set to compare.</li>
<li><strong>set2</strong> &#8211; The second set to compare.</li>
<li><strong>msg</strong> &#8211; Optional message to use on failure instead of a list of
differences.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>assertSetEqual uses ducktyping to support different types of sets, and
is optimized for sets specifically (parameters must support a
difference method).</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertTrue">
<code class="descname">assertTrue</code><span class="sig-paren">(</span><em>expr</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertTrue" title="Permalink to this definition">¶</a></dt>
<dd><p>Check that the expression is true.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertTupleEqual">
<code class="descname">assertTupleEqual</code><span class="sig-paren">(</span><em>tuple1</em>, <em>tuple2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertTupleEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>A tuple-specific equality assertion.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>tuple1</strong> &#8211; The first tuple to compare.</li>
<li><strong>tuple2</strong> &#8211; The second tuple to compare.</li>
<li><strong>msg</strong> &#8211; Optional message to use on failure instead of a list of
differences.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertWarns">
<code class="descname">assertWarns</code><span class="sig-paren">(</span><em>expected_warning</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertWarns" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail unless a warning of class warnClass is triggered
by the callable when invoked with specified positional and
keyword arguments.  If a different type of warning is
triggered, it will not be handled: depending on the other
warning filtering rules in effect, it might be silenced, printed
out, or raised as an exception.</p>
<p>If called with the callable and arguments omitted, will return a
context object used like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertWarns</span><span class="p">(</span><span class="n">SomeWarning</span><span class="p">):</span>
    <span class="n">do_something</span><span class="p">()</span>
</pre></div>
</div>
<p>An optional keyword argument &#8216;msg&#8217; can be provided when assertWarns
is used as a context object.</p>
<p>The context manager keeps a reference to the first matching
warning as the &#8216;warning&#8217; attribute; similarly, the &#8216;filename&#8217;
and &#8216;lineno&#8217; attributes give you information about the line
of Python code from which the warning was triggered.
This allows you to inspect the warning after the assertion:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertWarns</span><span class="p">(</span><span class="n">SomeWarning</span><span class="p">)</span> <span class="k">as</span> <span class="n">cm</span><span class="p">:</span>
    <span class="n">do_something</span><span class="p">()</span>
<span class="n">the_warning</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">warning</span>
<span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">the_warning</span><span class="o">.</span><span class="n">some_attribute</span><span class="p">,</span> <span class="mi">147</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertWarnsRegex">
<code class="descname">assertWarnsRegex</code><span class="sig-paren">(</span><em>expected_warning</em>, <em>expected_regex</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertWarnsRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Asserts that the message in a triggered warning matches a regexp.
Basic functioning is similar to assertWarns() with the addition
that only warnings whose messages also match the regular expression
are considered successful matches.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>expected_warning</strong> &#8211; Warning class expected to be triggered.</li>
<li><strong>expected_regex</strong> &#8211; Regex (re pattern object or string) expected
to be found in error message.</li>
<li><strong>args</strong> &#8211; Function to be called and extra positional args.</li>
<li><strong>kwargs</strong> &#8211; Extra kwargs.</li>
<li><strong>msg</strong> &#8211; Optional message used in case of failure. Can only be used
when assertWarnsRegex is used as a context manager.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assert_">
<code class="descname">assert_</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assert_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.countTestCases">
<code class="descname">countTestCases</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.countTestCases" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.debug">
<code class="descname">debug</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.debug" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the test without collecting errors in a TestResult</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.defaultTestResult">
<code class="descname">defaultTestResult</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.defaultTestResult" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.doCleanups">
<code class="descname">doCleanups</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.doCleanups" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute all cleanup functions. Normally called for you after
tearDown.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.fail">
<code class="descname">fail</code><span class="sig-paren">(</span><em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.fail" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail immediately, with the given message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIf">
<code class="descname">failIf</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIfAlmostEqual">
<code class="descname">failIfAlmostEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIfAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIfEqual">
<code class="descname">failIfEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIfEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnless">
<code class="descname">failUnless</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnless" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessAlmostEqual">
<code class="descname">failUnlessAlmostEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessEqual">
<code class="descname">failUnlessEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessRaises">
<code class="descname">failUnlessRaises</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessRaises" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failureException">
<code class="descname">failureException</code><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failureException" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference external" href="https://docs.python.org/library/exceptions.html#AssertionError" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">AssertionError</span></code></a></p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.get_dataset">
<code class="descname">get_dataset</code><span class="sig-paren">(</span><em>mode='classification'</em>, <em>featurizer='GraphConv'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_graph_models.html#TestGraphModels.get_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.get_dataset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.id">
<code class="descname">id</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.id" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.longMessage">
<code class="descname">longMessage</code><em class="property"> = True</em><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.longMessage" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.maxDiff">
<code class="descname">maxDiff</code><em class="property"> = 640</em><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.maxDiff" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.run">
<code class="descname">run</code><span class="sig-paren">(</span><em>result=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.run" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.setUp">
<code class="descname">setUp</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.setUp" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook method for setting up the test fixture before exercising it.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.setUpClass">
<code class="descname">setUpClass</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.setUpClass" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook method for setting up class fixture before running tests in the class.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.shortDescription">
<code class="descname">shortDescription</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.shortDescription" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a one-line description of the test, or None if no
description has been provided.</p>
<p>The default implementation of this method returns the first line of
the specified test method&#8217;s docstring.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.skipTest">
<code class="descname">skipTest</code><span class="sig-paren">(</span><em>reason</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.skipTest" title="Permalink to this definition">¶</a></dt>
<dd><p>Skip this test.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.subTest">
<code class="descname">subTest</code><span class="sig-paren">(</span><em>msg=&lt;object object&gt;</em>, <em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.subTest" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a context manager that will return the enclosed block
of code in a subtest identified by the optional message and
keyword parameters.  A failure in the subtest marks the test
case as failed but resumes execution at the end of the enclosed
block, allowing further test code to be executed.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.tearDown">
<code class="descname">tearDown</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.tearDown" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook method for deconstructing the test fixture after testing it.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.tearDownClass">
<code class="descname">tearDownClass</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.tearDownClass" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook method for deconstructing the class fixture after running all tests in the class.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_error_bars">
<code class="descname">test_graph_conv_error_bars</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_graph_models.html#TestGraphModels.test_graph_conv_error_bars"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_error_bars" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_model">
<code class="descname">test_graph_conv_model</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_graph_models.html#TestGraphModels.test_graph_conv_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_model" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_regression_model">
<code class="descname">test_graph_conv_regression_model</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_graph_models.html#TestGraphModels.test_graph_conv_regression_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_regression_model" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.test_symmetry_functions">
<span id="deepchem-models-tensorgraph-models-test-symmetry-functions-module"></span><h2>deepchem.models.tensorgraph.models.test_symmetry_functions module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.test_symmetry_functions" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.test_symmetry_functions.</code><code class="descname">TestANIRegression</code><span class="sig-paren">(</span><em>methodName='runTest'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_symmetry_functions.html#TestANIRegression"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">unittest.case.TestCase</span></code></p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.addCleanup">
<code class="descname">addCleanup</code><span class="sig-paren">(</span><em>function</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.addCleanup" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a function, with arguments, to be called when the test is
completed. Functions added are called on a LIFO basis and are
called after tearDown on test failure or success.</p>
<p>Cleanup items are called even if setUp fails (unlike tearDown).</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.addTypeEqualityFunc">
<code class="descname">addTypeEqualityFunc</code><span class="sig-paren">(</span><em>typeobj</em>, <em>function</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.addTypeEqualityFunc" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a type specific assertEqual style function to compare a type.</p>
<p>This method is for use by TestCase subclasses that need to register
their own type equality functions to provide nicer error messages.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>typeobj</strong> &#8211; The data type to call this function on when both values
are of the same type in assertEqual().</li>
<li><strong>function</strong> &#8211; The callable taking two arguments and an optional
msg= argument that raises self.failureException with a
useful error message when the two arguments are not equal.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertAlmostEqual">
<code class="descname">assertAlmostEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>places=None</em>, <em>msg=None</em>, <em>delta=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are unequal as determined by their
difference rounded to the given number of decimal places
(default 7) and comparing to zero, or by comparing that the
between the two objects is more than the given delta.</p>
<p>Note that decimal places (from zero) are usually not the same
as significant digits (measured from the most significant digit).</p>
<p>If the two objects compare equal then they will automatically
compare almost equal.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertAlmostEquals">
<code class="descname">assertAlmostEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertAlmostEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertCountEqual">
<code class="descname">assertCountEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertCountEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>An unordered sequence comparison asserting that the same elements,
regardless of order.  If the same element occurs more than once,
it verifies that the elements occur the same number of times.</p>
<blockquote>
<div><blockquote>
<div><dl class="docutils">
<dt>self.assertEqual(Counter(list(first)),</dt>
<dd>Counter(list(second)))</dd>
</dl>
</div></blockquote>
<dl class="docutils">
<dt>Example:</dt>
<dd><ul class="first last simple">
<li>[0, 1, 1] and [1, 0, 1] compare equal.</li>
<li>[0, 0, 1] and [0, 1] compare unequal.</li>
</ul>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertDictContainsSubset">
<code class="descname">assertDictContainsSubset</code><span class="sig-paren">(</span><em>subset</em>, <em>dictionary</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertDictContainsSubset" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks whether dictionary is a superset of subset.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertDictEqual">
<code class="descname">assertDictEqual</code><span class="sig-paren">(</span><em>d1</em>, <em>d2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertDictEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertEqual">
<code class="descname">assertEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are unequal as determined by the &#8216;==&#8217;
operator.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertEquals">
<code class="descname">assertEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertFalse">
<code class="descname">assertFalse</code><span class="sig-paren">(</span><em>expr</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertFalse" title="Permalink to this definition">¶</a></dt>
<dd><p>Check that the expression is false.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertGreater">
<code class="descname">assertGreater</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertGreater" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &gt; b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertGreaterEqual">
<code class="descname">assertGreaterEqual</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertGreaterEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &gt;= b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIn">
<code class="descname">assertIn</code><span class="sig-paren">(</span><em>member</em>, <em>container</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIn" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a in b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIs">
<code class="descname">assertIs</code><span class="sig-paren">(</span><em>expr1</em>, <em>expr2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIs" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a is b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsInstance">
<code class="descname">assertIsInstance</code><span class="sig-paren">(</span><em>obj</em>, <em>cls</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsInstance" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as self.assertTrue(isinstance(obj, cls)), with a nicer
default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNone">
<code class="descname">assertIsNone</code><span class="sig-paren">(</span><em>obj</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNone" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as self.assertTrue(obj is None), with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNot">
<code class="descname">assertIsNot</code><span class="sig-paren">(</span><em>expr1</em>, <em>expr2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNot" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a is not b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNotNone">
<code class="descname">assertIsNotNone</code><span class="sig-paren">(</span><em>obj</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNotNone" title="Permalink to this definition">¶</a></dt>
<dd><p>Included for symmetry with assertIsNone.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLess">
<code class="descname">assertLess</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLess" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &lt; b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLessEqual">
<code class="descname">assertLessEqual</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLessEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &lt;= b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertListEqual">
<code class="descname">assertListEqual</code><span class="sig-paren">(</span><em>list1</em>, <em>list2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertListEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>A list-specific equality assertion.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>list1</strong> &#8211; The first list to compare.</li>
<li><strong>list2</strong> &#8211; The second list to compare.</li>
<li><strong>msg</strong> &#8211; Optional message to use on failure instead of a list of
differences.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLogs">
<code class="descname">assertLogs</code><span class="sig-paren">(</span><em>logger=None</em>, <em>level=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLogs" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail unless a log message of level <em>level</em> or higher is emitted
on <em>logger_name</em> or its children.  If omitted, <em>level</em> defaults to
INFO and <em>logger</em> defaults to the root logger.</p>
<p>This method must be used as a context manager, and will yield
a recording object with two attributes: <cite>output</cite> and <cite>records</cite>.
At the end of the context manager, the <cite>output</cite> attribute will
be a list of the matching formatted log messages and the
<cite>records</cite> attribute will be a list of the corresponding LogRecord
objects.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertLogs</span><span class="p">(</span><span class="s1">&#39;foo&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="s1">&#39;INFO&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">cm</span><span class="p">:</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;foo&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;first message&#39;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;foo.bar&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s1">&#39;second message&#39;</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;INFO:foo:first message&#39;</span><span class="p">,</span>
                             <span class="s1">&#39;ERROR:foo.bar:second message&#39;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertMultiLineEqual">
<code class="descname">assertMultiLineEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertMultiLineEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Assert that two multi-line strings are equal.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotAlmostEqual">
<code class="descname">assertNotAlmostEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>places=None</em>, <em>msg=None</em>, <em>delta=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are equal as determined by their
difference rounded to the given number of decimal places
(default 7) and comparing to zero, or by comparing that the
between the two objects is less than the given delta.</p>
<p>Note that decimal places (from zero) are usually not the same
as significant digits (measured from the most significant digit).</p>
<p>Objects that are equal automatically fail.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotAlmostEquals">
<code class="descname">assertNotAlmostEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotAlmostEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotEqual">
<code class="descname">assertNotEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are equal as determined by the &#8216;!=&#8217;
operator.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotEquals">
<code class="descname">assertNotEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotIn">
<code class="descname">assertNotIn</code><span class="sig-paren">(</span><em>member</em>, <em>container</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotIn" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a not in b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotIsInstance">
<code class="descname">assertNotIsInstance</code><span class="sig-paren">(</span><em>obj</em>, <em>cls</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotIsInstance" title="Permalink to this definition">¶</a></dt>
<dd><p>Included for symmetry with assertIsInstance.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotRegex">
<code class="descname">assertNotRegex</code><span class="sig-paren">(</span><em>text</em>, <em>unexpected_regex</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail the test if the text matches the regular expression.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotRegexpMatches">
<code class="descname">assertNotRegexpMatches</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotRegexpMatches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaises">
<code class="descname">assertRaises</code><span class="sig-paren">(</span><em>expected_exception</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaises" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail unless an exception of class expected_exception is raised
by the callable when invoked with specified positional and
keyword arguments. If a different type of exception is
raised, it will not be caught, and the test case will be
deemed to have suffered an error, exactly as for an
unexpected exception.</p>
<p>If called with the callable and arguments omitted, will return a
context object used like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertRaises</span><span class="p">(</span><span class="n">SomeException</span><span class="p">):</span>
    <span class="n">do_something</span><span class="p">()</span>
</pre></div>
</div>
<p>An optional keyword argument &#8216;msg&#8217; can be provided when assertRaises
is used as a context object.</p>
<p>The context manager keeps a reference to the exception as
the &#8216;exception&#8217; attribute. This allows you to inspect the
exception after the assertion:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertRaises</span><span class="p">(</span><span class="n">SomeException</span><span class="p">)</span> <span class="k">as</span> <span class="n">cm</span><span class="p">:</span>
    <span class="n">do_something</span><span class="p">()</span>
<span class="n">the_exception</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">exception</span>
<span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">the_exception</span><span class="o">.</span><span class="n">error_code</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaisesRegex">
<code class="descname">assertRaisesRegex</code><span class="sig-paren">(</span><em>expected_exception</em>, <em>expected_regex</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaisesRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Asserts that the message in a raised exception matches a regex.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>expected_exception</strong> &#8211; Exception class expected to be raised.</li>
<li><strong>expected_regex</strong> &#8211; Regex (re pattern object or string) expected
to be found in error message.</li>
<li><strong>args</strong> &#8211; Function to be called and extra positional args.</li>
<li><strong>kwargs</strong> &#8211; Extra kwargs.</li>
<li><strong>msg</strong> &#8211; Optional message used in case of failure. Can only be used
when assertRaisesRegex is used as a context manager.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaisesRegexp">
<code class="descname">assertRaisesRegexp</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaisesRegexp" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRegex">
<code class="descname">assertRegex</code><span class="sig-paren">(</span><em>text</em>, <em>expected_regex</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail the test unless the text matches the regular expression.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRegexpMatches">
<code class="descname">assertRegexpMatches</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRegexpMatches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertSequenceEqual">
<code class="descname">assertSequenceEqual</code><span class="sig-paren">(</span><em>seq1</em>, <em>seq2</em>, <em>msg=None</em>, <em>seq_type=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertSequenceEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>An equality assertion for ordered sequences (like lists and tuples).</p>
<p>For the purposes of this function, a valid ordered sequence type is one
which can be indexed, has a length, and has an equality operator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>seq1</strong> &#8211; The first sequence to compare.</li>
<li><strong>seq2</strong> &#8211; The second sequence to compare.</li>
<li><strong>seq_type</strong> &#8211; The expected datatype of the sequences, or None if no
datatype should be enforced.</li>
<li><strong>msg</strong> &#8211; Optional message to use on failure instead of a list of
differences.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertSetEqual">
<code class="descname">assertSetEqual</code><span class="sig-paren">(</span><em>set1</em>, <em>set2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertSetEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>A set-specific equality assertion.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>set1</strong> &#8211; The first set to compare.</li>
<li><strong>set2</strong> &#8211; The second set to compare.</li>
<li><strong>msg</strong> &#8211; Optional message to use on failure instead of a list of
differences.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>assertSetEqual uses ducktyping to support different types of sets, and
is optimized for sets specifically (parameters must support a
difference method).</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertTrue">
<code class="descname">assertTrue</code><span class="sig-paren">(</span><em>expr</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertTrue" title="Permalink to this definition">¶</a></dt>
<dd><p>Check that the expression is true.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertTupleEqual">
<code class="descname">assertTupleEqual</code><span class="sig-paren">(</span><em>tuple1</em>, <em>tuple2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertTupleEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>A tuple-specific equality assertion.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>tuple1</strong> &#8211; The first tuple to compare.</li>
<li><strong>tuple2</strong> &#8211; The second tuple to compare.</li>
<li><strong>msg</strong> &#8211; Optional message to use on failure instead of a list of
differences.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertWarns">
<code class="descname">assertWarns</code><span class="sig-paren">(</span><em>expected_warning</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertWarns" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail unless a warning of class warnClass is triggered
by the callable when invoked with specified positional and
keyword arguments.  If a different type of warning is
triggered, it will not be handled: depending on the other
warning filtering rules in effect, it might be silenced, printed
out, or raised as an exception.</p>
<p>If called with the callable and arguments omitted, will return a
context object used like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertWarns</span><span class="p">(</span><span class="n">SomeWarning</span><span class="p">):</span>
    <span class="n">do_something</span><span class="p">()</span>
</pre></div>
</div>
<p>An optional keyword argument &#8216;msg&#8217; can be provided when assertWarns
is used as a context object.</p>
<p>The context manager keeps a reference to the first matching
warning as the &#8216;warning&#8217; attribute; similarly, the &#8216;filename&#8217;
and &#8216;lineno&#8217; attributes give you information about the line
of Python code from which the warning was triggered.
This allows you to inspect the warning after the assertion:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertWarns</span><span class="p">(</span><span class="n">SomeWarning</span><span class="p">)</span> <span class="k">as</span> <span class="n">cm</span><span class="p">:</span>
    <span class="n">do_something</span><span class="p">()</span>
<span class="n">the_warning</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">warning</span>
<span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">the_warning</span><span class="o">.</span><span class="n">some_attribute</span><span class="p">,</span> <span class="mi">147</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertWarnsRegex">
<code class="descname">assertWarnsRegex</code><span class="sig-paren">(</span><em>expected_warning</em>, <em>expected_regex</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertWarnsRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Asserts that the message in a triggered warning matches a regexp.
Basic functioning is similar to assertWarns() with the addition
that only warnings whose messages also match the regular expression
are considered successful matches.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>expected_warning</strong> &#8211; Warning class expected to be triggered.</li>
<li><strong>expected_regex</strong> &#8211; Regex (re pattern object or string) expected
to be found in error message.</li>
<li><strong>args</strong> &#8211; Function to be called and extra positional args.</li>
<li><strong>kwargs</strong> &#8211; Extra kwargs.</li>
<li><strong>msg</strong> &#8211; Optional message used in case of failure. Can only be used
when assertWarnsRegex is used as a context manager.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assert_">
<code class="descname">assert_</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assert_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.countTestCases">
<code class="descname">countTestCases</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.countTestCases" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.debug">
<code class="descname">debug</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.debug" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the test without collecting errors in a TestResult</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.defaultTestResult">
<code class="descname">defaultTestResult</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.defaultTestResult" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.doCleanups">
<code class="descname">doCleanups</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.doCleanups" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute all cleanup functions. Normally called for you after
tearDown.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.fail">
<code class="descname">fail</code><span class="sig-paren">(</span><em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.fail" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail immediately, with the given message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIf">
<code class="descname">failIf</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIfAlmostEqual">
<code class="descname">failIfAlmostEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIfAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIfEqual">
<code class="descname">failIfEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIfEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnless">
<code class="descname">failUnless</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnless" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessAlmostEqual">
<code class="descname">failUnlessAlmostEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessEqual">
<code class="descname">failUnlessEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessRaises">
<code class="descname">failUnlessRaises</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessRaises" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failureException">
<code class="descname">failureException</code><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failureException" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference external" href="https://docs.python.org/library/exceptions.html#AssertionError" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">AssertionError</span></code></a></p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.id">
<code class="descname">id</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.id" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.longMessage">
<code class="descname">longMessage</code><em class="property"> = True</em><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.longMessage" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.maxDiff">
<code class="descname">maxDiff</code><em class="property"> = 640</em><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.maxDiff" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.run">
<code class="descname">run</code><span class="sig-paren">(</span><em>result=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.run" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.setUp">
<code class="descname">setUp</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_symmetry_functions.html#TestANIRegression.setUp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.setUp" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.setUpClass">
<code class="descname">setUpClass</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.setUpClass" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook method for setting up class fixture before running tests in the class.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.shortDescription">
<code class="descname">shortDescription</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.shortDescription" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a one-line description of the test, or None if no
description has been provided.</p>
<p>The default implementation of this method returns the first line of
the specified test method&#8217;s docstring.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.skipTest">
<code class="descname">skipTest</code><span class="sig-paren">(</span><em>reason</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.skipTest" title="Permalink to this definition">¶</a></dt>
<dd><p>Skip this test.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.subTest">
<code class="descname">subTest</code><span class="sig-paren">(</span><em>msg=&lt;object object&gt;</em>, <em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.subTest" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a context manager that will return the enclosed block
of code in a subtest identified by the optional message and
keyword parameters.  A failure in the subtest marks the test
case as failed but resumes execution at the end of the enclosed
block, allowing further test code to be executed.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.tearDown">
<code class="descname">tearDown</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.tearDown" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook method for deconstructing the test fixture after testing it.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.tearDownClass">
<code class="descname">tearDownClass</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.tearDownClass" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook method for deconstructing the class fixture after running all tests in the class.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.test_gradients">
<code class="descname">test_gradients</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_symmetry_functions.html#TestANIRegression.test_gradients"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.test_gradients" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.test_numpy_save_load">
<code class="descname">test_numpy_save_load</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_symmetry_functions.html#TestANIRegression.test_numpy_save_load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.test_numpy_save_load" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.text_cnn">
<span id="deepchem-models-tensorgraph-models-text-cnn-module"></span><h2>deepchem.models.tensorgraph.models.text_cnn module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.text_cnn" title="Permalink to this headline">¶</a></h2>
<p>Created on Thu Sep 28 15:17:50 2017</p>
<p>&#64;author: zqwu</p>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.text_cnn.</code><code class="descname">TextCNNTensorGraph</code><span class="sig-paren">(</span><em>n_tasks, char_dict, seq_length, n_embedding=75, filter_sizes=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20], num_filters=[100, 200, 200, 200, 200, 100, 100, 100, 100, 100, 160, 160], dropout=0.25, mode='classification', **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/text_cnn.html#TextCNNTensorGraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p>A Convolutional neural network on smiles strings
Reimplementation of the discriminator module in ORGAN: <a class="reference external" href="https://arxiv.org/abs/1705.10843">https://arxiv.org/abs/1705.10843</a>
Originated from: <a class="reference external" href="http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf">http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf</a></p>
<p>This model applies multiple 1D convolutional filters to the padded strings,
then max-over-time pooling is applied on all filters, extracting one feature per filter.
All features are concatenated and transformed through several hidden layers to form predictions.</p>
<p>This model is initially developed for sentence-level classification tasks, with
words represented as vectors. In this implementation, SMILES strings are dissected
into characters and transformed to one-hot vectors in a similar way. The model can
be used for general molecular-level classification or regression tasks. It is also
used in the ORGAN model as discriminator.</p>
<p>Training of the model only requires SMILES strings input, all featurized datasets
that include SMILES in the <cite>ids</cite> attribute are accepted. PDBbind, QM7 and QM7b
are not supported. To use the model, <cite>build_char_dict</cite> should be called first
before defining the model to build character dict of input dataset, example can
be found in examples/delaney/delaney_textcnn.py</p>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build_char_dict">
<em class="property">static </em><code class="descname">build_char_dict</code><span class="sig-paren">(</span><em>dataset</em>, <em>default_dict={'7': 13</em>, <em>'I': 19</em>, <em>'C': 16</em>, <em>'/': 6</em>, <em>'s': 33</em>, <em>'4': 10</em>, <em>'[': 24</em>, <em>'8': 14</em>, <em>'=': 15</em>, <em>'_': 27</em>, <em>'5': 11</em>, <em>'Br': 30</em>, <em>'-': 5</em>, <em>'6': 12</em>, <em>'c': 28</em>, <em>'F': 17</em>, <em>'n': 31</em>, <em>'1': 7</em>, <em>'H': 18</em>, <em>')': 3</em>, <em>'Cl': 29</em>, <em>'2': 8</em>, <em>'+': 4</em>, <em>']': 26</em>, <em>'3': 9</em>, <em>'\\': 25</em>, <em>'N': 20</em>, <em>'O': 21</em>, <em>'S': 23</em>, <em>'(': 2</em>, <em>'o': 32</em>, <em>'P': 22</em>, <em>'#': 1}</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/text_cnn.html#TextCNNTensorGraph.build_char_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build_char_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect all unique characters(in smiles) from the dataset.
This method should be called before defining the model to build appropriate char_dict</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/text_cnn.html#TextCNNTensorGraph.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build_graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>layers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; the list of layers to train.  If None, all layers in the model will be
trained.</li>
<li><strong>loss</strong> (<a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><em>Layer</em></a>) &#8211; the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</li>
<li><strong>optimizer</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.optimizers.Optimizer" title="deepchem.models.tensorgraph.optimizers.Optimizer"><em>Optimizer</em></a>) &#8211; the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><em>the newly created submodel, which can be passed to any of the fitting</em></li>
<li><em>methods.</em></li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/text_cnn.html#TextCNNTensorGraph.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.default_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Transfer smiles strings to fixed length integer vectors</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset object.</li>
<li><strong>metric</strong> (<a class="reference internal" href="deepchem.metrics.html#deepchem.metrics.Metric" title="deepchem.metrics.Metric"><em>deepchem.metrics.Metric</em></a>) &#8211; Evaluation metric</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of deepchem.transformers.Transformer</li>
<li><strong>per_task_metrics</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; If True, return per-task scores.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Maps tasks to scores under metric.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/library/stdtypes.html#dict" title="(in Python v3.6)">dict</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<a class="reference internal" href="deepchem.data.html#deepchem.data.datasets.Dataset" title="deepchem.data.datasets.Dataset"><em>Dataset</em></a>) &#8211; the Dataset to train on</li>
<li><strong>nb_epoch</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of epochs to train for</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>deterministic</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>feed_dict_generator</strong> (<em>generator</em>) &#8211; this should generate batches, each represented as a dict that maps
Layers to values.</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
<li><strong>submodel</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.Submodel" title="deepchem.models.tensorgraph.tensor_graph.Submodel"><em>Submodel</em></a>) &#8211; an alternate training objective to use.  This should have been created by
calling create_submodel().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>deep</strong> (<em>boolean, optional</em>) &#8211; If True, will return the parameters for this estimator and
contained subobjects that are estimators.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong> &#8211;
Parameter names mapped to their values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">mapping of string to any</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>results</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>generator</strong> (<em>Generator</em>) &#8211; Generator that constructs feed dictionaries for TensorGraph.</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
<li><strong>Returns</strong> &#8211; y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataset</strong> (<em>dc.data.Dataset</em>) &#8211; Dataset to make prediction on</li>
<li><strong>transformers</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of dc.trans.Transformers.</li>
<li><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y_pred</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>ndarray</em>) &#8211; the input data, as a Numpy array.</li>
<li><strong>transformers</strong> (<em>List</em>) &#8211; List of dc.trans.Transformers</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">numpy ndarray of shape (n_samples, n_classes*n_tasks)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">y_pred</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoints to keep.  Older checkpoints are discarded.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.smiles_to_seq">
<code class="descname">smiles_to_seq</code><span class="sig-paren">(</span><em>smiles</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/text_cnn.html#TextCNNTensorGraph.smiles_to_seq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.smiles_to_seq" title="Permalink to this definition">¶</a></dt>
<dd><p>Tokenize characters in smiles to integers</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-deepchem.models.tensorgraph.models" title="Permalink to this headline">¶</a></h2>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="_sources/deepchem.models.tensorgraph.models.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2016, Stanford University and the Authors.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>