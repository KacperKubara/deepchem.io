<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

    <title>deepchem package &mdash; deepchem 1.3.1 documentation</title>

    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.3.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="deepchem 1.3.1 documentation" href="index.html" />
    <link rel="next" title="deepchem.data package" href="deepchem.data.html" />
    <link rel="prev" title="DeepChem" href="index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-inverse navbar-default ">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html"><span><img src="_static/logo.png"></span>
          deepchem</a>
        <span class="navbar-text navbar-version pull-left"><b>1.3.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">

                <li><a href="/docs/notebooks/index.html">Tutorials</a></li>


              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="/docs/deepchem.html">master</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="/docs/2.0.0/deepchem.html">2.0.0</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="/docs/1.3.1/deepchem.html">1.3.1</a></li>
</ul>
</ul>
</li>
</ul>
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>

        </div>
    </div>
  </div>    </div>
  </div>  </div><div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="deepchem-nn-package">
<h1>deepchem.nn package<a class="headerlink" href="#deepchem-nn-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-deepchem.nn.activations">
<span id="deepchem-nn-activations-module"></span><h2>deepchem.nn.activations module<a class="headerlink" href="#module-deepchem.nn.activations" title="Permalink to this headline">¶</a></h2>
<p>Activations for models.</p>
<p>Copied over from Keras.</p>
<dl class="function">
<dt id="deepchem.nn.activations.elu">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">elu</code><span class="sig-paren">(</span><em>x</em>, <em>alpha=1.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#elu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.elu" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.get">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">get</code><span class="sig-paren">(</span><em>identifier</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#get"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.get" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.get_from_module">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">get_from_module</code><span class="sig-paren">(</span><em>identifier</em>, <em>module_params</em>, <em>module_name</em>, <em>instantiate=False</em>, <em>kwargs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#get_from_module"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.get_from_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves a class of function member of a module.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>identifier</strong> (<em>the object to retrieve. It could be specified</em>) &#8211; by name (as a string), or by dict. In any other case,
identifier itself will be returned without any changes.</li>
<li><strong>module_params</strong> (<em>the members of a module</em>) &#8211; (e.g. the output of globals()).</li>
<li><strong>module_name</strong> (<em>string; the name of the target module. Only used</em>) &#8211; to format error messages.</li>
<li><strong>instantiate</strong> (<em>whether to instantiate the returned object</em>) &#8211; (if it&#8217;s a class).</li>
<li><strong>kwargs</strong> (<em>a dictionary of keyword arguments to pass to the</em>) &#8211; class constructor if <cite>instantiate</cite> is <cite>True</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">The target object.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last">ValueError: if the identifier cannot be found.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.hard_sigmoid">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">hard_sigmoid</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#hard_sigmoid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.hard_sigmoid" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.linear">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">linear</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#linear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.linear" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.relu">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">relu</code><span class="sig-paren">(</span><em>x</em>, <em>alpha=0.0</em>, <em>max_value=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#relu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.relu" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.selu">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">selu</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#selu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.selu" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.sigmoid">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">sigmoid</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#sigmoid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.sigmoid" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.softmax">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">softmax</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#softmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.softmax" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.softplus">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">softplus</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#softplus"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.softplus" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.softsign">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">softsign</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#softsign"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.softsign" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.tanh">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">tanh</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#tanh"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.tanh" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-deepchem.nn.constraints">
<span id="deepchem-nn-constraints-module"></span><h2>deepchem.nn.constraints module<a class="headerlink" href="#module-deepchem.nn.constraints" title="Permalink to this headline">¶</a></h2>
<p>Place constraints on models.</p>
<dl class="class">
<dt id="deepchem.nn.constraints.Constraint">
<em class="property">class </em><code class="descclassname">deepchem.nn.constraints.</code><code class="descname">Constraint</code><a class="reference internal" href="_modules/deepchem/nn/constraints.html#Constraint"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.constraints.Constraint" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
</dd></dl>

<dl class="class">
<dt id="deepchem.nn.constraints.MaxNorm">
<em class="property">class </em><code class="descclassname">deepchem.nn.constraints.</code><code class="descname">MaxNorm</code><span class="sig-paren">(</span><em>m=2</em>, <em>axis=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/constraints.html#MaxNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.constraints.MaxNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.constraints.Constraint" title="deepchem.nn.constraints.Constraint"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.constraints.Constraint</span></code></a></p>
<p>MaxNorm weight constraint.</p>
<p>Constrains the weights incident to each hidden unit
to have a norm less than or equal to a desired value.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>m</strong> (<em>the maximum norm for the incoming weights.</em>) &#8211; </li>
<li><strong>axis</strong> (<em>integer, axis along which to calculate weight norms.</em>) &#8211; For instance, in a <cite>Dense</cite> layer the weight matrix
has shape (input_dim, output_dim),
set axis to 0 to constrain each weight vector
of length <cite>(input_dim,)</cite>.</li>
<li><strong>References</strong> (<em>#</em>) &#8211; <ul>
<li>[Dropout: A Simple Way to Prevent Neural Networks from Overfitting Srivastava, Hinton, et al. 2014](<a class="reference external" href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf</a>)</li>
</ul>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="deepchem.nn.constraints.NonNeg">
<em class="property">class </em><code class="descclassname">deepchem.nn.constraints.</code><code class="descname">NonNeg</code><a class="reference internal" href="_modules/deepchem/nn/constraints.html#NonNeg"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.constraints.NonNeg" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.constraints.Constraint" title="deepchem.nn.constraints.Constraint"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.constraints.Constraint</span></code></a></p>
<p>Constrains the weights to be non-negative.</p>
</dd></dl>

<dl class="class">
<dt id="deepchem.nn.constraints.UnitNorm">
<em class="property">class </em><code class="descclassname">deepchem.nn.constraints.</code><code class="descname">UnitNorm</code><span class="sig-paren">(</span><em>axis=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/constraints.html#UnitNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.constraints.UnitNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.constraints.Constraint" title="deepchem.nn.constraints.Constraint"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.constraints.Constraint</span></code></a></p>
<p>Constrains the weights incident to each hidden unit to have unit norm.</p>
<dl class="docutils">
<dt># Arguments</dt>
<dd><dl class="first last docutils">
<dt>axis: integer, axis along which to calculate weight norms.</dt>
<dd>For instance, in a <cite>Dense</cite> layer the weight matrix
has shape <cite>(input_dim, output_dim)</cite>,
set <cite>axis</cite> to <cite>0</cite> to constrain each weight vector
of length <cite>(input_dim,)</cite>.
In a <cite>Convolution2D</cite> layer with <cite>dim_ordering=&#8221;tf&#8221;</cite>,
the weight tensor has shape
<cite>(rows, cols, input_depth, output_depth)</cite>,
set <cite>axis</cite> to <cite>[0, 1, 2]</cite>
to constrain the weights of each filter tensor of size
<cite>(rows, cols, input_depth)</cite>.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.constraints.get">
<code class="descclassname">deepchem.nn.constraints.</code><code class="descname">get</code><span class="sig-paren">(</span><em>identifier</em>, <em>kwargs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/constraints.html#get"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.constraints.get" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.nn.constraints.maxnorm">
<code class="descclassname">deepchem.nn.constraints.</code><code class="descname">maxnorm</code><a class="headerlink" href="#deepchem.nn.constraints.maxnorm" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#deepchem.nn.constraints.MaxNorm" title="deepchem.nn.constraints.MaxNorm"><code class="xref py py-class docutils literal"><span class="pre">MaxNorm</span></code></a></p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.nn.constraints.nonneg">
<code class="descclassname">deepchem.nn.constraints.</code><code class="descname">nonneg</code><a class="headerlink" href="#deepchem.nn.constraints.nonneg" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#deepchem.nn.constraints.NonNeg" title="deepchem.nn.constraints.NonNeg"><code class="xref py py-class docutils literal"><span class="pre">NonNeg</span></code></a></p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.nn.constraints.unitnorm">
<code class="descclassname">deepchem.nn.constraints.</code><code class="descname">unitnorm</code><a class="headerlink" href="#deepchem.nn.constraints.unitnorm" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#deepchem.nn.constraints.UnitNorm" title="deepchem.nn.constraints.UnitNorm"><code class="xref py py-class docutils literal"><span class="pre">UnitNorm</span></code></a></p>
</dd></dl>

</div>
<div class="section" id="module-deepchem.nn.copy">
<span id="deepchem-nn-copy-module"></span><h2>deepchem.nn.copy module<a class="headerlink" href="#module-deepchem.nn.copy" title="Permalink to this headline">¶</a></h2>
<p>Copies Classes from keras to remove dependency.</p>
<p>Most of this code is copied over from Keras. Hoping to use as a staging
area while we remove our Keras dependency.</p>
<dl class="class">
<dt id="deepchem.nn.copy.BatchNormalization">
<em class="property">class </em><code class="descclassname">deepchem.nn.copy.</code><code class="descname">BatchNormalization</code><span class="sig-paren">(</span><em>epsilon=0.001</em>, <em>mode=0</em>, <em>axis=-1</em>, <em>momentum=0.99</em>, <em>beta_init='zero'</em>, <em>gamma_init='one'</em>, <em>gamma_regularizer=None</em>, <em>beta_regularizer=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#BatchNormalization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.BatchNormalization" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Batch normalization layer (Ioffe and Szegedy, 2014).</p>
<p>Normalize the activations of the previous layer at each batch,
i.e. applies a transformation that maintains the mean activation
close to 0 and the activation standard deviation close to 1.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>epsilon</strong> (<em>small float &gt; 0. Fuzz parameter.</em>) &#8211; </li>
<li><strong>mode</strong> (<em>integer, 0, 1 or 2.</em>) &#8211; <ul>
<li><dl class="first docutils">
<dt>0: feature-wise normalization.</dt>
<dd>Each feature map in the input will
be normalized separately. The axis on which
to normalize is specified by the <cite>axis</cite> argument.
During training we use per-batch statistics to normalize
the data, and during testing we use running averages
computed during the training phase.</dd>
</dl>
</li>
<li>1: sample-wise normalization. This mode assumes a 2D input.</li>
<li><dl class="first docutils">
<dt>2: feature-wise normalization, like mode 0, but</dt>
<dd>using per-batch statistics to normalize the data during both
testing and training.</dd>
</dl>
</li>
</ul>
</li>
<li><strong>axis</strong> (<em>integer, axis along which to normalize in mode 0. For instance,</em>) &#8211; if your input tensor has shape (samples, channels, rows, cols),
set axis to 1 to normalize per feature map (channels axis).</li>
<li><strong>momentum</strong> (<em>momentum in the computation of the</em>) &#8211; exponential average of the mean and standard deviation
of the data, for feature-wise normalization.</li>
<li><strong>beta_init</strong> (<em>name of initialization function for shift parameter, or</em>) &#8211; alternatively, TensorFlow function to use for weights initialization.</li>
<li><strong>gamma_init</strong> (<em>name of initialization function for scale parameter, or</em>) &#8211; alternatively, TensorFlow function to use for weights initialization.</li>
<li><strong>gamma_regularizer</strong> (<em>instance of WeightRegularizer</em>) &#8211; (eg. L1 or L2 regularization), applied to the gamma vector.</li>
<li><strong>beta_regularizer</strong> (<em>instance of WeightRegularizer,</em>) &#8211; applied to the beta vector.</li>
<li><strong>shape</strong> (<em>Output</em>) &#8211; </li>
<li><strong>Use the keyword argument input_shape</strong> (<em>Arbitrary.</em>) &#8211; </li>
<li><strong>of integers, does not include the samples axis)</strong> (<em>(tuple</em>) &#8211; </li>
<li><strong>using this layer as the first layer in a model.</strong> (<em>when</em>) &#8211; </li>
<li><strong>shape</strong> &#8211; </li>
<li><strong>shape as input.</strong> (<em>Same</em>) &#8211; </li>
<li><strong>References</strong> &#8211; <ul>
<li>[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](<a class="reference external" href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a>)</li>
</ul>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.copy.BatchNormalization.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.BatchNormalization.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.BatchNormalization.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.BatchNormalization.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.BatchNormalization.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.BatchNormalization.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.BatchNormalization.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#BatchNormalization.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.BatchNormalization.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.BatchNormalization.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#BatchNormalization.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.BatchNormalization.call" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.copy.Dense">
<em class="property">class </em><code class="descclassname">deepchem.nn.copy.</code><code class="descname">Dense</code><span class="sig-paren">(</span><em>output_dim</em>, <em>input_dim</em>, <em>init='glorot_uniform'</em>, <em>activation='relu'</em>, <em>bias=True</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Dense"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Dense" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Just your regular densely-connected NN layer.</p>
<p>TODO(rbharath): Make this functional in deepchem</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">deepchem</span> <span class="kn">as</span> <span class="nn">dc</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># as first layer in a sequential model:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">dc</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="mi">16</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">dc</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># now the model will take as input arrays of shape (*, 16)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and output arrays of shape (*, 32)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># this is equivalent to the above:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">dc</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="mi">16</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">dc</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">))</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>output_dim</strong> (<em>int &gt; 0.</em>) &#8211; </li>
<li><strong>init</strong> (<em>name of initialization function for the weights of the layer</em>) &#8211; </li>
<li><strong>activation</strong> (<em>name of activation function to use</em>) &#8211; (see [activations](../activations.md)).
If you don&#8217;t specify anything, no activation is applied
(ie. &#8220;linear&#8221; activation: a(x) = x).</li>
<li><strong>W_regularizer</strong> (<em>(eg. L1 or L2 regularization), applied to the main weights matrix.</em>) &#8211; </li>
<li><strong>b_regularizer</strong> (<em>instance of regularize applied to the bias.</em>) &#8211; </li>
<li><strong>activity_regularizer</strong> (<em>instance of [ActivityRegularizer](../regularizers.md),</em>) &#8211; applied to the network output.</li>
<li><strong>bias</strong> (<em>whether to include a bias</em>) &#8211; (i.e. make the layer affine rather than linear).</li>
<li><strong>input_dim</strong> (<em>dimensionality of the input (integer). This argument</em>) &#8211; (or alternatively, the keyword argument <cite>input_shape</cite>)
is required when using this layer as the first layer in a model.</li>
<li><strong>Input shape</strong> (<em>#</em>) &#8211; nD tensor with shape: (nb_samples, ..., input_dim).
The most common situation would be
a 2D input with shape (nb_samples, input_dim).</li>
<li><strong>Output shape</strong> (<em>#</em>) &#8211; nD tensor with shape: (nb_samples, ..., output_dim).
For instance, for a 2D input with shape <cite>(nb_samples, input_dim)</cite>,
the output would have shape <cite>(nb_samples, output_dim)</cite>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.copy.Dense.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.Dense.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.Dense.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.Dense.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.Dense.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.Dense.call" title="Permalink to this definition">¶</a></dt>
<dd><p>This is where the layer&#8217;s logic lives.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>input tensor, or list/tuple of input tensors.</em>) &#8211; </td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">A tensor or list/tuple of tensors.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.copy.Dropout">
<em class="property">class </em><code class="descclassname">deepchem.nn.copy.</code><code class="descname">Dropout</code><span class="sig-paren">(</span><em>p</em>, <em>seed=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Dropout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Dropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Applies Dropout to the input.</p>
<p>Dropout consists in randomly setting
a fraction <cite>p</cite> of input units to 0 at each update during training time,
which helps prevent overfitting.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>p</strong> (<em>float between 0 and 1. Fraction of the input units to drop.</em>) &#8211; </li>
<li><strong>seed</strong> (<em>A Python integer to use as random seed.</em>) &#8211; </li>
<li><strong>References</strong> (<em>#</em>) &#8211; <ul>
<li>[Dropout: A Simple Way to Prevent Neural Networks from Overfitting](<a class="reference external" href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf</a>)</li>
</ul>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.copy.Dropout.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.Dropout.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.Dropout.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.Dropout.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.Dropout.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.Dropout.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.Dropout.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Dropout.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Dropout.call" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="deepchem.nn.copy.Input">
<code class="descclassname">deepchem.nn.copy.</code><code class="descname">Input</code><span class="sig-paren">(</span><em>shape=None</em>, <em>batch_shape=None</em>, <em>name=None</em>, <em>dtype=tf.float32</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Input" title="Permalink to this definition">¶</a></dt>
<dd><p>Input() is used to create a placeholder input</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>A shape tuple (integer), not including the batch size.</em>) &#8211; For instance, <cite>shape=(32,)</cite> indicates that the expected input
will be batches of 32-dimensional vectors.</li>
<li><strong>name</strong> (<em>An optional name string for the layer.</em>) &#8211; Should be unique in a model (do not reuse the same name twice).
It will be autogenerated if it isn&#8217;t provided.</li>
<li><strong>dtype</strong> (<em>The data type expected by the input, as a string</em>) &#8211; (<cite>float32</cite>, <cite>float64</cite>, <cite>int32</cite>...)</li>
<li><strong>TODO(rbharath)</strong> (<em>#</em>) &#8211; </li>
<li><strong>Example</strong> &#8211; </li>
<li><strong># this is a logistic regression in Keras</strong> (<em>&gt;&gt;&gt;</em>) &#8211; </li>
<li><strong>a = dc.nn.Input(shape=(32,))</strong> (<em>&gt;&gt;&gt;</em>) &#8211; </li>
<li><strong>b = dc.nn.Dense(16)(a)</strong> (<em>&gt;&gt;&gt;</em>) &#8211; </li>
<li><strong>model = dc.nn.FunctionalModel(input=a, output=b)</strong> (<em>&gt;&gt;&gt;</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="deepchem.nn.copy.InputLayer">
<em class="property">class </em><code class="descclassname">deepchem.nn.copy.</code><code class="descname">InputLayer</code><span class="sig-paren">(</span><em>input_shape=None</em>, <em>batch_input_shape=None</em>, <em>input_dtype=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#InputLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.InputLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Layer to be used as an entry point into a graph.</p>
<p>Create its a placeholder tensor (pass arguments <cite>input_shape</cite>
or <cite>batch_input_shape</cite> as well as <cite>input_dtype</cite>).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input_shape</strong> (<em>Shape tuple, not including the batch axis.</em>) &#8211; </li>
<li><strong>batch_input_shape</strong> (<em>Shape tuple, including the batch axis.</em>) &#8211; </li>
<li><strong>input_dtype</strong> (<em>Datatype of the input.</em>) &#8211; </li>
<li><strong>name</strong> (<em>Name of the layer (string).</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.copy.InputLayer.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.InputLayer.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.InputLayer.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.InputLayer.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.InputLayer.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.InputLayer.call" title="Permalink to this definition">¶</a></dt>
<dd><p>This is where the layer&#8217;s logic lives.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>input tensor, or list/tuple of input tensors.</em>) &#8211; </td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">A tensor or list/tuple of tensors.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.copy.Layer">
<em class="property">class </em><code class="descclassname">deepchem.nn.copy.</code><code class="descname">Layer</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
<p>Abstract base layer class.</p>
<dl class="attribute">
<dt id="deepchem.nn.copy.Layer.name">
<code class="descname">name</code><a class="headerlink" href="#deepchem.nn.copy.Layer.name" title="Permalink to this definition">¶</a></dt>
<dd><p><em>String, must be unique within a model.</em></p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.nn.copy.Layer.trainable">
<code class="descname">trainable</code><a class="headerlink" href="#deepchem.nn.copy.Layer.trainable" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Boolean, whether the layer weights</em></p>
<p>will be updated during training.</p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.nn.copy.Layer.uses_learning_phase">
<code class="descname">uses_learning_phase</code><a class="headerlink" href="#deepchem.nn.copy.Layer.uses_learning_phase" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Whether any operation</em></p>
<p>of the layer uses model_ops.in_training_phase()
or model_ops.in_test_phase().</p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.nn.copy.Layer.input_shape">
<code class="descname">input_shape</code><a class="headerlink" href="#deepchem.nn.copy.Layer.input_shape" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Shape tuple. Provided for convenience,</em></p>
<p>but note that there may be cases in which this
attribute is ill-defined (e.g. a shared layer
with multiple input shapes), in which case
requesting input_shape will raise an Exception.
Prefer using layer.get_input_shape_for(input_shape),</p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.nn.copy.Layer.output_shape">
<code class="descname">output_shape</code><a class="headerlink" href="#deepchem.nn.copy.Layer.output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Shape tuple. See above.</em></p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">input, output</code></dt>
<dd><p><em>Input/output tensor(s). Note that if the layer is used</em></p>
<p>more than once (shared layer), this is ill-defined
and will raise an exception. In such cases, use</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">call(x): Where the layer's logic lives.</code></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">__call__(x): Wrapper around the layer logic (`call`).</code></dt>
<dd><dl class="docutils">
<dt>If x is a tensor:</dt>
<dd><ul class="first last simple">
<li>Connect current layer with last layer from tensor:</li>
<li>Add layer to tensor history</li>
</ul>
</dd>
</dl>
<p>If layer is not built:</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.Layer.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Layer.__call__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Layer.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.Layer.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Layer.add_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Layer.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.Layer.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Layer.add_weight"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Layer.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.Layer.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Layer.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Layer.call" title="Permalink to this definition">¶</a></dt>
<dd><p>This is where the layer&#8217;s logic lives.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>input tensor, or list/tuple of input tensors.</em>) &#8211; </td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">A tensor or list/tuple of tensors.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="deepchem.nn.copy.object_list_uid">
<code class="descclassname">deepchem.nn.copy.</code><code class="descname">object_list_uid</code><span class="sig-paren">(</span><em>object_list</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#object_list_uid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.object_list_uid" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.copy.to_list">
<code class="descclassname">deepchem.nn.copy.</code><code class="descname">to_list</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#to_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.to_list" title="Permalink to this definition">¶</a></dt>
<dd><p>This normalizes a list/tensor into a list.</p>
<p>If a tensor is passed, we return
a list of size 1 containing the tensor.</p>
</dd></dl>

</div>
<div class="section" id="module-deepchem.nn.initializations">
<span id="deepchem-nn-initializations-module"></span><h2>deepchem.nn.initializations module<a class="headerlink" href="#module-deepchem.nn.initializations" title="Permalink to this headline">¶</a></h2>
<p>Ops for tensor initialization</p>
<dl class="function">
<dt id="deepchem.nn.initializations.get">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">get</code><span class="sig-paren">(</span><em>identifier</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#get"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.get" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.get_fans">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">get_fans</code><span class="sig-paren">(</span><em>shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#get_fans"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.get_fans" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.glorot_normal">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">glorot_normal</code><span class="sig-paren">(</span><em>shape</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#glorot_normal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.glorot_normal" title="Permalink to this definition">¶</a></dt>
<dd><p>Glorot normal variance scaling initializer.</p>
<dl class="docutils">
<dt># References</dt>
<dd>Glorot &amp; Bengio, AISTATS 2010</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.glorot_uniform">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">glorot_uniform</code><span class="sig-paren">(</span><em>shape</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#glorot_uniform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.glorot_uniform" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.he_normal">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">he_normal</code><span class="sig-paren">(</span><em>shape</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#he_normal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.he_normal" title="Permalink to this definition">¶</a></dt>
<dd><p>He normal variance scaling initializer.</p>
<dl class="docutils">
<dt># References</dt>
<dd>He et al., <a class="reference external" href="http://arxiv.org/abs/1502.01852">http://arxiv.org/abs/1502.01852</a></dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.he_uniform">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">he_uniform</code><span class="sig-paren">(</span><em>shape</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#he_uniform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.he_uniform" title="Permalink to this definition">¶</a></dt>
<dd><p>He uniform variance scaling initializer.</p>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.identity">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">identity</code><span class="sig-paren">(</span><em>shape</em>, <em>scale=1</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#identity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.identity" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.lecun_uniform">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">lecun_uniform</code><span class="sig-paren">(</span><em>shape</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#lecun_uniform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.lecun_uniform" title="Permalink to this definition">¶</a></dt>
<dd><p>LeCun uniform variance scaling initializer.</p>
<dl class="docutils">
<dt># References</dt>
<dd>LeCun 98, Efficient Backprop,
<a class="reference external" href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf</a></dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.normal">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">normal</code><span class="sig-paren">(</span><em>shape</em>, <em>scale=0.05</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#normal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.normal" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.one">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">one</code><span class="sig-paren">(</span><em>shape</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#one"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.one" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.orthogonal">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">orthogonal</code><span class="sig-paren">(</span><em>shape</em>, <em>scale=1.1</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#orthogonal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.orthogonal" title="Permalink to this definition">¶</a></dt>
<dd><p>Orthogonal initializer.</p>
<dl class="docutils">
<dt># References</dt>
<dd>Saxe et al., <a class="reference external" href="http://arxiv.org/abs/1312.6120">http://arxiv.org/abs/1312.6120</a></dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.uniform">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">uniform</code><span class="sig-paren">(</span><em>shape</em>, <em>scale=0.05</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#uniform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.uniform" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.zero">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">zero</code><span class="sig-paren">(</span><em>shape</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#zero"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.zero" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-deepchem.nn.layers">
<span id="deepchem-nn-layers-module"></span><h2>deepchem.nn.layers module<a class="headerlink" href="#module-deepchem.nn.layers" title="Permalink to this headline">¶</a></h2>
<p>Custom Keras Layers.</p>
<dl class="class">
<dt id="deepchem.nn.layers.AttnLSTMEmbedding">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">AttnLSTMEmbedding</code><span class="sig-paren">(</span><em>n_test</em>, <em>n_support</em>, <em>n_feat</em>, <em>max_depth</em>, <em>init='glorot_uniform'</em>, <em>activation='linear'</em>, <em>dropout=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#AttnLSTMEmbedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.AttnLSTMEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Implements AttnLSTM as in matching networks paper.</p>
<p>References:
Matching Networks for One Shot Learning
<a class="reference external" href="https://arxiv.org/pdf/1606.04080v1.pdf">https://arxiv.org/pdf/1606.04080v1.pdf</a></p>
<p>Order Matters: Sequence to sequence for sets
<a class="reference external" href="https://arxiv.org/abs/1511.06391">https://arxiv.org/abs/1511.06391</a></p>
<dl class="method">
<dt id="deepchem.nn.layers.AttnLSTMEmbedding.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.AttnLSTMEmbedding.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.AttnLSTMEmbedding.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.AttnLSTMEmbedding.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.AttnLSTMEmbedding.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.AttnLSTMEmbedding.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.AttnLSTMEmbedding.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x_xp</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#AttnLSTMEmbedding.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.AttnLSTMEmbedding.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x_xp</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of two tensors (X, Xp). X should be of shape (n_test, n_feat) and
Xp should be of shape (n_support, n_feat) where n_test is the size of
the test set, n_support that of the support set, and n_feat is the number
of per-atom features.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Returns two tensors of same shape as input. Namely the output shape will
be [(n_test, n_feat), (n_support, n_feat)]</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)">list</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.AttnLSTMEmbedding.compute_mask">
<code class="descname">compute_mask</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#AttnLSTMEmbedding.compute_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.AttnLSTMEmbedding.compute_mask" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.AttnLSTMEmbedding.get_output_shape_for">
<code class="descname">get_output_shape_for</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#AttnLSTMEmbedding.get_output_shape_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.AttnLSTMEmbedding.get_output_shape_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the output shape. Same as input_shape.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input_shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; Will be of form [(n_test, n_feat), (n_support, n_feat)]</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Of same shape as input [(n_test, n_feat), (n_support, n_feat)]</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)">list</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.DAGGather">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">DAGGather</code><span class="sig-paren">(</span><em>n_graph_feat=30, n_outputs=30, max_atoms=50, layer_sizes=[100], init='glorot_uniform', activation='relu', dropout=None, **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGGather"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGGather" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Gather layer of DAG model
for each molecule, graph outputs are summed and input into another NN</p>
<dl class="method">
<dt id="deepchem.nn.layers.DAGGather.DAGgraph_step">
<code class="descname">DAGgraph_step</code><span class="sig-paren">(</span><em>batch_inputs</em>, <em>W_list</em>, <em>b_list</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGGather.DAGgraph_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGGather.DAGgraph_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGGather.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DAGGather.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGGather.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DAGGather.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGGather.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DAGGather.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGGather.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGGather.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGGather.build" title="Permalink to this definition">¶</a></dt>
<dd><p>&#8220;Construct internal trainable weights.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGGather.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGGather.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGGather.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>x = [graph_features, membership]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>tf.Tensor</em>) &#8211; Tensor of each atom&#8217;s graph features</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>outputs</strong> &#8211;
Tensor of each molecule&#8217;s features</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">tf.Tensor</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.DAGLayer">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">DAGLayer</code><span class="sig-paren">(</span><em>n_graph_feat=30, n_atom_feat=75, max_atoms=50, layer_sizes=[100], init='glorot_uniform', activation='relu', dropout=None, batch_size=64, **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>&#8221; Main layer of DAG model
For a molecule with n atoms, n different graphs are generated and run through
The final outputs of each graph become the graph features of corresponding
atom, which will be summed and put into another network in DAGGather Layer</p>
<dl class="method">
<dt id="deepchem.nn.layers.DAGLayer.DAGgraph_step">
<code class="descname">DAGgraph_step</code><span class="sig-paren">(</span><em>batch_inputs</em>, <em>W_list</em>, <em>b_list</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGLayer.DAGgraph_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGLayer.DAGgraph_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGLayer.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DAGLayer.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGLayer.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DAGLayer.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGLayer.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DAGLayer.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGLayer.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGLayer.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGLayer.build" title="Permalink to this definition">¶</a></dt>
<dd><p>&#8220;Construct internal trainable weights.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGLayer.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGLayer.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGLayer.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>x = [atom_features, parents, calculation_orders, calculation_masks, membership, n_atoms]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; list of Tensors of form described above.</li>
<li><strong>mask</strong> (<em>bool, optional</em>) &#8211; Ignored. Present only to shadow superclass call() method.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>outputs</strong> &#8211;
Tensor of atom features, of shape (n_atoms, n_graph_feat)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.DTNNEmbedding">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">DTNNEmbedding</code><span class="sig-paren">(</span><em>n_embedding=30</em>, <em>periodic_table_length=30</em>, <em>init='glorot_uniform'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNEmbedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Generate embeddings for all atoms in the batch</p>
<dl class="method">
<dt id="deepchem.nn.layers.DTNNEmbedding.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DTNNEmbedding.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNEmbedding.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DTNNEmbedding.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNEmbedding.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DTNNEmbedding.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNEmbedding.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNEmbedding.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNEmbedding.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNEmbedding.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNEmbedding.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNEmbedding.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>Tensor</em>) &#8211; 1D tensor of length n_atoms (atomic number)</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Of shape (n_atoms, n_embedding), where n_embedding is number of atom features</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">tf.Tensor</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.DTNNGather">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">DTNNGather</code><span class="sig-paren">(</span><em>n_embedding=30, n_outputs=100, layer_sizes=[100], output_activation=True, init='glorot_uniform', activation='tanh', **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNGather"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNGather" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Map the atomic features into molecular properties and sum</p>
<dl class="method">
<dt id="deepchem.nn.layers.DTNNGather.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DTNNGather.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNGather.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DTNNGather.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNGather.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DTNNGather.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNGather.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNGather.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNGather.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNGather.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNGather.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNGather.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>list of Tensor</em>) &#8211; should be [embedding tensor of molecules, of shape (batch_size*max_n_atoms*n_embedding),
mask tensor of molecules, of shape (batch_size*max_n_atoms)]</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Of shape (batch_size)</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">list of tf.Tensor</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.DTNNStep">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">DTNNStep</code><span class="sig-paren">(</span><em>n_embedding=30</em>, <em>n_distance=100</em>, <em>n_hidden=60</em>, <em>init='glorot_uniform'</em>, <em>activation='tanh'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNStep"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNStep" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>A convolution step that merge in distance and atom info of
all other atoms into current atom.</p>
<p>model based on <a class="reference external" href="https://arxiv.org/abs/1609.08259">https://arxiv.org/abs/1609.08259</a></p>
<dl class="method">
<dt id="deepchem.nn.layers.DTNNStep.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DTNNStep.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNStep.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DTNNStep.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNStep.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DTNNStep.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNStep.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNStep.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNStep.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNStep.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNStep.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNStep.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>list of Tensor</em>) &#8211; should be [atom_features: n_atoms*n_embedding,
distance_matrix: n_pairs*n_distance,
atom_membership: n_atoms
distance_membership_i: n_pairs,
distance_membership_j: n_pairs,
]</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">new embeddings for atoms, same shape as x[0]</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">tf.Tensor</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.GraphConv">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">GraphConv</code><span class="sig-paren">(</span><em>nb_filter</em>, <em>n_atom_features</em>, <em>init='glorot_uniform'</em>, <em>activation='linear'</em>, <em>dropout=None</em>, <em>max_deg=10</em>, <em>min_deg=0</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphConv" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>&#8220;Performs a graph convolution.</p>
<p>Note this layer expects the presence of placeholders defined by GraphTopology
and expects that they follow the ordering provided by
GraphTopology.get_input_placeholders().</p>
<dl class="method">
<dt id="deepchem.nn.layers.GraphConv.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.GraphConv.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphConv.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.GraphConv.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphConv.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.GraphConv.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphConv.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphConv.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphConv.build" title="Permalink to this definition">¶</a></dt>
<dd><p>&#8220;Construct internal trainable weights.</p>
<p>n_atom_features should provide the number of features per atom.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>n_atom_features</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; Number of features provied per atom.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphConv.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphConv.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphConv.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>This layer is meant to be executed on a Graph. So x is expected to
be a list of placeholders, with the first placeholder the list of
atom_features (learned or input) at this level, the second the deg_slice,
the third the membership, and the remaining the deg_adj_lists.</p>
<p>Visually</p>
<p>x = [atom_features, deg_slice, membership, deg_adj_list placeholders...]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; list of Tensors of form described above.</li>
<li><strong>mask</strong> (<em>bool, optional</em>) &#8211; Ignored. Present only to shadow superclass call() method.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>atom_features</strong> &#8211;
Of shape (n_atoms, nb_filter)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphConv.get_output_shape_for">
<code class="descname">get_output_shape_for</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphConv.get_output_shape_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphConv.get_output_shape_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Output tensor shape produced by this layer.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.GraphGather">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">GraphGather</code><span class="sig-paren">(</span><em>batch_size</em>, <em>activation='linear'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphGather"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphGather" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Gathers information for each molecule.</p>
<p>The various graph convolution operations expect as input a tensor
atom_features of shape (n_atoms, n_feat). However, we train on batches of
molecules at a time. The GraphTopology object groups a list of molecules
into the atom_features tensor. The tensorial operations are done on this tensor,
but at the end, the atoms need to be grouped back into molecules. This
layer takes care of that operation.</p>
<p>Note this layer expects the presence of placeholders defined by GraphTopology
and expects that they follow the ordering provided by
GraphTopology.get_input_placeholders().</p>
<dl class="method">
<dt id="deepchem.nn.layers.GraphGather.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.GraphGather.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphGather.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.GraphGather.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphGather.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.GraphGather.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphGather.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphGather.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphGather.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Nothing needed (no learnable weights).</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphGather.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphGather.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphGather.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>This layer is meant to be executed on a Graph. So x is expected to
be a list of placeholders, with the first placeholder the list of
atom_features (learned or input) at this level, the second the deg_slice,
the third the membership, and the remaining the deg_adj_lists.</p>
<p>Visually</p>
<p>x = [atom_features, deg_slice, membership, deg_adj_list placeholders...]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; list of Tensors of form described above.</li>
<li><strong>mask</strong> (<em>bool, optional</em>) &#8211; Ignored. Present only to shadow superclass call() method.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Of shape (batch_size, n_feat), where n_feat is number of atom_features</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphGather.get_output_shape_for">
<code class="descname">get_output_shape_for</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphGather.get_output_shape_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphGather.get_output_shape_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Output tensor shape produced by this layer.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.GraphPool">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">GraphPool</code><span class="sig-paren">(</span><em>max_deg=10</em>, <em>min_deg=0</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphPool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphPool" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Performs a pooling operation over an arbitrary graph.</p>
<p>Performs a max pool over the feature vectors for an atom and its neighbors
in bond-graph. Returns a tensor of the same size as the input.</p>
<dl class="method">
<dt id="deepchem.nn.layers.GraphPool.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.GraphPool.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphPool.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.GraphPool.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphPool.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.GraphPool.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphPool.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphPool.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphPool.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Nothing needed (no learnable weights).</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphPool.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphPool.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphPool.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>This layer is meant to be executed on a Graph. So x is expected to
be a list of placeholders, with the first placeholder the list of
atom_features (learned or input) at this level, the second the deg_slice,
the third the membership, and the remaining the deg_adj_lists.</p>
<p>Visually</p>
<p>x = [atom_features, deg_slice, membership, deg_adj_list placeholders...]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; list of Tensors of form described above.</li>
<li><strong>mask</strong> (<em>bool, optional</em>) &#8211; Ignored. Present only to shadow superclass call() method.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Of shape (n_atoms, n_feat), where n_feat is number of atom_features</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphPool.get_output_shape_for">
<code class="descname">get_output_shape_for</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphPool.get_output_shape_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphPool.get_output_shape_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Output tensor shape produced by this layer.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.LSTMStep">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">LSTMStep</code><span class="sig-paren">(</span><em>output_dim</em>, <em>input_dim</em>, <em>init='glorot_uniform'</em>, <em>inner_init='orthogonal'</em>, <em>forget_bias_init='one'</em>, <em>activation='tanh'</em>, <em>inner_activation='hard_sigmoid'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#LSTMStep"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.LSTMStep" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>LSTM whose call is a single step in the LSTM.</p>
<p>This layer exists because the Keras LSTM layer is intrinsically linked to an
RNN with sequence inputs, and here, we will not be using sequence inputs, but
rather we generate a sequence of inputs using the intermediate outputs of the
LSTM, and so will require step by step operation of the lstm</p>
<dl class="method">
<dt id="deepchem.nn.layers.LSTMStep.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.LSTMStep.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.LSTMStep.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.LSTMStep.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.LSTMStep.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.LSTMStep.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.LSTMStep.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#LSTMStep.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.LSTMStep.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.LSTMStep.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x_states</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#LSTMStep.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.LSTMStep.call" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.LSTMStep.get_initial_states">
<code class="descname">get_initial_states</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#LSTMStep.get_initial_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.LSTMStep.get_initial_states" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.LSTMStep.get_output_shape_for">
<code class="descname">get_output_shape_for</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#LSTMStep.get_output_shape_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.LSTMStep.get_output_shape_for" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.ResiLSTMEmbedding">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">ResiLSTMEmbedding</code><span class="sig-paren">(</span><em>n_test</em>, <em>n_support</em>, <em>n_feat</em>, <em>max_depth</em>, <em>init='glorot_uniform'</em>, <em>activation='linear'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#ResiLSTMEmbedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.ResiLSTMEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Embeds its inputs using an LSTM layer.</p>
<dl class="method">
<dt id="deepchem.nn.layers.ResiLSTMEmbedding.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.ResiLSTMEmbedding.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.ResiLSTMEmbedding.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.ResiLSTMEmbedding.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.ResiLSTMEmbedding.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.ResiLSTMEmbedding.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.ResiLSTMEmbedding.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#ResiLSTMEmbedding.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.ResiLSTMEmbedding.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds this layer.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.ResiLSTMEmbedding.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>argument</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#ResiLSTMEmbedding.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.ResiLSTMEmbedding.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>argument</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of two tensors (X, Xp). X should be of shape (n_test, n_feat) and
Xp should be of shape (n_support, n_feat) where n_test is the size of
the test set, n_support that of the support set, and n_feat is the number
of per-atom features.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Returns two tensors of same shape as input. Namely the output shape will
be [(n_test, n_feat), (n_support, n_feat)]</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)">list</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.ResiLSTMEmbedding.compute_mask">
<code class="descname">compute_mask</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#ResiLSTMEmbedding.compute_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.ResiLSTMEmbedding.compute_mask" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.ResiLSTMEmbedding.get_output_shape_for">
<code class="descname">get_output_shape_for</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#ResiLSTMEmbedding.get_output_shape_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.ResiLSTMEmbedding.get_output_shape_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the output shape. Same as input_shape.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input_shape</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; Will be of form [(n_test, n_feat), (n_support, n_feat)]</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Of same shape as input [(n_test, n_feat), (n_support, n_feat)]</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)">list</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="deepchem.nn.layers.affine">
<code class="descclassname">deepchem.nn.layers.</code><code class="descname">affine</code><span class="sig-paren">(</span><em>x</em>, <em>W</em>, <em>b</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#affine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.affine" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.layers.cos">
<code class="descclassname">deepchem.nn.layers.</code><code class="descname">cos</code><span class="sig-paren">(</span><em>x</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#cos"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.cos" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.layers.graph_conv">
<code class="descclassname">deepchem.nn.layers.</code><code class="descname">graph_conv</code><span class="sig-paren">(</span><em>atoms</em>, <em>deg_adj_lists</em>, <em>deg_slice</em>, <em>max_deg</em>, <em>min_deg</em>, <em>W_list</em>, <em>b_list</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#graph_conv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.graph_conv" title="Permalink to this definition">¶</a></dt>
<dd><p>Core tensorflow function implementing graph convolution</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>atoms</strong> (<em>tf.Tensor</em>) &#8211; Should be of shape (n_atoms, n_feat)</li>
<li><strong>deg_adj_lists</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; Of length (max_deg+1-min_deg). The deg-th element is a list of
adjacency lists for atoms of degree deg.</li>
<li><strong>deg_slice</strong> (<em>tf.Tensor</em>) &#8211; Of shape (max_deg+1-min_deg,2). Explained in GraphTopology.</li>
<li><strong>max_deg</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; Maximum degree of atoms in molecules.</li>
<li><strong>min_deg</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; Minimum degree of atoms in molecules</li>
<li><strong>W_list</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of learnable weights for convolution.</li>
<li><strong>b_list</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; List of learnable biases for convolution.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Of shape (n_atoms, n_feat)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.layers.graph_gather">
<code class="descclassname">deepchem.nn.layers.</code><code class="descname">graph_gather</code><span class="sig-paren">(</span><em>atoms</em>, <em>membership_placeholder</em>, <em>batch_size</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#graph_gather"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.graph_gather" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>atoms</strong> (<em>tf.Tensor</em>) &#8211; Of shape (n_atoms, n_feat)</li>
<li><strong>membership_placeholder</strong> (<em>tf.Placeholder</em>) &#8211; Of shape (n_atoms,). Molecule each atom belongs to.</li>
<li><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; Batch size for deep model.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Of shape (batch_size, n_feat)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.layers.graph_pool">
<code class="descclassname">deepchem.nn.layers.</code><code class="descname">graph_pool</code><span class="sig-paren">(</span><em>atoms</em>, <em>deg_adj_lists</em>, <em>deg_slice</em>, <em>max_deg</em>, <em>min_deg</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#graph_pool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.graph_pool" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>atoms</strong> (<em>tf.Tensor</em>) &#8211; Of shape (n_atoms, n_feat)</li>
<li><strong>deg_adj_lists</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; Of length (max_deg+1-min_deg). The deg-th element is a list of
adjacency lists for atoms of degree deg.</li>
<li><strong>deg_slice</strong> (<em>tf.Tensor</em>) &#8211; Of shape (max_deg+1-min_deg,2). Explained in GraphTopology.</li>
<li><strong>max_deg</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; Maximum degree of atoms in molecules.</li>
<li><strong>min_deg</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; Minimum degree of atoms in molecules</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Of shape (batch_size, n_feat)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.layers.sum_neigh">
<code class="descclassname">deepchem.nn.layers.</code><code class="descname">sum_neigh</code><span class="sig-paren">(</span><em>atoms</em>, <em>deg_adj_lists</em>, <em>max_deg</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#sum_neigh"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.sum_neigh" title="Permalink to this definition">¶</a></dt>
<dd><p>Store the summed atoms by degree</p>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.layers.tf_affine">
<code class="descclassname">deepchem.nn.layers.</code><code class="descname">tf_affine</code><span class="sig-paren">(</span><em>x</em>, <em>vm</em>, <em>scope</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#tf_affine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.tf_affine" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-deepchem.nn.model_ops">
<span id="deepchem-nn-model-ops-module"></span><h2>deepchem.nn.model_ops module<a class="headerlink" href="#module-deepchem.nn.model_ops" title="Permalink to this headline">¶</a></h2>
<p>Ops for graph construction.</p>
<p>Large amounts of code borrowed from Keras. Will try to incorporate into
DeepChem properly.</p>
<dl class="function">
<dt id="deepchem.nn.model_ops.add_bias">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">add_bias</code><span class="sig-paren">(</span><em>tensor</em>, <em>init=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#add_bias"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.add_bias" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a bias term to a tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>tensor</strong> (<em>tf.Tensor</em>) &#8211; Variable tensor.</li>
<li><strong>init</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) &#8211; Bias initializer. Defaults to zero.</li>
<li><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) &#8211; Name for this op. Defaults to tensor.op.name.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A biased tensor with the same shape as the input tensor.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.binary_crossentropy">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">binary_crossentropy</code><span class="sig-paren">(</span><em>output</em>, <em>target</em>, <em>from_logits=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#binary_crossentropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.binary_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary crossentropy between an output tensor and a target tensor.</p>
<dl class="docutils">
<dt># Arguments</dt>
<dd><p class="first">output: A tensor.
target: A tensor with the same shape as <cite>output</cite>.
from_logits: Whether <cite>output</cite> is expected to be a logits tensor.</p>
<blockquote class="last">
<div>By default, we consider that <cite>output</cite>
encodes a probability distribution.</div></blockquote>
</dd>
<dt># Returns</dt>
<dd>A tensor.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.cast_to_floatx">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">cast_to_floatx</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#cast_to_floatx"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.cast_to_floatx" title="Permalink to this definition">¶</a></dt>
<dd><p>Cast a Numpy array to the default Keras float type.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>Numpy array.</em>) &#8211; </td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">The same Numpy array, cast to its new type.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.categorical_crossentropy">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">categorical_crossentropy</code><span class="sig-paren">(</span><em>output</em>, <em>target</em>, <em>from_logits=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#categorical_crossentropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.categorical_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Categorical crossentropy between an output tensor
and a target tensor, where the target is a tensor of the same
shape as the output.</p>
<p># TODO(rbharath): Should probably swap this over to tf mode.</p>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.clip">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">clip</code><span class="sig-paren">(</span><em>x</em>, <em>min_value</em>, <em>max_value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#clip"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.clip" title="Permalink to this definition">¶</a></dt>
<dd><p>Element-wise value clipping.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">A tensor.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.concatenate">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">concatenate</code><span class="sig-paren">(</span><em>tensors</em>, <em>axis=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#concatenate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.concatenate" title="Permalink to this definition">¶</a></dt>
<dd><p>Concatenates a list of tensors alongside the specified axis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">A tensor.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.cosine_distances">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">cosine_distances</code><span class="sig-paren">(</span><em>test</em>, <em>support</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#cosine_distances"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.cosine_distances" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes pairwise cosine distances between provided tensors</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>test</strong> (<em>tf.Tensor</em>) &#8211; Of shape (n_test, n_feat)</li>
<li><strong>support</strong> (<em>tf.Tensor</em>) &#8211; Of shape (n_support, n_feat)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Of shape (n_test, n_support)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.dot">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">dot</code><span class="sig-paren">(</span><em>x</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#dot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.dot" title="Permalink to this definition">¶</a></dt>
<dd><p>Multiplies 2 tensors (and/or variables) and returns a <em>tensor</em>.
When attempting to multiply a ND tensor
with a ND tensor, it reproduces the Theano behavior.
(e.g. (2, 3).(4, 3, 5) = (2, 4, 5))</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>Tensor or variable.</em>) &#8211; </li>
<li><strong>y</strong> (<em>Tensor or variable.</em>) &#8211; </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A tensor, dot product of x and y.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.dropout">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">dropout</code><span class="sig-paren">(</span><em>tensor</em>, <em>dropout_prob</em>, <em>training=True</em>, <em>training_only=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#dropout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.dropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Random dropout.</p>
<p>This implementation supports &#8220;always-on&#8221; dropout (training_only=False), which
can be used to calculate model uncertainty. See Gal and Ghahramani,
<a class="reference external" href="http://arxiv.org/abs/1506.02142">http://arxiv.org/abs/1506.02142</a>.</p>
<dl class="docutils">
<dt>NOTE(user): To simplify the implementation, I have chosen not to reverse</dt>
<dd>the scaling that occurs in tf.nn.dropout when using dropout during
inference. This shouldn&#8217;t be an issue since the activations will be scaled
by the same constant in both training and inference. This means that there
are no training-time differences between networks that use dropout during
inference and those that do not.</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>tensor</strong> (<em>tf.Tensor</em>) &#8211; Input tensor.</li>
<li><strong>dropout_prob</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) &#8211; Float giving dropout probability for weights (NOT keep probability).</li>
<li><strong>training_only</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; Boolean. If True (standard dropout), apply dropout only
during training. If False, apply dropout during inference as well.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tensor with the same shape as the input tensor.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.elu">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">elu</code><span class="sig-paren">(</span><em>x</em>, <em>alpha=1.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#elu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.elu" title="Permalink to this definition">¶</a></dt>
<dd><p>Exponential linear unit.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>A tensor or variable to compute the activation function for.</em>) &#8211; </li>
<li><strong>alpha</strong> (<em>A scalar, slope of positive section.</em>) &#8211; </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A tensor.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.epsilon">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">epsilon</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#epsilon"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.epsilon" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the value of the fuzz
factor used in numeric expressions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">A float.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.euclidean_distance">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">euclidean_distance</code><span class="sig-paren">(</span><em>test</em>, <em>support</em>, <em>max_dist_sq=20</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#euclidean_distance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.euclidean_distance" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes pairwise euclidean distances between provided tensors</p>
<p>TODO(rbharath): BROKEN! THIS DOESN&#8217;T WORK!</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>test</strong> (<em>tf.Tensor</em>) &#8211; Of shape (n_test, n_feat)</li>
<li><strong>support</strong> (<em>tf.Tensor</em>) &#8211; Of shape (n_support, n_feat)</li>
<li><strong>max_dist_sq</strong> (<em>float, optional</em>) &#8211; Maximum pairwise distance allowed.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Of shape (n_test, n_support)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.fully_connected_layer">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">fully_connected_layer</code><span class="sig-paren">(</span><em>tensor</em>, <em>size=None</em>, <em>weight_init=None</em>, <em>bias_init=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#fully_connected_layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.fully_connected_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Fully connected layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>tensor</strong> (<em>tf.Tensor</em>) &#8211; Input tensor.</li>
<li><strong>size</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; Number of output nodes for this layer.</li>
<li><strong>weight_init</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) &#8211; Weight initializer.</li>
<li><strong>bias_init</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) &#8211; Bias initializer.</li>
<li><strong>name</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) &#8211; Name for this op. Defaults to &#8216;fully_connected&#8217;.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A new tensor representing the output of the fully connected layer.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">tf.Tensor</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/library/exceptions.html#ValueError" title="(in Python v3.6)"><code class="xref py py-exc docutils literal"><span class="pre">ValueError</span></code></a> &#8211;
If input tensor is not 2D.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.get_dtype">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">get_dtype</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#get_dtype"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.get_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the dtype of a Keras tensor or variable, as a string.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>Tensor or variable.</em>) &#8211; </td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">String, dtype of <cite>x</cite>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.get_ndim">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">get_ndim</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#get_ndim"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.get_ndim" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of axes in a tensor, as an integer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>Tensor or variable.</em>) &#8211; </td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">Integer (scalar), number of axes.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.get_uid">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">get_uid</code><span class="sig-paren">(</span><em>prefix=''</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#get_uid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.get_uid" title="Permalink to this definition">¶</a></dt>
<dd><p>Provides a unique UID given a string prefix.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>prefix</strong> (<em>string.</em>) &#8211; </td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">An integer.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.hard_sigmoid">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">hard_sigmoid</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#hard_sigmoid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.hard_sigmoid" title="Permalink to this definition">¶</a></dt>
<dd><p>Segment-wise linear approximation of sigmoid.
Faster than sigmoid.
Returns 0. if x &lt; -2.5, 1. if x &gt; 2.5.
In -2.5 &lt;= x &lt;= 2.5, returns 0.2 * x + 0.5.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>A tensor or variable.</em>) &#8211; </td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">A tensor.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.in_train_phase">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">in_train_phase</code><span class="sig-paren">(</span><em>x</em>, <em>alt</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#in_train_phase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.in_train_phase" title="Permalink to this definition">¶</a></dt>
<dd><p>Selects <cite>x</cite> in train phase, and <cite>alt</cite> otherwise.
Note that <cite>alt</cite> should have the <em>same shape</em> as <cite>x</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">Either <cite>x</cite> or <cite>alt</cite> based on <cite>K.learning_phase</cite>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.int_shape">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">int_shape</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#int_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.int_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the shape of a Keras tensor or a Keras variable as a tuple of
integers or None entries.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>Tensor or variable.</em>) &#8211; </td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">A tuple of integers (or None entries).</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.l2_normalize">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">l2_normalize</code><span class="sig-paren">(</span><em>x</em>, <em>axis</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#l2_normalize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.l2_normalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalizes a tensor wrt the L2 norm alongside the specified axis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>input tensor.</em>) &#8211; </li>
<li><strong>axis</strong> (<em>axis along which to perform normalization.</em>) &#8211; </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A tensor.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.learning_phase">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">learning_phase</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#learning_phase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.learning_phase" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the learning phase flag.</p>
<p>The learning phase flag is a bool tensor (0 = test, 1 = train)
to be passed as input to any Keras function
that uses a different behavior at train time and test time.</p>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.logits">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">logits</code><span class="sig-paren">(</span><em>features</em>, <em>num_classes=2</em>, <em>weight_init=None</em>, <em>bias_init=None</em>, <em>dropout_prob=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.logits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a logits tensor for a single classification task.</p>
<p>You almost certainly don&#8217;t want dropout on there &#8211; it&#8217;s like randomly setting
the (unscaled) probability of a target class to 0.5.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>features</strong> &#8211; A 2D tensor with dimensions batch_size x num_features.</li>
<li><strong>num_classes</strong> &#8211; Number of classes for each task.</li>
<li><strong>weight_init</strong> &#8211; Weight initializer.</li>
<li><strong>bias_init</strong> &#8211; Bias initializer.</li>
<li><strong>dropout_prob</strong> &#8211; Float giving dropout probability for weights (NOT keep
probability).</li>
<li><strong>name</strong> &#8211; Name for this op.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A logits tensor with shape batch_size x num_classes.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.lrelu">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">lrelu</code><span class="sig-paren">(</span><em>alpha=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#lrelu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.lrelu" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a leaky rectified linear unit function.</p>
<p>This function returns a new function that implements the LReLU with a
specified alpha.  The returned value can be used as an activation function in
network layers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) &#8211; the slope of the function when x&lt;0</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">a function f(x) that returns alpha*x when x&lt;0, and x when x&gt;0.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.max">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">max</code><span class="sig-paren">(</span><em>x</em>, <em>axis=None</em>, <em>keepdims=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#max"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.max" title="Permalink to this definition">¶</a></dt>
<dd><p>Maximum value in a tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>A tensor or variable.</em>) &#8211; </li>
<li><strong>axis</strong> (<em>An integer, the axis to find maximum values.</em>) &#8211; </li>
<li><strong>keepdims</strong> (<em>A boolean, whether to keep the dimensions or not.</em>) &#8211; If <cite>keepdims</cite> is <cite>False</cite>, the rank of the tensor is reduced
by 1. If <cite>keepdims</cite> is <cite>True</cite>,
the reduced dimension is retained with length 1.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A tensor with maximum values of <cite>x</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.mean">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">mean</code><span class="sig-paren">(</span><em>x</em>, <em>axis=None</em>, <em>keepdims=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#mean"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean of a tensor, alongside the specified axis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>A tensor or variable.</em>) &#8211; </li>
<li><strong>axis</strong> (<em>A list of integer. Axes to compute the mean.</em>) &#8211; </li>
<li><strong>keepdims</strong> (<em>A boolean, whether to keep the dimensions or not.</em>) &#8211; If keepdims is False, the rank of the tensor is reduced
by 1 for each entry in axis. If keep_dims is True,
the reduced dimensions are retained with length 1.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A tensor with the mean of elements of x.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.moving_average_update">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">moving_average_update</code><span class="sig-paren">(</span><em>variable</em>, <em>value</em>, <em>momentum</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#moving_average_update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.moving_average_update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.multitask_logits">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">multitask_logits</code><span class="sig-paren">(</span><em>features</em>, <em>num_tasks</em>, <em>num_classes=2</em>, <em>weight_init=None</em>, <em>bias_init=None</em>, <em>dropout_prob=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#multitask_logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.multitask_logits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a logit tensor for each classification task.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>features</strong> &#8211; A 2D tensor with dimensions batch_size x num_features.</li>
<li><strong>num_tasks</strong> &#8211; Number of classification tasks.</li>
<li><strong>num_classes</strong> &#8211; Number of classes for each task.</li>
<li><strong>weight_init</strong> &#8211; Weight initializer.</li>
<li><strong>bias_init</strong> &#8211; Bias initializer.</li>
<li><strong>dropout_prob</strong> &#8211; Float giving dropout probability for weights (NOT keep
probability).</li>
<li><strong>name</strong> &#8211; Name for this op. Defaults to &#8216;multitask_logits&#8217;.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A list of logit tensors; one for each classification task.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.normalize_batch_in_training">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">normalize_batch_in_training</code><span class="sig-paren">(</span><em>x</em>, <em>gamma</em>, <em>beta</em>, <em>reduction_axes</em>, <em>epsilon=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#normalize_batch_in_training"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.normalize_batch_in_training" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes mean and std for batch then apply batch_normalization on batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">A tuple length of 3, (normalized_tensor, mean, variance).</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.ones">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">ones</code><span class="sig-paren">(</span><em>shape</em>, <em>dtype=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#ones"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.ones" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates an all-ones tensor variable and returns it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>shape</strong> (<em>Tuple of integers, shape of returned Keras variable.</em>) &#8211; </li>
<li><strong>dtype</strong> (<em>Tensorflow dtype</em>) &#8211; </li>
<li><strong>name</strong> (<em>String, name of returned Keras variable.</em>) &#8211; </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A Keras variable, filled with <cite>1.0</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.optimizer">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">optimizer</code><span class="sig-paren">(</span><em>optimizer='adam'</em>, <em>learning_rate=0.001</em>, <em>momentum=0.9</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#optimizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Create model optimizer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>optimizer</strong> (<em>str, optional</em>) &#8211; Name of optimizer</li>
<li><strong>learning_rate</strong> (<em>float, optional</em>) &#8211; Learning rate for algorithm</li>
<li><strong>momentum</strong> (<em>float, optional</em>) &#8211; Momentum rate</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">A training Optimizer.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/library/exceptions.html#NotImplementedError" title="(in Python v3.6)"><code class="xref py py-exc docutils literal"><span class="pre">NotImplementedError</span></code></a> &#8211;
If an unsupported optimizer is requested.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.random_normal_variable">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">random_normal_variable</code><span class="sig-paren">(</span><em>shape</em>, <em>mean</em>, <em>scale</em>, <em>dtype=tf.float32</em>, <em>name=None</em>, <em>seed=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#random_normal_variable"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.random_normal_variable" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates an Keras variable filled with
samples drawn from a normal distribution and returns it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>shape</strong> (<em>Tuple of integers, shape of returned Keras variable.</em>) &#8211; </li>
<li><strong>mean</strong> (<em>Float, mean of the normal distribution.</em>) &#8211; </li>
<li><strong>scale</strong> (<em>Float, standard deviation of the normal distribution.</em>) &#8211; </li>
<li><strong>dtype</strong> (<em>Tensorflow dtype</em>) &#8211; </li>
<li><strong>name</strong> (<em>String, name of returned Keras variable.</em>) &#8211; </li>
<li><strong>seed</strong> (<em>Integer, random seed.</em>) &#8211; </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A tf.Variable, filled with drawn samples.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.random_uniform_variable">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">random_uniform_variable</code><span class="sig-paren">(</span><em>shape</em>, <em>low</em>, <em>high</em>, <em>dtype=tf.float32</em>, <em>name=None</em>, <em>seed=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#random_uniform_variable"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.random_uniform_variable" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates an variable filled with
samples drawn from a uniform distribution and returns it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>shape</strong> (<em>Tuple of integers, shape of returned variable.</em>) &#8211; </li>
<li><strong>low</strong> (<em>Float, lower boundary of the output inteval.</em>) &#8211; </li>
<li><strong>high</strong> (<em>Float, upper boundary of the output interval.</em>) &#8211; </li>
<li><strong>dtype</strong> (<em>Tensorflow dtype</em>) &#8211; </li>
<li><strong>name</strong> (<em>String, name of returned variable.</em>) &#8211; </li>
<li><strong>seed</strong> (<em>Integer, random seed.</em>) &#8211; </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A tf.Variable, filled with drawn samples.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.relu">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">relu</code><span class="sig-paren">(</span><em>x</em>, <em>alpha=0.0</em>, <em>max_value=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#relu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.relu" title="Permalink to this definition">¶</a></dt>
<dd><p>Rectified linear unit.
With default values, it returns element-wise <cite>max(x, 0)</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>A tensor or variable.</em>) &#8211; </li>
<li><strong>alpha</strong> (<em>A scalar, slope of negative section (default=`0.`).</em>) &#8211; </li>
<li><strong>max_value</strong> (<em>Saturation threshold.</em>) &#8211; </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A tensor.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.selu">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">selu</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#selu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.selu" title="Permalink to this definition">¶</a></dt>
<dd><p>Scaled Exponential Linear unit.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>A tensor or variable.</em>) &#8211; </td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">A tensor.</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<ul class="simple">
<li>[Self-Normalizing Neural Networks](<a class="reference external" href="https://arxiv.org/abs/1706.02515">https://arxiv.org/abs/1706.02515</a>)</li>
</ul>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.softmax_N">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">softmax_N</code><span class="sig-paren">(</span><em>tensor</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#softmax_N"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.softmax_N" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply softmax across last dimension of a tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>tensor</strong> &#8211; Input tensor.</li>
<li><strong>name</strong> &#8211; Name for this op. If None, defaults to &#8216;softmax_N&#8217;.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A tensor with softmax-normalized values on the last dimension.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.sparse_categorical_crossentropy">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">sparse_categorical_crossentropy</code><span class="sig-paren">(</span><em>output</em>, <em>target</em>, <em>from_logits=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#sparse_categorical_crossentropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.sparse_categorical_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Categorical crossentropy between an output tensor
and a target tensor, where the target is an integer tensor.</p>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.sqrt">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">sqrt</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#sqrt"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.sqrt" title="Permalink to this definition">¶</a></dt>
<dd><p>Element-wise square root.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>input tensor.</em>) &#8211; </td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">A tensor.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.sum">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">sum</code><span class="sig-paren">(</span><em>x</em>, <em>axis=None</em>, <em>keepdims=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#sum"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.sum" title="Permalink to this definition">¶</a></dt>
<dd><p>Sum of the values in a tensor, alongside the specified axis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>A tensor or variable.</em>) &#8211; </li>
<li><strong>axis</strong> (<em>An integer, the axis to sum over.</em>) &#8211; </li>
<li><strong>keepdims</strong> (<em>A boolean, whether to keep the dimensions or not.</em>) &#8211; If keepdims is False, the rank of the tensor is reduced
by 1. If keepdims is True,
the reduced dimension is retained with length 1.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A tensor with sum of x.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.switch">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">switch</code><span class="sig-paren">(</span><em>condition</em>, <em>then_expression</em>, <em>else_expression</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#switch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.switch" title="Permalink to this definition">¶</a></dt>
<dd><p>Switches between two operations
depending on a scalar value (<cite>int</cite> or <cite>bool</cite>).
Note that both <cite>then_expression</cite> and <cite>else_expression</cite>
should be symbolic tensors of the <em>same shape</em>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>condition</strong> (<em>scalar tensor.</em>) &#8211; </li>
<li><strong>then_expression</strong> (<em>either a tensor, or a callable that returns a tensor.</em>) &#8211; </li>
<li><strong>else_expression</strong> (<em>either a tensor, or a callable that returns a tensor.</em>) &#8211; </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">The selected tensor.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.var">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">var</code><span class="sig-paren">(</span><em>x</em>, <em>axis=None</em>, <em>keepdims=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#var"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.var" title="Permalink to this definition">¶</a></dt>
<dd><p>Variance of a tensor, alongside the specified axis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>A tensor or variable.</em>) &#8211; </li>
<li><strong>axis</strong> (<em>An integer, the axis to compute the variance.</em>) &#8211; </li>
<li><strong>keepdims</strong> (<em>A boolean, whether to keep the dimensions or not.</em>) &#8211; If keepdims is False, the rank of the tensor is reduced
by 1. If keepdims is True,
the reduced dimension is retained with length 1.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A tensor with the variance of elements of <cite>x</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.weight_decay">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">weight_decay</code><span class="sig-paren">(</span><em>penalty_type</em>, <em>penalty</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#weight_decay"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.weight_decay" title="Permalink to this definition">¶</a></dt>
<dd><p>Add weight decay.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>model</strong> &#8211; TensorflowGraph.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A scalar tensor containing the weight decay cost.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Raises:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/library/exceptions.html#NotImplementedError" title="(in Python v3.6)"><code class="xref py py-exc docutils literal"><span class="pre">NotImplementedError</span></code></a> &#8211;
If an unsupported penalty type is requested.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.zeros">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">zeros</code><span class="sig-paren">(</span><em>shape</em>, <em>dtype=tf.float32</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#zeros"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.zeros" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates an all-zeros variable and returns it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>shape</strong> (<em>Tuple of integers, shape of returned Keras variable</em>) &#8211; </li>
<li><strong>dtype</strong> (<em>Tensorflow dtype</em>) &#8211; </li>
<li><strong>name</strong> (<em>String, name of returned Keras variable</em>) &#8211; </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">A variable (including Keras metadata), filled with <cite>0.0</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-deepchem.nn.objectives">
<span id="deepchem-nn-objectives-module"></span><h2>deepchem.nn.objectives module<a class="headerlink" href="#module-deepchem.nn.objectives" title="Permalink to this headline">¶</a></h2>
<p>Ops for objectives</p>
<p>Code borrowed from Keras.</p>
<dl class="function">
<dt id="deepchem.nn.objectives.KLD">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">KLD</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.KLD" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.MAE">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">MAE</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.MAE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.MAPE">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">MAPE</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.MAPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.MSE">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">MSE</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.MSE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.MSLE">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">MSLE</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.MSLE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.binary_crossentropy">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">binary_crossentropy</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#binary_crossentropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.binary_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.categorical_crossentropy">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">categorical_crossentropy</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#categorical_crossentropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.categorical_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.cosine">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">cosine</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.cosine" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.cosine_proximity">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">cosine_proximity</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#cosine_proximity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.cosine_proximity" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.hinge">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">hinge</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#hinge"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.hinge" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.kld">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">kld</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.kld" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.kullback_leibler_divergence">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">kullback_leibler_divergence</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#kullback_leibler_divergence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.kullback_leibler_divergence" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.mae">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">mae</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.mae" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.mape">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">mape</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.mape" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.mean_absolute_error">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">mean_absolute_error</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#mean_absolute_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.mean_absolute_error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.mean_absolute_percentage_error">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">mean_absolute_percentage_error</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#mean_absolute_percentage_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.mean_absolute_percentage_error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.mean_squared_error">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">mean_squared_error</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#mean_squared_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.mean_squared_error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.mean_squared_logarithmic_error">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">mean_squared_logarithmic_error</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#mean_squared_logarithmic_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.mean_squared_logarithmic_error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.mse">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">mse</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.mse" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.msle">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">msle</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.msle" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.poisson">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">poisson</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#poisson"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.poisson" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.sparse_categorical_crossentropy">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">sparse_categorical_crossentropy</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#sparse_categorical_crossentropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.sparse_categorical_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.squared_hinge">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">squared_hinge</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#squared_hinge"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.squared_hinge" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-deepchem.nn.regularizers">
<span id="deepchem-nn-regularizers-module"></span><h2>deepchem.nn.regularizers module<a class="headerlink" href="#module-deepchem.nn.regularizers" title="Permalink to this headline">¶</a></h2>
<p>Ops for regularizers</p>
<p>Code borrowed from Keras.</p>
<dl class="attribute">
<dt id="deepchem.nn.regularizers.ActivityRegularizer">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">ActivityRegularizer</code><a class="headerlink" href="#deepchem.nn.regularizers.ActivityRegularizer" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#deepchem.nn.regularizers.L1L2Regularizer" title="deepchem.nn.regularizers.L1L2Regularizer"><code class="xref py py-class docutils literal"><span class="pre">L1L2Regularizer</span></code></a></p>
</dd></dl>

<dl class="class">
<dt id="deepchem.nn.regularizers.L1L2Regularizer">
<em class="property">class </em><code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">L1L2Regularizer</code><span class="sig-paren">(</span><em>l1=0.0</em>, <em>l2=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#L1L2Regularizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.L1L2Regularizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.regularizers.Regularizer" title="deepchem.nn.regularizers.Regularizer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.regularizers.Regularizer</span></code></a></p>
<p>Regularizer for L1 and L2 regularization.</p>
<dl class="docutils">
<dt># Arguments</dt>
<dd>l1: Float; L1 regularization factor.
l2: Float; L2 regularization factor.</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="deepchem.nn.regularizers.Regularizer">
<em class="property">class </em><code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">Regularizer</code><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#Regularizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.Regularizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.nn.regularizers.WeightRegularizer">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">WeightRegularizer</code><a class="headerlink" href="#deepchem.nn.regularizers.WeightRegularizer" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#deepchem.nn.regularizers.L1L2Regularizer" title="deepchem.nn.regularizers.L1L2Regularizer"><code class="xref py py-class docutils literal"><span class="pre">L1L2Regularizer</span></code></a></p>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.regularizers.activity_l1">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">activity_l1</code><span class="sig-paren">(</span><em>l=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#activity_l1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.activity_l1" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.regularizers.activity_l1l2">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">activity_l1l2</code><span class="sig-paren">(</span><em>l1=0.01</em>, <em>l2=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#activity_l1l2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.activity_l1l2" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.regularizers.activity_l2">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">activity_l2</code><span class="sig-paren">(</span><em>l=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#activity_l2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.activity_l2" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.regularizers.l1">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">l1</code><span class="sig-paren">(</span><em>l=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#l1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.l1" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.regularizers.l1l2">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">l1l2</code><span class="sig-paren">(</span><em>l1=0.01</em>, <em>l2=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#l1l2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.l1l2" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.regularizers.l2">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">l2</code><span class="sig-paren">(</span><em>l=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#l2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.l2" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-deepchem.nn.weave_layers">
<span id="deepchem-nn-weave-layers-module"></span><h2>deepchem.nn.weave_layers module<a class="headerlink" href="#module-deepchem.nn.weave_layers" title="Permalink to this headline">¶</a></h2>
<p>Created on Thu Mar 30 14:02:04 2017</p>
<p>&#64;author: michael</p>
<dl class="class">
<dt id="deepchem.nn.weave_layers.AlternateWeaveGather">
<em class="property">class </em><code class="descclassname">deepchem.nn.weave_layers.</code><code class="descname">AlternateWeaveGather</code><span class="sig-paren">(</span><em>batch_size</em>, <em>n_input=128</em>, <em>gaussian_expand=False</em>, <em>init='glorot_uniform'</em>, <em>activation='tanh'</em>, <em>epsilon=0.001</em>, <em>momentum=0.99</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#AlternateWeaveGather"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveGather" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.weave_layers.WeaveGather" title="deepchem.nn.weave_layers.WeaveGather"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.weave_layers.WeaveGather</span></code></a></p>
<p>Alternate implementation of weave gather layer
corresponding to AlternateWeaveLayer</p>
<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveGather.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveGather.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveGather.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveGather.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveGather.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveGather.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveGather.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveGather.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveGather.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#AlternateWeaveGather.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveGather.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>x = [atom_features, atom_split]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; Tensors as listed above</li>
<li><strong>mask</strong> (<em>bool, optional</em>) &#8211; Ignored. Present only to shadow superclass call() method.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>outputs</strong> &#8211;
Tensor of molecular features</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveGather.gaussian_histogram">
<code class="descname">gaussian_histogram</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveGather.gaussian_histogram" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.weave_layers.AlternateWeaveLayer">
<em class="property">class </em><code class="descclassname">deepchem.nn.weave_layers.</code><code class="descname">AlternateWeaveLayer</code><span class="sig-paren">(</span><em>max_atoms</em>, <em>n_atom_input_feat=75</em>, <em>n_pair_input_feat=14</em>, <em>n_atom_output_feat=50</em>, <em>n_pair_output_feat=50</em>, <em>n_hidden_AA=50</em>, <em>n_hidden_PA=50</em>, <em>n_hidden_AP=50</em>, <em>n_hidden_PP=50</em>, <em>update_pair=True</em>, <em>init='glorot_uniform'</em>, <em>activation='relu'</em>, <em>dropout=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#AlternateWeaveLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.weave_layers.WeaveLayer" title="deepchem.nn.weave_layers.WeaveLayer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.weave_layers.WeaveLayer</span></code></a></p>
<p>Alternate implementation of weave module
same variables, different graph structures</p>
<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveLayer.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveLayer.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveLayer.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveLayer.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveLayer.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveLayer.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveLayer.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveLayer.build" title="Permalink to this definition">¶</a></dt>
<dd><p>&#8220;Construct internal trainable weights.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveLayer.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#AlternateWeaveLayer.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveLayer.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>x = [atom_features, pair_features, pair_split, atom_split, atom_to_pair]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; list of Tensors of form described above.</li>
<li><strong>mask</strong> (<em>bool, optional</em>) &#8211; Ignored. Present only to shadow superclass call() method.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>A</strong> (<em>Tensor</em>) &#8211;
Tensor of atom_features</li>
<li><strong>P</strong> (<em>Tensor</em>) &#8211;
Tensor of pair_features</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.weave_layers.WeaveConcat">
<em class="property">class </em><code class="descclassname">deepchem.nn.weave_layers.</code><code class="descname">WeaveConcat</code><span class="sig-paren">(</span><em>batch_size</em>, <em>n_atom_input_feat=50</em>, <em>n_output=128</em>, <em>init='glorot_uniform'</em>, <em>activation='tanh'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveConcat"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveConcat" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>&#8221; Concat a batch of molecules into a batch of atoms</p>
<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveConcat.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveConcat.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveConcat.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveConcat.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveConcat.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveConcat.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveConcat.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveConcat.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveConcat.build" title="Permalink to this definition">¶</a></dt>
<dd><p>&#8220;Construct internal trainable weights.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveConcat.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveConcat.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveConcat.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>x = [atom_features, atom_mask]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; Tensors as listed above</li>
<li><strong>mask</strong> (<em>bool, optional</em>) &#8211; Ignored. Present only to shadow superclass call() method.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>outputs</strong> &#8211;
Tensor of concatenated atom features</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.weave_layers.WeaveGather">
<em class="property">class </em><code class="descclassname">deepchem.nn.weave_layers.</code><code class="descname">WeaveGather</code><span class="sig-paren">(</span><em>batch_size</em>, <em>n_input=128</em>, <em>gaussian_expand=False</em>, <em>init='glorot_uniform'</em>, <em>activation='tanh'</em>, <em>epsilon=0.001</em>, <em>momentum=0.99</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveGather"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveGather" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>&#8221; Gather layer of Weave model
a batch of normalized atom features go through a hidden layer,
then summed to form molecular features</p>
<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveGather.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveGather.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveGather.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveGather.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveGather.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveGather.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveGather.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveGather.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveGather.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveGather.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveGather.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveGather.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>x = [atom_features, membership]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; Tensors as listed above</li>
<li><strong>mask</strong> (<em>bool, optional</em>) &#8211; Ignored. Present only to shadow superclass call() method.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>outputs</strong> &#8211;
Tensor of molecular features</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveGather.gaussian_histogram">
<code class="descname">gaussian_histogram</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveGather.gaussian_histogram"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveGather.gaussian_histogram" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.weave_layers.WeaveLayer">
<em class="property">class </em><code class="descclassname">deepchem.nn.weave_layers.</code><code class="descname">WeaveLayer</code><span class="sig-paren">(</span><em>max_atoms</em>, <em>n_atom_input_feat=75</em>, <em>n_pair_input_feat=14</em>, <em>n_atom_output_feat=50</em>, <em>n_pair_output_feat=50</em>, <em>n_hidden_AA=50</em>, <em>n_hidden_PA=50</em>, <em>n_hidden_AP=50</em>, <em>n_hidden_PP=50</em>, <em>update_pair=True</em>, <em>init='glorot_uniform'</em>, <em>activation='relu'</em>, <em>dropout=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>&#8221; Main layer of Weave model
For each molecule, atom features and pair features are recombined to
generate new atom(pair) features</p>
<p>Detailed structure and explanations:
<a class="reference external" href="https://arxiv.org/abs/1603.00856">https://arxiv.org/abs/1603.00856</a></p>
<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveLayer.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveLayer.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around self.call(), for handling
:param x:
:type x: Can be a tensor or list/tuple of tensors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveLayer.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveLayer.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveLayer.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveLayer.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>shape</strong> (<em>The shape tuple of the weight.</em>) &#8211; </li>
<li><strong>initializer</strong> (<em>An Initializer instance (callable).</em>) &#8211; </li>
<li><strong>regularizer</strong> (<em>An optional Regularizer instance.</em>) &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveLayer.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveLayer.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveLayer.build" title="Permalink to this definition">¶</a></dt>
<dd><p>&#8220;Construct internal trainable weights.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveLayer.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveLayer.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveLayer.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>x = [atom_features, pair_features, atom_mask, pair_mask]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#list" title="(in Python v3.6)"><em>list</em></a>) &#8211; list of Tensors of form described above.</li>
<li><strong>mask</strong> (<em>bool, optional</em>) &#8211; Ignored. Present only to shadow superclass call() method.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>A</strong> (<em>Tensor</em>) &#8211;
Tensor of atom_features</li>
<li><strong>P</strong> (<em>Tensor</em>) &#8211;
Tensor of pair_features</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.nn">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-deepchem.nn" title="Permalink to this headline">¶</a></h2>
<p>Imports a number of useful deep learning primitives into one place.</p>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="_sources/deepchem.nn.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2016, Stanford University and the Authors.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>