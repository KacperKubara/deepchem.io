<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>deepchem.nn package &mdash; deepchem 1.2 documentation</title>
    
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="deepchem 1.2 documentation" href="index.html" />
    <link rel="up" title="deepchem package" href="deepchem.html" />
    <link rel="next" title="deepchem.rl package" href="deepchem.rl.html" />
    <link rel="prev" title="deepchem.molnet.load_function package" href="deepchem.molnet.load_function.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-inverse navbar-default ">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html"><span><img src="_static/logo.png"></span>
          deepchem</a>
        <span class="navbar-text navbar-version pull-left"><b>1.2</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="notebooks/index.html">Notebooks</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="deepchem.html">deepchem package</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">deepchem.nn package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-deepchem.nn.activations">deepchem.nn.activations module</a></li>
<li><a class="reference internal" href="#module-deepchem.nn.constraints">deepchem.nn.constraints module</a></li>
<li><a class="reference internal" href="#module-deepchem.nn.copy">deepchem.nn.copy module</a></li>
<li><a class="reference internal" href="#module-deepchem.nn.initializations">deepchem.nn.initializations module</a></li>
<li><a class="reference internal" href="#module-deepchem.nn.layers">deepchem.nn.layers module</a></li>
<li><a class="reference internal" href="#module-deepchem.nn.model_ops">deepchem.nn.model_ops module</a></li>
<li><a class="reference internal" href="#module-deepchem.nn.objectives">deepchem.nn.objectives module</a></li>
<li><a class="reference internal" href="#module-deepchem.nn.regularizers">deepchem.nn.regularizers module</a></li>
<li><a class="reference internal" href="#module-deepchem.nn.weave_layers">deepchem.nn.weave_layers module</a></li>
<li><a class="reference internal" href="#module-deepchem.nn">Module contents</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="deepchem-nn-package">
<h1>deepchem.nn package<a class="headerlink" href="#deepchem-nn-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-deepchem.nn.activations">
<span id="deepchem-nn-activations-module"></span><h2>deepchem.nn.activations module<a class="headerlink" href="#module-deepchem.nn.activations" title="Permalink to this headline">¶</a></h2>
<p>Activations for models.</p>
<p>Copied over from Keras.</p>
<dl class="function">
<dt id="deepchem.nn.activations.elu">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">elu</code><span class="sig-paren">(</span><em>x</em>, <em>alpha=1.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#elu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.elu" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.get">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">get</code><span class="sig-paren">(</span><em>identifier</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#get"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.get" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.get_from_module">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">get_from_module</code><span class="sig-paren">(</span><em>identifier</em>, <em>module_params</em>, <em>module_name</em>, <em>instantiate=False</em>, <em>kwargs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#get_from_module"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.get_from_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieves a class of function member of a module.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>identifier: the object to retrieve. It could be specified</strong></p>
<blockquote>
<div><p>by name (as a string), or by dict. In any other case,
identifier itself will be returned without any changes.</p>
</div></blockquote>
<p><strong>module_params: the members of a module</strong></p>
<blockquote>
<div><p>(e.g. the output of globals()).</p>
</div></blockquote>
<p><strong>module_name: string; the name of the target module. Only used</strong></p>
<blockquote>
<div><p>to format error messages.</p>
</div></blockquote>
<p><strong>instantiate: whether to instantiate the returned object</strong></p>
<blockquote>
<div><p>(if it&#8217;s a class).</p>
</div></blockquote>
<p><strong>kwargs: a dictionary of keyword arguments to pass to the</strong></p>
<blockquote>
<div><p>class constructor if <cite>instantiate</cite> is <cite>True</cite>.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The target object.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last"><strong>ValueError: if the identifier cannot be found.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.hard_sigmoid">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">hard_sigmoid</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#hard_sigmoid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.hard_sigmoid" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.linear">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">linear</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#linear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.linear" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.relu">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">relu</code><span class="sig-paren">(</span><em>x</em>, <em>alpha=0.0</em>, <em>max_value=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#relu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.relu" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.selu">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">selu</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#selu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.selu" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.sigmoid">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">sigmoid</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#sigmoid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.sigmoid" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.softmax">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">softmax</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#softmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.softmax" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.softplus">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">softplus</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#softplus"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.softplus" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.softsign">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">softsign</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#softsign"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.softsign" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.activations.tanh">
<code class="descclassname">deepchem.nn.activations.</code><code class="descname">tanh</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/activations.html#tanh"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.activations.tanh" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-deepchem.nn.constraints">
<span id="deepchem-nn-constraints-module"></span><h2>deepchem.nn.constraints module<a class="headerlink" href="#module-deepchem.nn.constraints" title="Permalink to this headline">¶</a></h2>
<p>Place constraints on models.</p>
<dl class="class">
<dt id="deepchem.nn.constraints.Constraint">
<em class="property">class </em><code class="descclassname">deepchem.nn.constraints.</code><code class="descname">Constraint</code><a class="reference internal" href="_modules/deepchem/nn/constraints.html#Constraint"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.constraints.Constraint" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(p)</td>
<td></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="deepchem.nn.constraints.MaxNorm">
<em class="property">class </em><code class="descclassname">deepchem.nn.constraints.</code><code class="descname">MaxNorm</code><span class="sig-paren">(</span><em>m=2</em>, <em>axis=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/constraints.html#MaxNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.constraints.MaxNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.constraints.Constraint" title="deepchem.nn.constraints.Constraint"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.constraints.Constraint</span></code></a></p>
<p>MaxNorm weight constraint.</p>
<p>Constrains the weights incident to each hidden unit
to have a norm less than or equal to a desired value.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>m: the maximum norm for the incoming weights.</strong></p>
<p><strong>axis: integer, axis along which to calculate weight norms.</strong></p>
<blockquote>
<div><p>For instance, in a <cite>Dense</cite> layer the weight matrix
has shape (input_dim, output_dim),
set axis to 0 to constrain each weight vector
of length <cite>(input_dim,)</cite>.</p>
</div></blockquote>
<p><strong># References</strong></p>
<blockquote class="last">
<div><ul class="simple">
<li>[Dropout: A Simple Way to Prevent Neural Networks from Overfitting Srivastava, Hinton, et al. 2014](<a class="reference external" href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf</a>)</li>
</ul>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(p)</td>
<td></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="deepchem.nn.constraints.NonNeg">
<em class="property">class </em><code class="descclassname">deepchem.nn.constraints.</code><code class="descname">NonNeg</code><a class="reference internal" href="_modules/deepchem/nn/constraints.html#NonNeg"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.constraints.NonNeg" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.constraints.Constraint" title="deepchem.nn.constraints.Constraint"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.constraints.Constraint</span></code></a></p>
<p>Constrains the weights to be non-negative.</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(p)</td>
<td></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="deepchem.nn.constraints.UnitNorm">
<em class="property">class </em><code class="descclassname">deepchem.nn.constraints.</code><code class="descname">UnitNorm</code><span class="sig-paren">(</span><em>axis=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/constraints.html#UnitNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.constraints.UnitNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.constraints.Constraint" title="deepchem.nn.constraints.Constraint"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.constraints.Constraint</span></code></a></p>
<p>Constrains the weights incident to each hidden unit to have unit norm.</p>
<dl class="docutils">
<dt># Arguments</dt>
<dd><dl class="first last docutils">
<dt>axis: integer, axis along which to calculate weight norms.</dt>
<dd>For instance, in a <cite>Dense</cite> layer the weight matrix
has shape <cite>(input_dim, output_dim)</cite>,
set <cite>axis</cite> to <cite>0</cite> to constrain each weight vector
of length <cite>(input_dim,)</cite>.
In a <cite>Convolution2D</cite> layer with <cite>dim_ordering=&#8221;tf&#8221;</cite>,
the weight tensor has shape
<cite>(rows, cols, input_depth, output_depth)</cite>,
set <cite>axis</cite> to <cite>[0, 1, 2]</cite>
to constrain the weights of each filter tensor of size
<cite>(rows, cols, input_depth)</cite>.</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(p)</td>
<td></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.constraints.get">
<code class="descclassname">deepchem.nn.constraints.</code><code class="descname">get</code><span class="sig-paren">(</span><em>identifier</em>, <em>kwargs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/constraints.html#get"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.constraints.get" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.nn.constraints.maxnorm">
<code class="descclassname">deepchem.nn.constraints.</code><code class="descname">maxnorm</code><a class="headerlink" href="#deepchem.nn.constraints.maxnorm" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#deepchem.nn.constraints.MaxNorm" title="deepchem.nn.constraints.MaxNorm"><code class="xref py py-class docutils literal"><span class="pre">MaxNorm</span></code></a></p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.nn.constraints.nonneg">
<code class="descclassname">deepchem.nn.constraints.</code><code class="descname">nonneg</code><a class="headerlink" href="#deepchem.nn.constraints.nonneg" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#deepchem.nn.constraints.NonNeg" title="deepchem.nn.constraints.NonNeg"><code class="xref py py-class docutils literal"><span class="pre">NonNeg</span></code></a></p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.nn.constraints.unitnorm">
<code class="descclassname">deepchem.nn.constraints.</code><code class="descname">unitnorm</code><a class="headerlink" href="#deepchem.nn.constraints.unitnorm" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#deepchem.nn.constraints.UnitNorm" title="deepchem.nn.constraints.UnitNorm"><code class="xref py py-class docutils literal"><span class="pre">UnitNorm</span></code></a></p>
</dd></dl>

</div>
<div class="section" id="module-deepchem.nn.copy">
<span id="deepchem-nn-copy-module"></span><h2>deepchem.nn.copy module<a class="headerlink" href="#module-deepchem.nn.copy" title="Permalink to this headline">¶</a></h2>
<p>Copies Classes from keras to remove dependency.</p>
<p>Most of this code is copied over from Keras. Hoping to use as a staging
area while we remove our Keras dependency.</p>
<dl class="class">
<dt id="deepchem.nn.copy.BatchNormalization">
<em class="property">class </em><code class="descclassname">deepchem.nn.copy.</code><code class="descname">BatchNormalization</code><span class="sig-paren">(</span><em>epsilon=0.001</em>, <em>mode=0</em>, <em>axis=-1</em>, <em>momentum=0.99</em>, <em>beta_init='zero'</em>, <em>gamma_init='one'</em>, <em>gamma_regularizer=None</em>, <em>beta_regularizer=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#BatchNormalization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.BatchNormalization" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Batch normalization layer (Ioffe and Szegedy, 2014).</p>
<p>Normalize the activations of the previous layer at each batch,
i.e. applies a transformation that maintains the mean activation
close to 0 and the activation standard deviation close to 1.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>epsilon: small float &gt; 0. Fuzz parameter.</strong></p>
<p><strong>mode: integer, 0, 1 or 2.</strong></p>
<blockquote>
<div><ul class="simple">
<li><dl class="first docutils">
<dt>0: feature-wise normalization.</dt>
<dd>Each feature map in the input will
be normalized separately. The axis on which
to normalize is specified by the <cite>axis</cite> argument.
During training we use per-batch statistics to normalize
the data, and during testing we use running averages
computed during the training phase.</dd>
</dl>
</li>
<li>1: sample-wise normalization. This mode assumes a 2D input.</li>
<li><dl class="first docutils">
<dt>2: feature-wise normalization, like mode 0, but</dt>
<dd>using per-batch statistics to normalize the data during both
testing and training.</dd>
</dl>
</li>
</ul>
</div></blockquote>
<p><strong>axis: integer, axis along which to normalize in mode 0. For instance,</strong></p>
<blockquote>
<div><p>if your input tensor has shape (samples, channels, rows, cols),
set axis to 1 to normalize per feature map (channels axis).</p>
</div></blockquote>
<p><strong>momentum: momentum in the computation of the</strong></p>
<blockquote>
<div><p>exponential average of the mean and standard deviation
of the data, for feature-wise normalization.</p>
</div></blockquote>
<p><strong>beta_init: name of initialization function for shift parameter, or</strong></p>
<blockquote>
<div><p>alternatively, TensorFlow function to use for weights initialization.</p>
</div></blockquote>
<p><strong>gamma_init: name of initialization function for scale parameter, or</strong></p>
<blockquote>
<div><p>alternatively, TensorFlow function to use for weights initialization.</p>
</div></blockquote>
<p><strong>gamma_regularizer: instance of WeightRegularizer</strong></p>
<blockquote>
<div><p>(eg. L1 or L2 regularization), applied to the gamma vector.</p>
</div></blockquote>
<p><strong>beta_regularizer: instance of WeightRegularizer,</strong></p>
<blockquote>
<div><p>applied to the beta vector.</p>
</div></blockquote>
<p><strong>Input shape:</strong></p>
<p><strong>Arbitrary. Use the keyword argument input_shape</strong></p>
<p><strong>(tuple of integers, does not include the samples axis)</strong></p>
<p><strong>when using this layer as the first layer in a model.</strong></p>
<p><strong>Output shape:</strong></p>
<p><strong>Same shape as input.</strong></p>
<p><strong>References:</strong></p>
<blockquote class="last">
<div><ul class="simple">
<li>[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](<a class="reference external" href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a>)</li>
</ul>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.copy.BatchNormalization.add_loss" title="deepchem.nn.copy.BatchNormalization.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.copy.BatchNormalization.add_weight" title="deepchem.nn.copy.BatchNormalization.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.copy.BatchNormalization.build" title="deepchem.nn.copy.BatchNormalization.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>(input_shape)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.copy.BatchNormalization.call" title="deepchem.nn.copy.BatchNormalization.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x)</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.copy.BatchNormalization.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.BatchNormalization.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.BatchNormalization.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.BatchNormalization.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.BatchNormalization.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#BatchNormalization.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.BatchNormalization.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.BatchNormalization.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#BatchNormalization.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.BatchNormalization.call" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.copy.Dense">
<em class="property">class </em><code class="descclassname">deepchem.nn.copy.</code><code class="descname">Dense</code><span class="sig-paren">(</span><em>output_dim</em>, <em>input_dim</em>, <em>init='glorot_uniform'</em>, <em>activation='relu'</em>, <em>bias=True</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Dense"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Dense" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Just your regular densely-connected NN layer.</p>
<p>TODO(rbharath): Make this functional in deepchem</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">deepchem</span> <span class="kn">as</span> <span class="nn">dc</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># as first layer in a sequential model:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">dc</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="mi">16</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">dc</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># now the model will take as input arrays of shape (*, 16)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and output arrays of shape (*, 32)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># this is equivalent to the above:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">dc</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="mi">16</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">dc</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">))</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>output_dim: int &gt; 0.</strong></p>
<p><strong>init: name of initialization function for the weights of the layer</strong></p>
<p><strong>activation: name of activation function to use</strong></p>
<blockquote>
<div><p>(see [activations](../activations.md)).
If you don&#8217;t specify anything, no activation is applied
(ie. &#8220;linear&#8221; activation: a(x) = x).</p>
</div></blockquote>
<p><strong>W_regularizer: (eg. L1 or L2 regularization), applied to the main weights matrix.</strong></p>
<p><strong>b_regularizer: instance of regularize applied to the bias.</strong></p>
<p><strong>activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),</strong></p>
<blockquote>
<div><p>applied to the network output.</p>
</div></blockquote>
<p><strong>bias: whether to include a bias</strong></p>
<blockquote>
<div><p>(i.e. make the layer affine rather than linear).</p>
</div></blockquote>
<p><strong>input_dim: dimensionality of the input (integer). This argument</strong></p>
<blockquote>
<div><p>(or alternatively, the keyword argument <cite>input_shape</cite>)
is required when using this layer as the first layer in a model.</p>
</div></blockquote>
<p><strong># Input shape</strong></p>
<blockquote>
<div><p>nD tensor with shape: (nb_samples, ..., input_dim).
The most common situation would be
a 2D input with shape (nb_samples, input_dim).</p>
</div></blockquote>
<p><strong># Output shape</strong></p>
<blockquote class="last">
<div><p>nD tensor with shape: (nb_samples, ..., output_dim).
For instance, for a 2D input with shape <cite>(nb_samples, input_dim)</cite>,
the output would have shape <cite>(nb_samples, output_dim)</cite>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.copy.Dense.add_loss" title="deepchem.nn.copy.Dense.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.copy.Dense.add_weight" title="deepchem.nn.copy.Dense.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.copy.Dense.call" title="deepchem.nn.copy.Dense.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x)</td>
<td>This is where the layer&#8217;s logic lives.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.copy.Dense.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.Dense.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.Dense.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.Dense.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.Dense.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.Dense.call" title="Permalink to this definition">¶</a></dt>
<dd><p>This is where the layer&#8217;s logic lives.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x: input tensor, or list/tuple of input tensors.</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A tensor or list/tuple of tensors.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.copy.Dropout">
<em class="property">class </em><code class="descclassname">deepchem.nn.copy.</code><code class="descname">Dropout</code><span class="sig-paren">(</span><em>p</em>, <em>seed=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Dropout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Dropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Applies Dropout to the input.</p>
<p>Dropout consists in randomly setting
a fraction <cite>p</cite> of input units to 0 at each update during training time,
which helps prevent overfitting.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>p: float between 0 and 1. Fraction of the input units to drop.</strong></p>
<p><strong>seed: A Python integer to use as random seed.</strong></p>
<p><strong># References</strong></p>
<blockquote class="last">
<div><ul class="simple">
<li>[Dropout: A Simple Way to Prevent Neural Networks from Overfitting](<a class="reference external" href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf</a>)</li>
</ul>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.copy.Dropout.add_loss" title="deepchem.nn.copy.Dropout.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.copy.Dropout.add_weight" title="deepchem.nn.copy.Dropout.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.copy.Dropout.call" title="deepchem.nn.copy.Dropout.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x)</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.copy.Dropout.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.Dropout.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.Dropout.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.Dropout.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.Dropout.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Dropout.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Dropout.call" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="deepchem.nn.copy.Input">
<code class="descclassname">deepchem.nn.copy.</code><code class="descname">Input</code><span class="sig-paren">(</span><em>shape=None</em>, <em>batch_shape=None</em>, <em>name=None</em>, <em>dtype=tf.float32</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Input" title="Permalink to this definition">¶</a></dt>
<dd><p>Input() is used to create a placeholder input</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: A shape tuple (integer), not including the batch size.</strong></p>
<blockquote>
<div><p>For instance, <cite>shape=(32,)</cite> indicates that the expected input
will be batches of 32-dimensional vectors.</p>
</div></blockquote>
<p><strong>name: An optional name string for the layer.</strong></p>
<blockquote>
<div><p>Should be unique in a model (do not reuse the same name twice).
It will be autogenerated if it isn&#8217;t provided.</p>
</div></blockquote>
<p><strong>dtype: The data type expected by the input, as a string</strong></p>
<blockquote>
<div><p>(<cite>float32</cite>, <cite>float64</cite>, <cite>int32</cite>...)</p>
</div></blockquote>
<p><strong># TODO(rbharath): Support this type of functional API.</strong></p>
<p><strong>Example:</strong></p>
<p><strong>&gt;&gt;&gt; # this is a logistic regression in Keras</strong></p>
<p><strong>&gt;&gt;&gt; a = dc.nn.Input(shape=(32,))</strong></p>
<p><strong>&gt;&gt;&gt; b = dc.nn.Dense(16)(a)</strong></p>
<p class="last"><strong>&gt;&gt;&gt; model = dc.nn.FunctionalModel(input=a, output=b)</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="deepchem.nn.copy.InputLayer">
<em class="property">class </em><code class="descclassname">deepchem.nn.copy.</code><code class="descname">InputLayer</code><span class="sig-paren">(</span><em>input_shape=None</em>, <em>batch_input_shape=None</em>, <em>input_dtype=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#InputLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.InputLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Layer to be used as an entry point into a graph.</p>
<p>Create its a placeholder tensor (pass arguments <cite>input_shape</cite>
or <cite>batch_input_shape</cite> as well as <cite>input_dtype</cite>).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>input_shape: Shape tuple, not including the batch axis.</strong></p>
<p><strong>batch_input_shape: Shape tuple, including the batch axis.</strong></p>
<p><strong>input_dtype: Datatype of the input.</strong></p>
<p class="last"><strong>name: Name of the layer (string).</strong></p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.copy.InputLayer.add_loss" title="deepchem.nn.copy.InputLayer.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.copy.InputLayer.add_weight" title="deepchem.nn.copy.InputLayer.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.copy.InputLayer.call" title="deepchem.nn.copy.InputLayer.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x)</td>
<td>This is where the layer&#8217;s logic lives.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.copy.InputLayer.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.InputLayer.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.InputLayer.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.InputLayer.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.InputLayer.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.copy.InputLayer.call" title="Permalink to this definition">¶</a></dt>
<dd><p>This is where the layer&#8217;s logic lives.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x: input tensor, or list/tuple of input tensors.</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A tensor or list/tuple of tensors.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.copy.Layer">
<em class="property">class </em><code class="descclassname">deepchem.nn.copy.</code><code class="descname">Layer</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
<p>Abstract base layer class.</p>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="24%" />
<col width="76%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><strong>name: String, must be unique within a model.</strong></td>
<td>&nbsp;</td>
</tr>
<tr class="row-even"><td><strong>trainable: Boolean, whether the layer weights</strong></td>
<td>will be updated during training.</td>
</tr>
<tr class="row-odd"><td><strong>uses_learning_phase: Whether any operation</strong></td>
<td>of the layer uses model_ops.in_training_phase() or model_ops.in_test_phase().</td>
</tr>
<tr class="row-even"><td><strong>input_shape: Shape tuple. Provided for convenience,</strong></td>
<td>but note that there may be cases in which this attribute is ill-defined (e.g. a shared layer with multiple input shapes), in which case requesting input_shape will raise an Exception. Prefer using layer.get_input_shape_for(input_shape),</td>
</tr>
<tr class="row-odd"><td><strong>output_shape: Shape tuple. See above.</strong></td>
<td>&nbsp;</td>
</tr>
<tr class="row-even"><td><strong>input, output: Input/output tensor(s). Note that if the layer is used</strong></td>
<td>more than once (shared layer), this is ill-defined and will raise an exception. In such cases, use</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="docutils">
<colgroup>
<col width="32%" />
<col width="68%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><strong>call(x): Where the layer&#8217;s logic lives.</strong></td>
<td>&nbsp;</td>
</tr>
<tr class="row-even"><td><strong>__call__(x): Wrapper around the layer logic (`call`).</strong></td>
<td>If x is a tensor: - Connect current layer with last layer from tensor: - Add layer to tensor history If layer is not built:</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.copy.Layer.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Layer.add_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Layer.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.Layer.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Layer.add_weight"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Layer.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.copy.Layer.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#Layer.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.Layer.call" title="Permalink to this definition">¶</a></dt>
<dd><p>This is where the layer&#8217;s logic lives.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x: input tensor, or list/tuple of input tensors.</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A tensor or list/tuple of tensors.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="deepchem.nn.copy.object_list_uid">
<code class="descclassname">deepchem.nn.copy.</code><code class="descname">object_list_uid</code><span class="sig-paren">(</span><em>object_list</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#object_list_uid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.object_list_uid" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.copy.to_list">
<code class="descclassname">deepchem.nn.copy.</code><code class="descname">to_list</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/copy.html#to_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.copy.to_list" title="Permalink to this definition">¶</a></dt>
<dd><p>This normalizes a list/tensor into a list.</p>
<p>If a tensor is passed, we return
a list of size 1 containing the tensor.</p>
</dd></dl>

</div>
<div class="section" id="module-deepchem.nn.initializations">
<span id="deepchem-nn-initializations-module"></span><h2>deepchem.nn.initializations module<a class="headerlink" href="#module-deepchem.nn.initializations" title="Permalink to this headline">¶</a></h2>
<p>Ops for tensor initialization</p>
<dl class="function">
<dt id="deepchem.nn.initializations.get">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">get</code><span class="sig-paren">(</span><em>identifier</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#get"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.get" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.get_fans">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">get_fans</code><span class="sig-paren">(</span><em>shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#get_fans"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.get_fans" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.glorot_normal">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">glorot_normal</code><span class="sig-paren">(</span><em>shape</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#glorot_normal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.glorot_normal" title="Permalink to this definition">¶</a></dt>
<dd><p>Glorot normal variance scaling initializer.</p>
<dl class="docutils">
<dt># References</dt>
<dd>Glorot &amp; Bengio, AISTATS 2010</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.glorot_uniform">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">glorot_uniform</code><span class="sig-paren">(</span><em>shape</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#glorot_uniform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.glorot_uniform" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.he_normal">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">he_normal</code><span class="sig-paren">(</span><em>shape</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#he_normal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.he_normal" title="Permalink to this definition">¶</a></dt>
<dd><p>He normal variance scaling initializer.</p>
<dl class="docutils">
<dt># References</dt>
<dd>He et al., <a class="reference external" href="http://arxiv.org/abs/1502.01852">http://arxiv.org/abs/1502.01852</a></dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.he_uniform">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">he_uniform</code><span class="sig-paren">(</span><em>shape</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#he_uniform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.he_uniform" title="Permalink to this definition">¶</a></dt>
<dd><p>He uniform variance scaling initializer.</p>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.identity">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">identity</code><span class="sig-paren">(</span><em>shape</em>, <em>scale=1</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#identity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.identity" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.lecun_uniform">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">lecun_uniform</code><span class="sig-paren">(</span><em>shape</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#lecun_uniform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.lecun_uniform" title="Permalink to this definition">¶</a></dt>
<dd><p>LeCun uniform variance scaling initializer.</p>
<dl class="docutils">
<dt># References</dt>
<dd>LeCun 98, Efficient Backprop,
<a class="reference external" href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf</a></dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.normal">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">normal</code><span class="sig-paren">(</span><em>shape</em>, <em>scale=0.05</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#normal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.normal" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.one">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">one</code><span class="sig-paren">(</span><em>shape</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#one"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.one" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.orthogonal">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">orthogonal</code><span class="sig-paren">(</span><em>shape</em>, <em>scale=1.1</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#orthogonal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.orthogonal" title="Permalink to this definition">¶</a></dt>
<dd><p>Orthogonal initializer.</p>
<dl class="docutils">
<dt># References</dt>
<dd>Saxe et al., <a class="reference external" href="http://arxiv.org/abs/1312.6120">http://arxiv.org/abs/1312.6120</a></dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.uniform">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">uniform</code><span class="sig-paren">(</span><em>shape</em>, <em>scale=0.05</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#uniform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.uniform" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.initializations.zero">
<code class="descclassname">deepchem.nn.initializations.</code><code class="descname">zero</code><span class="sig-paren">(</span><em>shape</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/initializations.html#zero"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.initializations.zero" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-deepchem.nn.layers">
<span id="deepchem-nn-layers-module"></span><h2>deepchem.nn.layers module<a class="headerlink" href="#module-deepchem.nn.layers" title="Permalink to this headline">¶</a></h2>
<p>Custom Keras Layers.</p>
<dl class="class">
<dt id="deepchem.nn.layers.AttnLSTMEmbedding">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">AttnLSTMEmbedding</code><span class="sig-paren">(</span><em>n_test</em>, <em>n_support</em>, <em>n_feat</em>, <em>max_depth</em>, <em>init='glorot_uniform'</em>, <em>activation='linear'</em>, <em>dropout=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#AttnLSTMEmbedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.AttnLSTMEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Implements AttnLSTM as in matching networks paper.</p>
<p>References:
Matching Networks for One Shot Learning
<a class="reference external" href="https://arxiv.org/pdf/1606.04080v1.pdf">https://arxiv.org/pdf/1606.04080v1.pdf</a></p>
<p>Order Matters: Sequence to sequence for sets
<a class="reference external" href="https://arxiv.org/abs/1511.06391">https://arxiv.org/abs/1511.06391</a></p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.AttnLSTMEmbedding.add_loss" title="deepchem.nn.layers.AttnLSTMEmbedding.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.AttnLSTMEmbedding.add_weight" title="deepchem.nn.layers.AttnLSTMEmbedding.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.AttnLSTMEmbedding.call" title="deepchem.nn.layers.AttnLSTMEmbedding.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x_xp[,&nbsp;mask])</td>
<td>Execute this layer on input tensors.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.AttnLSTMEmbedding.compute_mask" title="deepchem.nn.layers.AttnLSTMEmbedding.compute_mask"><code class="xref py py-obj docutils literal"><span class="pre">compute_mask</span></code></a>(x[,&nbsp;mask])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.AttnLSTMEmbedding.get_output_shape_for" title="deepchem.nn.layers.AttnLSTMEmbedding.get_output_shape_for"><code class="xref py py-obj docutils literal"><span class="pre">get_output_shape_for</span></code></a>(input_shape)</td>
<td>Returns the output shape.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.layers.AttnLSTMEmbedding.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.AttnLSTMEmbedding.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.AttnLSTMEmbedding.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.AttnLSTMEmbedding.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.AttnLSTMEmbedding.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x_xp</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#AttnLSTMEmbedding.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.AttnLSTMEmbedding.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x_xp: list</strong></p>
<blockquote>
<div><p>List of two tensors (X, Xp). X should be of shape (n_test, n_feat) and
Xp should be of shape (n_support, n_feat) where n_test is the size of
the test set, n_support that of the support set, and n_feat is the number
of per-atom features.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">list</p>
<blockquote class="last">
<div><p>Returns two tensors of same shape as input. Namely the output shape will
be [(n_test, n_feat), (n_support, n_feat)]</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.AttnLSTMEmbedding.compute_mask">
<code class="descname">compute_mask</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#AttnLSTMEmbedding.compute_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.AttnLSTMEmbedding.compute_mask" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.AttnLSTMEmbedding.get_output_shape_for">
<code class="descname">get_output_shape_for</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#AttnLSTMEmbedding.get_output_shape_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.AttnLSTMEmbedding.get_output_shape_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the output shape. Same as input_shape.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>input_shape: list</strong></p>
<blockquote>
<div><p>Will be of form [(n_test, n_feat), (n_support, n_feat)]</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">list</p>
<blockquote class="last">
<div><p>Of same shape as input [(n_test, n_feat), (n_support, n_feat)]</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.DAGGather">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">DAGGather</code><span class="sig-paren">(</span><em>n_graph_feat=30, n_outputs=30, max_atoms=50, layer_sizes=[100], init='glorot_uniform', activation='relu', dropout=None, **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGGather"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGGather" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Gather layer of DAG model
for each molecule, graph outputs are summed and input into another NN</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.DAGGather.DAGgraph_step" title="deepchem.nn.layers.DAGGather.DAGgraph_step"><code class="xref py py-obj docutils literal"><span class="pre">DAGgraph_step</span></code></a>(batch_inputs,&nbsp;W_list,&nbsp;b_list)</td>
<td></td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.DAGGather.add_loss" title="deepchem.nn.layers.DAGGather.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.DAGGather.add_weight" title="deepchem.nn.layers.DAGGather.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.DAGGather.build" title="deepchem.nn.layers.DAGGather.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td>&#8220;Construct internal trainable weights.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.DAGGather.call" title="deepchem.nn.layers.DAGGather.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x[,&nbsp;mask])</td>
<td>Execute this layer on input tensors.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.layers.DAGGather.DAGgraph_step">
<code class="descname">DAGgraph_step</code><span class="sig-paren">(</span><em>batch_inputs</em>, <em>W_list</em>, <em>b_list</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGGather.DAGgraph_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGGather.DAGgraph_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGGather.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DAGGather.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGGather.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DAGGather.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGGather.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGGather.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGGather.build" title="Permalink to this definition">¶</a></dt>
<dd><p>&#8220;Construct internal trainable weights.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGGather.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGGather.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGGather.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>x = [graph_features, membership]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: tf.Tensor</strong></p>
<blockquote>
<div><p>Tensor of each atom&#8217;s graph features</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">outputs: tf.Tensor</p>
<blockquote class="last">
<div><p>Tensor of each molecule&#8217;s features</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.DAGLayer">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">DAGLayer</code><span class="sig-paren">(</span><em>n_graph_feat=30, n_atom_feat=75, max_atoms=50, layer_sizes=[100], init='glorot_uniform', activation='relu', dropout=None, batch_size=64, **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>&#8221; Main layer of DAG model
For a molecule with n atoms, n different graphs are generated and run through
The final outputs of each graph become the graph features of corresponding
atom, which will be summed and put into another network in DAGGather Layer</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.DAGLayer.DAGgraph_step" title="deepchem.nn.layers.DAGLayer.DAGgraph_step"><code class="xref py py-obj docutils literal"><span class="pre">DAGgraph_step</span></code></a>(batch_inputs,&nbsp;W_list,&nbsp;b_list)</td>
<td></td>
</tr>
<tr class="row-even"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.DAGLayer.add_loss" title="deepchem.nn.layers.DAGLayer.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.DAGLayer.add_weight" title="deepchem.nn.layers.DAGLayer.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.DAGLayer.build" title="deepchem.nn.layers.DAGLayer.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td>&#8220;Construct internal trainable weights.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.DAGLayer.call" title="deepchem.nn.layers.DAGLayer.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x[,&nbsp;mask])</td>
<td>Execute this layer on input tensors.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.layers.DAGLayer.DAGgraph_step">
<code class="descname">DAGgraph_step</code><span class="sig-paren">(</span><em>batch_inputs</em>, <em>W_list</em>, <em>b_list</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGLayer.DAGgraph_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGLayer.DAGgraph_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGLayer.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DAGLayer.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGLayer.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DAGLayer.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGLayer.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGLayer.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGLayer.build" title="Permalink to this definition">¶</a></dt>
<dd><p>&#8220;Construct internal trainable weights.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DAGLayer.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DAGLayer.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DAGLayer.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>x = [atom_features, parents, calculation_orders, calculation_masks, membership, n_atoms]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: list</strong></p>
<blockquote>
<div><p>list of Tensors of form described above.</p>
</div></blockquote>
<p><strong>mask: bool, optional</strong></p>
<blockquote>
<div><p>Ignored. Present only to shadow superclass call() method.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">outputs: tf.Tensor</p>
<blockquote class="last">
<div><p>Tensor of atom features, of shape (n_atoms, n_graph_feat)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.DTNNEmbedding">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">DTNNEmbedding</code><span class="sig-paren">(</span><em>n_embedding=30</em>, <em>periodic_table_length=30</em>, <em>init='glorot_uniform'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNEmbedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Generate embeddings for all atoms in the batch</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.DTNNEmbedding.add_loss" title="deepchem.nn.layers.DTNNEmbedding.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.DTNNEmbedding.add_weight" title="deepchem.nn.layers.DTNNEmbedding.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.DTNNEmbedding.build" title="deepchem.nn.layers.DTNNEmbedding.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.DTNNEmbedding.call" title="deepchem.nn.layers.DTNNEmbedding.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x)</td>
<td>Execute this layer on input tensors.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.layers.DTNNEmbedding.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DTNNEmbedding.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNEmbedding.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DTNNEmbedding.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNEmbedding.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNEmbedding.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNEmbedding.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNEmbedding.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNEmbedding.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNEmbedding.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: Tensor</strong></p>
<blockquote>
<div><p>1D tensor of length n_atoms (atomic number)</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tf.Tensor</p>
<blockquote class="last">
<div><p>Of shape (n_atoms, n_embedding), where n_embedding is number of atom features</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.DTNNGather">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">DTNNGather</code><span class="sig-paren">(</span><em>n_embedding=30, n_outputs=100, layer_sizes=[100], output_activation=True, init='glorot_uniform', activation='tanh', **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNGather"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNGather" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Map the atomic features into molecular properties and sum</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.DTNNGather.add_loss" title="deepchem.nn.layers.DTNNGather.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.DTNNGather.add_weight" title="deepchem.nn.layers.DTNNGather.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.DTNNGather.build" title="deepchem.nn.layers.DTNNGather.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.DTNNGather.call" title="deepchem.nn.layers.DTNNGather.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x)</td>
<td>Execute this layer on input tensors.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.layers.DTNNGather.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DTNNGather.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNGather.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DTNNGather.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNGather.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNGather.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNGather.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNGather.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNGather.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNGather.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: list of Tensor</strong></p>
<blockquote>
<div><dl class="docutils">
<dt>should be [embedding tensor of molecules, of shape (batch_size*max_n_atoms*n_embedding),</dt>
<dd><p class="first last">mask tensor of molecules, of shape (batch_size*max_n_atoms)]</p>
</dd>
</dl>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">list of tf.Tensor</p>
<blockquote class="last">
<div><p>Of shape (batch_size)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.DTNNStep">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">DTNNStep</code><span class="sig-paren">(</span><em>n_embedding=30</em>, <em>n_distance=100</em>, <em>n_hidden=60</em>, <em>init='glorot_uniform'</em>, <em>activation='tanh'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNStep"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNStep" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>A convolution step that merge in distance and atom info of
all other atoms into current atom.</p>
<p>model based on <a class="reference external" href="https://arxiv.org/abs/1609.08259">https://arxiv.org/abs/1609.08259</a></p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.DTNNStep.add_loss" title="deepchem.nn.layers.DTNNStep.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.DTNNStep.add_weight" title="deepchem.nn.layers.DTNNStep.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.DTNNStep.build" title="deepchem.nn.layers.DTNNStep.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.DTNNStep.call" title="deepchem.nn.layers.DTNNStep.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x)</td>
<td>Execute this layer on input tensors.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.layers.DTNNStep.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DTNNStep.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNStep.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.DTNNStep.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNStep.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNStep.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNStep.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.DTNNStep.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#DTNNStep.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.DTNNStep.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: list of Tensor</strong></p>
<blockquote>
<div><dl class="docutils">
<dt>should be [atom_features: n_atoms*n_embedding,</dt>
<dd><p class="first last">distance_matrix: n_pairs*n_distance,
atom_membership: n_atoms
distance_membership_i: n_pairs,
distance_membership_j: n_pairs,
]</p>
</dd>
</dl>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tf.Tensor</p>
<blockquote class="last">
<div><p>new embeddings for atoms, same shape as x[0]</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.GraphConv">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">GraphConv</code><span class="sig-paren">(</span><em>nb_filter</em>, <em>n_atom_features</em>, <em>init='glorot_uniform'</em>, <em>activation='linear'</em>, <em>dropout=None</em>, <em>max_deg=10</em>, <em>min_deg=0</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphConv" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>&#8220;Performs a graph convolution.</p>
<p>Note this layer expects the presence of placeholders defined by GraphTopology
and expects that they follow the ordering provided by
GraphTopology.get_input_placeholders().</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.GraphConv.add_loss" title="deepchem.nn.layers.GraphConv.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.GraphConv.add_weight" title="deepchem.nn.layers.GraphConv.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.GraphConv.build" title="deepchem.nn.layers.GraphConv.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td>&#8220;Construct internal trainable weights.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.GraphConv.call" title="deepchem.nn.layers.GraphConv.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x[,&nbsp;mask])</td>
<td>Execute this layer on input tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.GraphConv.get_output_shape_for" title="deepchem.nn.layers.GraphConv.get_output_shape_for"><code class="xref py py-obj docutils literal"><span class="pre">get_output_shape_for</span></code></a>(input_shape)</td>
<td>Output tensor shape produced by this layer.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.layers.GraphConv.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.GraphConv.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphConv.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.GraphConv.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphConv.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphConv.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphConv.build" title="Permalink to this definition">¶</a></dt>
<dd><p>&#8220;Construct internal trainable weights.</p>
<p>n_atom_features should provide the number of features per atom.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>n_atom_features: int</strong></p>
<blockquote class="last">
<div><p>Number of features provied per atom.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphConv.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphConv.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphConv.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>This layer is meant to be executed on a Graph. So x is expected to
be a list of placeholders, with the first placeholder the list of
atom_features (learned or input) at this level, the second the deg_slice,
the third the membership, and the remaining the deg_adj_lists.</p>
<p>Visually</p>
<p>x = [atom_features, deg_slice, membership, deg_adj_list placeholders...]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: list</strong></p>
<blockquote>
<div><p>list of Tensors of form described above.</p>
</div></blockquote>
<p><strong>mask: bool, optional</strong></p>
<blockquote>
<div><p>Ignored. Present only to shadow superclass call() method.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">atom_features: tf.Tensor</p>
<blockquote class="last">
<div><p>Of shape (n_atoms, nb_filter)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphConv.get_output_shape_for">
<code class="descname">get_output_shape_for</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphConv.get_output_shape_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphConv.get_output_shape_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Output tensor shape produced by this layer.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.GraphGather">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">GraphGather</code><span class="sig-paren">(</span><em>batch_size</em>, <em>activation='linear'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphGather"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphGather" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Gathers information for each molecule.</p>
<p>The various graph convolution operations expect as input a tensor
atom_features of shape (n_atoms, n_feat). However, we train on batches of
molecules at a time. The GraphTopology object groups a list of molecules
into the atom_features tensor. The tensorial operations are done on this tensor,
but at the end, the atoms need to be grouped back into molecules. This
layer takes care of that operation.</p>
<p>Note this layer expects the presence of placeholders defined by GraphTopology
and expects that they follow the ordering provided by
GraphTopology.get_input_placeholders().</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.GraphGather.add_loss" title="deepchem.nn.layers.GraphGather.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.GraphGather.add_weight" title="deepchem.nn.layers.GraphGather.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.GraphGather.build" title="deepchem.nn.layers.GraphGather.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>(input_shape)</td>
<td>Nothing needed (no learnable weights).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.GraphGather.call" title="deepchem.nn.layers.GraphGather.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x[,&nbsp;mask])</td>
<td>Execute this layer on input tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.GraphGather.get_output_shape_for" title="deepchem.nn.layers.GraphGather.get_output_shape_for"><code class="xref py py-obj docutils literal"><span class="pre">get_output_shape_for</span></code></a>(input_shape)</td>
<td>Output tensor shape produced by this layer.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.layers.GraphGather.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.GraphGather.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphGather.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.GraphGather.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphGather.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphGather.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphGather.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Nothing needed (no learnable weights).</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphGather.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphGather.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphGather.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>This layer is meant to be executed on a Graph. So x is expected to
be a list of placeholders, with the first placeholder the list of
atom_features (learned or input) at this level, the second the deg_slice,
the third the membership, and the remaining the deg_adj_lists.</p>
<p>Visually</p>
<p>x = [atom_features, deg_slice, membership, deg_adj_list placeholders...]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: list</strong></p>
<blockquote>
<div><p>list of Tensors of form described above.</p>
</div></blockquote>
<p><strong>mask: bool, optional</strong></p>
<blockquote>
<div><p>Ignored. Present only to shadow superclass call() method.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tf.Tensor</p>
<blockquote class="last">
<div><p>Of shape (batch_size, n_feat), where n_feat is number of atom_features</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphGather.get_output_shape_for">
<code class="descname">get_output_shape_for</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphGather.get_output_shape_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphGather.get_output_shape_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Output tensor shape produced by this layer.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.GraphPool">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">GraphPool</code><span class="sig-paren">(</span><em>max_deg=10</em>, <em>min_deg=0</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphPool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphPool" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Performs a pooling operation over an arbitrary graph.</p>
<p>Performs a max pool over the feature vectors for an atom and its neighbors
in bond-graph. Returns a tensor of the same size as the input.</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.GraphPool.add_loss" title="deepchem.nn.layers.GraphPool.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.GraphPool.add_weight" title="deepchem.nn.layers.GraphPool.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.GraphPool.build" title="deepchem.nn.layers.GraphPool.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>(input_shape)</td>
<td>Nothing needed (no learnable weights).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.GraphPool.call" title="deepchem.nn.layers.GraphPool.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x[,&nbsp;mask])</td>
<td>Execute this layer on input tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.GraphPool.get_output_shape_for" title="deepchem.nn.layers.GraphPool.get_output_shape_for"><code class="xref py py-obj docutils literal"><span class="pre">get_output_shape_for</span></code></a>(input_shape)</td>
<td>Output tensor shape produced by this layer.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.layers.GraphPool.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.GraphPool.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphPool.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.GraphPool.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphPool.build">
<code class="descname">build</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphPool.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphPool.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Nothing needed (no learnable weights).</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphPool.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphPool.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphPool.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>This layer is meant to be executed on a Graph. So x is expected to
be a list of placeholders, with the first placeholder the list of
atom_features (learned or input) at this level, the second the deg_slice,
the third the membership, and the remaining the deg_adj_lists.</p>
<p>Visually</p>
<p>x = [atom_features, deg_slice, membership, deg_adj_list placeholders...]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: list</strong></p>
<blockquote>
<div><p>list of Tensors of form described above.</p>
</div></blockquote>
<p><strong>mask: bool, optional</strong></p>
<blockquote>
<div><p>Ignored. Present only to shadow superclass call() method.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tf.Tensor</p>
<blockquote class="last">
<div><p>Of shape (n_atoms, n_feat), where n_feat is number of atom_features</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.GraphPool.get_output_shape_for">
<code class="descname">get_output_shape_for</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#GraphPool.get_output_shape_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.GraphPool.get_output_shape_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Output tensor shape produced by this layer.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.LSTMStep">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">LSTMStep</code><span class="sig-paren">(</span><em>output_dim</em>, <em>input_dim</em>, <em>init='glorot_uniform'</em>, <em>inner_init='orthogonal'</em>, <em>forget_bias_init='one'</em>, <em>activation='tanh'</em>, <em>inner_activation='hard_sigmoid'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#LSTMStep"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.LSTMStep" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>LSTM whose call is a single step in the LSTM.</p>
<p>This layer exists because the Keras LSTM layer is intrinsically linked to an
RNN with sequence inputs, and here, we will not be using sequence inputs, but
rather we generate a sequence of inputs using the intermediate outputs of the
LSTM, and so will require step by step operation of the lstm</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.LSTMStep.add_loss" title="deepchem.nn.layers.LSTMStep.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.LSTMStep.add_weight" title="deepchem.nn.layers.LSTMStep.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.LSTMStep.build" title="deepchem.nn.layers.LSTMStep.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.LSTMStep.call" title="deepchem.nn.layers.LSTMStep.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x_states[,&nbsp;mask])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.LSTMStep.get_initial_states" title="deepchem.nn.layers.LSTMStep.get_initial_states"><code class="xref py py-obj docutils literal"><span class="pre">get_initial_states</span></code></a>(input_shape)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.LSTMStep.get_output_shape_for" title="deepchem.nn.layers.LSTMStep.get_output_shape_for"><code class="xref py py-obj docutils literal"><span class="pre">get_output_shape_for</span></code></a>(input_shape)</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.layers.LSTMStep.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.LSTMStep.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.LSTMStep.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.LSTMStep.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.LSTMStep.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#LSTMStep.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.LSTMStep.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.LSTMStep.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x_states</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#LSTMStep.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.LSTMStep.call" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.LSTMStep.get_initial_states">
<code class="descname">get_initial_states</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#LSTMStep.get_initial_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.LSTMStep.get_initial_states" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.LSTMStep.get_output_shape_for">
<code class="descname">get_output_shape_for</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#LSTMStep.get_output_shape_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.LSTMStep.get_output_shape_for" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.layers.ResiLSTMEmbedding">
<em class="property">class </em><code class="descclassname">deepchem.nn.layers.</code><code class="descname">ResiLSTMEmbedding</code><span class="sig-paren">(</span><em>n_test</em>, <em>n_support</em>, <em>n_feat</em>, <em>max_depth</em>, <em>init='glorot_uniform'</em>, <em>activation='linear'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#ResiLSTMEmbedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.ResiLSTMEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>Embeds its inputs using an LSTM layer.</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.ResiLSTMEmbedding.add_loss" title="deepchem.nn.layers.ResiLSTMEmbedding.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.ResiLSTMEmbedding.add_weight" title="deepchem.nn.layers.ResiLSTMEmbedding.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.ResiLSTMEmbedding.build" title="deepchem.nn.layers.ResiLSTMEmbedding.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td>Builds this layer.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.ResiLSTMEmbedding.call" title="deepchem.nn.layers.ResiLSTMEmbedding.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(argument[,&nbsp;mask])</td>
<td>Execute this layer on input tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.layers.ResiLSTMEmbedding.compute_mask" title="deepchem.nn.layers.ResiLSTMEmbedding.compute_mask"><code class="xref py py-obj docutils literal"><span class="pre">compute_mask</span></code></a>(x[,&nbsp;mask])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.layers.ResiLSTMEmbedding.get_output_shape_for" title="deepchem.nn.layers.ResiLSTMEmbedding.get_output_shape_for"><code class="xref py py-obj docutils literal"><span class="pre">get_output_shape_for</span></code></a>(input_shape)</td>
<td>Returns the output shape.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.layers.ResiLSTMEmbedding.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.ResiLSTMEmbedding.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.ResiLSTMEmbedding.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.layers.ResiLSTMEmbedding.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.ResiLSTMEmbedding.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#ResiLSTMEmbedding.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.ResiLSTMEmbedding.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds this layer.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.ResiLSTMEmbedding.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>argument</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#ResiLSTMEmbedding.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.ResiLSTMEmbedding.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>argument: list</strong></p>
<blockquote>
<div><p>List of two tensors (X, Xp). X should be of shape (n_test, n_feat) and
Xp should be of shape (n_support, n_feat) where n_test is the size of
the test set, n_support that of the support set, and n_feat is the number
of per-atom features.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">list</p>
<blockquote class="last">
<div><p>Returns two tensors of same shape as input. Namely the output shape will
be [(n_test, n_feat), (n_support, n_feat)]</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.ResiLSTMEmbedding.compute_mask">
<code class="descname">compute_mask</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#ResiLSTMEmbedding.compute_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.ResiLSTMEmbedding.compute_mask" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.layers.ResiLSTMEmbedding.get_output_shape_for">
<code class="descname">get_output_shape_for</code><span class="sig-paren">(</span><em>input_shape</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#ResiLSTMEmbedding.get_output_shape_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.ResiLSTMEmbedding.get_output_shape_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the output shape. Same as input_shape.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>input_shape: list</strong></p>
<blockquote>
<div><p>Will be of form [(n_test, n_feat), (n_support, n_feat)]</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">list</p>
<blockquote class="last">
<div><p>Of same shape as input [(n_test, n_feat), (n_support, n_feat)]</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="deepchem.nn.layers.affine">
<code class="descclassname">deepchem.nn.layers.</code><code class="descname">affine</code><span class="sig-paren">(</span><em>x</em>, <em>W</em>, <em>b</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#affine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.affine" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.layers.cos">
<code class="descclassname">deepchem.nn.layers.</code><code class="descname">cos</code><span class="sig-paren">(</span><em>x</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#cos"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.cos" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.layers.graph_conv">
<code class="descclassname">deepchem.nn.layers.</code><code class="descname">graph_conv</code><span class="sig-paren">(</span><em>atoms</em>, <em>deg_adj_lists</em>, <em>deg_slice</em>, <em>max_deg</em>, <em>min_deg</em>, <em>W_list</em>, <em>b_list</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#graph_conv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.graph_conv" title="Permalink to this definition">¶</a></dt>
<dd><p>Core tensorflow function implementing graph convolution</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>atoms: tf.Tensor</strong></p>
<blockquote>
<div><p>Should be of shape (n_atoms, n_feat)</p>
</div></blockquote>
<p><strong>deg_adj_lists: list</strong></p>
<blockquote>
<div><p>Of length (max_deg+1-min_deg). The deg-th element is a list of
adjacency lists for atoms of degree deg.</p>
</div></blockquote>
<p><strong>deg_slice: tf.Tensor</strong></p>
<blockquote>
<div><p>Of shape (max_deg+1-min_deg,2). Explained in GraphTopology.</p>
</div></blockquote>
<p><strong>max_deg: int</strong></p>
<blockquote>
<div><p>Maximum degree of atoms in molecules.</p>
</div></blockquote>
<p><strong>min_deg: int</strong></p>
<blockquote>
<div><p>Minimum degree of atoms in molecules</p>
</div></blockquote>
<p><strong>W_list: list</strong></p>
<blockquote>
<div><p>List of learnable weights for convolution.</p>
</div></blockquote>
<p><strong>b_list: list</strong></p>
<blockquote>
<div><p>List of learnable biases for convolution.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tf.Tensor</p>
<blockquote class="last">
<div><p>Of shape (n_atoms, n_feat)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.layers.graph_gather">
<code class="descclassname">deepchem.nn.layers.</code><code class="descname">graph_gather</code><span class="sig-paren">(</span><em>atoms</em>, <em>membership_placeholder</em>, <em>batch_size</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#graph_gather"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.graph_gather" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>atoms: tf.Tensor</strong></p>
<blockquote>
<div><p>Of shape (n_atoms, n_feat)</p>
</div></blockquote>
<p><strong>membership_placeholder: tf.Placeholder</strong></p>
<blockquote>
<div><p>Of shape (n_atoms,). Molecule each atom belongs to.</p>
</div></blockquote>
<p><strong>batch_size: int</strong></p>
<blockquote>
<div><p>Batch size for deep model.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tf.Tensor</p>
<blockquote class="last">
<div><p>Of shape (batch_size, n_feat)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.layers.graph_pool">
<code class="descclassname">deepchem.nn.layers.</code><code class="descname">graph_pool</code><span class="sig-paren">(</span><em>atoms</em>, <em>deg_adj_lists</em>, <em>deg_slice</em>, <em>max_deg</em>, <em>min_deg</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#graph_pool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.graph_pool" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>atoms: tf.Tensor</strong></p>
<blockquote>
<div><p>Of shape (n_atoms, n_feat)</p>
</div></blockquote>
<p><strong>deg_adj_lists: list</strong></p>
<blockquote>
<div><p>Of length (max_deg+1-min_deg). The deg-th element is a list of
adjacency lists for atoms of degree deg.</p>
</div></blockquote>
<p><strong>deg_slice: tf.Tensor</strong></p>
<blockquote>
<div><p>Of shape (max_deg+1-min_deg,2). Explained in GraphTopology.</p>
</div></blockquote>
<p><strong>max_deg: int</strong></p>
<blockquote>
<div><p>Maximum degree of atoms in molecules.</p>
</div></blockquote>
<p><strong>min_deg: int</strong></p>
<blockquote>
<div><p>Minimum degree of atoms in molecules</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tf.Tensor</p>
<blockquote class="last">
<div><p>Of shape (batch_size, n_feat)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.layers.sum_neigh">
<code class="descclassname">deepchem.nn.layers.</code><code class="descname">sum_neigh</code><span class="sig-paren">(</span><em>atoms</em>, <em>deg_adj_lists</em>, <em>max_deg</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#sum_neigh"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.sum_neigh" title="Permalink to this definition">¶</a></dt>
<dd><p>Store the summed atoms by degree</p>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.layers.tf_affine">
<code class="descclassname">deepchem.nn.layers.</code><code class="descname">tf_affine</code><span class="sig-paren">(</span><em>x</em>, <em>vm</em>, <em>scope</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/layers.html#tf_affine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.layers.tf_affine" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-deepchem.nn.model_ops">
<span id="deepchem-nn-model-ops-module"></span><h2>deepchem.nn.model_ops module<a class="headerlink" href="#module-deepchem.nn.model_ops" title="Permalink to this headline">¶</a></h2>
<p>Ops for graph construction.</p>
<p>Large amounts of code borrowed from Keras. Will try to incorporate into
DeepChem properly.</p>
<dl class="function">
<dt id="deepchem.nn.model_ops.add_bias">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">add_bias</code><span class="sig-paren">(</span><em>tensor</em>, <em>init=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#add_bias"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.add_bias" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a bias term to a tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>tensor: tf.Tensor</strong></p>
<blockquote>
<div><p>Variable tensor.</p>
</div></blockquote>
<p><strong>init: float</strong></p>
<blockquote>
<div><p>Bias initializer. Defaults to zero.</p>
</div></blockquote>
<p><strong>name: str</strong></p>
<blockquote>
<div><p>Name for this op. Defaults to tensor.op.name.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tf.Tensor</p>
<blockquote class="last">
<div><p>A biased tensor with the same shape as the input tensor.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.binary_crossentropy">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">binary_crossentropy</code><span class="sig-paren">(</span><em>output</em>, <em>target</em>, <em>from_logits=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#binary_crossentropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.binary_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary crossentropy between an output tensor and a target tensor.</p>
<dl class="docutils">
<dt># Arguments</dt>
<dd><p class="first">output: A tensor.
target: A tensor with the same shape as <cite>output</cite>.
from_logits: Whether <cite>output</cite> is expected to be a logits tensor.</p>
<blockquote class="last">
<div>By default, we consider that <cite>output</cite>
encodes a probability distribution.</div></blockquote>
</dd>
<dt># Returns</dt>
<dd>A tensor.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.cast_to_floatx">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">cast_to_floatx</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#cast_to_floatx"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.cast_to_floatx" title="Permalink to this definition">¶</a></dt>
<dd><p>Cast a Numpy array to the default Keras float type.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x: Numpy array.</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The same Numpy array, cast to its new type.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.categorical_crossentropy">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">categorical_crossentropy</code><span class="sig-paren">(</span><em>output</em>, <em>target</em>, <em>from_logits=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#categorical_crossentropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.categorical_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Categorical crossentropy between an output tensor
and a target tensor, where the target is a tensor of the same
shape as the output.</p>
<p># TODO(rbharath): Should probably swap this over to tf mode.</p>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.clip">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">clip</code><span class="sig-paren">(</span><em>x</em>, <em>min_value</em>, <em>max_value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#clip"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.clip" title="Permalink to this definition">¶</a></dt>
<dd><p>Element-wise value clipping.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">A tensor.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.concatenate">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">concatenate</code><span class="sig-paren">(</span><em>tensors</em>, <em>axis=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#concatenate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.concatenate" title="Permalink to this definition">¶</a></dt>
<dd><p>Concatenates a list of tensors alongside the specified axis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">A tensor.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.cosine_distances">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">cosine_distances</code><span class="sig-paren">(</span><em>test</em>, <em>support</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#cosine_distances"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.cosine_distances" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes pairwise cosine distances between provided tensors</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>test: tf.Tensor</strong></p>
<blockquote>
<div><p>Of shape (n_test, n_feat)</p>
</div></blockquote>
<p><strong>support: tf.Tensor</strong></p>
<blockquote>
<div><p>Of shape (n_support, n_feat)</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tf.Tensor:</p>
<blockquote class="last">
<div><p>Of shape (n_test, n_support)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.dot">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">dot</code><span class="sig-paren">(</span><em>x</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#dot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.dot" title="Permalink to this definition">¶</a></dt>
<dd><p>Multiplies 2 tensors (and/or variables) and returns a <em>tensor</em>.
When attempting to multiply a ND tensor
with a ND tensor, it reproduces the Theano behavior.
(e.g. (2, 3).(4, 3, 5) = (2, 4, 5))</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: Tensor or variable.</strong></p>
<p><strong>y: Tensor or variable.</strong></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A tensor, dot product of x and y.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.dropout">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">dropout</code><span class="sig-paren">(</span><em>tensor</em>, <em>dropout_prob</em>, <em>training=True</em>, <em>training_only=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#dropout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.dropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Random dropout.</p>
<p>This implementation supports &#8220;always-on&#8221; dropout (training_only=False), which
can be used to calculate model uncertainty. See Gal and Ghahramani,
<a class="reference external" href="http://arxiv.org/abs/1506.02142">http://arxiv.org/abs/1506.02142</a>.</p>
<dl class="docutils">
<dt>NOTE(user): To simplify the implementation, I have chosen not to reverse</dt>
<dd>the scaling that occurs in tf.nn.dropout when using dropout during
inference. This shouldn&#8217;t be an issue since the activations will be scaled
by the same constant in both training and inference. This means that there
are no training-time differences between networks that use dropout during
inference and those that do not.</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>tensor: tf.Tensor</strong></p>
<blockquote>
<div><p>Input tensor.</p>
</div></blockquote>
<p><strong>dropout_prob: float</strong></p>
<blockquote>
<div><p>Float giving dropout probability for weights (NOT keep probability).</p>
</div></blockquote>
<p><strong>training_only: bool</strong></p>
<blockquote>
<div><p>Boolean. If True (standard dropout), apply dropout only
during training. If False, apply dropout during inference as well.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tf.Tensor:</p>
<blockquote class="last">
<div><p>A tensor with the same shape as the input tensor.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.elu">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">elu</code><span class="sig-paren">(</span><em>x</em>, <em>alpha=1.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#elu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.elu" title="Permalink to this definition">¶</a></dt>
<dd><p>Exponential linear unit.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: A tensor or variable to compute the activation function for.</strong></p>
<p><strong>alpha: A scalar, slope of positive section.</strong></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A tensor.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.epsilon">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">epsilon</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#epsilon"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.epsilon" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the value of the fuzz
factor used in numeric expressions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">A float.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.euclidean_distance">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">euclidean_distance</code><span class="sig-paren">(</span><em>test</em>, <em>support</em>, <em>max_dist_sq=20</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#euclidean_distance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.euclidean_distance" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes pairwise euclidean distances between provided tensors</p>
<p>TODO(rbharath): BROKEN! THIS DOESN&#8217;T WORK!</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>test: tf.Tensor</strong></p>
<blockquote>
<div><p>Of shape (n_test, n_feat)</p>
</div></blockquote>
<p><strong>support: tf.Tensor</strong></p>
<blockquote>
<div><p>Of shape (n_support, n_feat)</p>
</div></blockquote>
<p><strong>max_dist_sq: float, optional</strong></p>
<blockquote>
<div><p>Maximum pairwise distance allowed.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tf.Tensor:</p>
<blockquote class="last">
<div><p>Of shape (n_test, n_support)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.fully_connected_layer">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">fully_connected_layer</code><span class="sig-paren">(</span><em>tensor</em>, <em>size=None</em>, <em>weight_init=None</em>, <em>bias_init=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#fully_connected_layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.fully_connected_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Fully connected layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>tensor: tf.Tensor</strong></p>
<blockquote>
<div><p>Input tensor.</p>
</div></blockquote>
<p><strong>size: int</strong></p>
<blockquote>
<div><p>Number of output nodes for this layer.</p>
</div></blockquote>
<p><strong>weight_init: float</strong></p>
<blockquote>
<div><p>Weight initializer.</p>
</div></blockquote>
<p><strong>bias_init: float</strong></p>
<blockquote>
<div><p>Bias initializer.</p>
</div></blockquote>
<p><strong>name: str</strong></p>
<blockquote>
<div><p>Name for this op. Defaults to &#8216;fully_connected&#8217;.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tf.Tensor:</p>
<blockquote>
<div><p>A new tensor representing the output of the fully connected layer.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Raises:</th><td class="field-body"><p class="first"><strong>ValueError</strong></p>
<blockquote class="last">
<div><p>If input tensor is not 2D.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.get_dtype">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">get_dtype</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#get_dtype"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.get_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the dtype of a Keras tensor or variable, as a string.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x: Tensor or variable.</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">String, dtype of <cite>x</cite>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.get_ndim">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">get_ndim</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#get_ndim"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.get_ndim" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of axes in a tensor, as an integer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x: Tensor or variable.</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Integer (scalar), number of axes.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.get_uid">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">get_uid</code><span class="sig-paren">(</span><em>prefix=''</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#get_uid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.get_uid" title="Permalink to this definition">¶</a></dt>
<dd><p>Provides a unique UID given a string prefix.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>prefix: string.</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">An integer.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.hard_sigmoid">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">hard_sigmoid</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#hard_sigmoid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.hard_sigmoid" title="Permalink to this definition">¶</a></dt>
<dd><p>Segment-wise linear approximation of sigmoid.
Faster than sigmoid.
Returns 0. if x &lt; -2.5, 1. if x &gt; 2.5.
In -2.5 &lt;= x &lt;= 2.5, returns 0.2 * x + 0.5.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x: A tensor or variable.</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A tensor.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.in_train_phase">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">in_train_phase</code><span class="sig-paren">(</span><em>x</em>, <em>alt</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#in_train_phase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.in_train_phase" title="Permalink to this definition">¶</a></dt>
<dd><p>Selects <cite>x</cite> in train phase, and <cite>alt</cite> otherwise.
Note that <cite>alt</cite> should have the <em>same shape</em> as <cite>x</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Either <cite>x</cite> or <cite>alt</cite> based on <cite>K.learning_phase</cite>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.int_shape">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">int_shape</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#int_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.int_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the shape of a Keras tensor or a Keras variable as a tuple of
integers or None entries.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">A tuple of integers (or None entries).</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.l2_normalize">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">l2_normalize</code><span class="sig-paren">(</span><em>x</em>, <em>axis</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#l2_normalize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.l2_normalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalizes a tensor wrt the L2 norm alongside the specified axis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: input tensor.</strong></p>
<p><strong>axis: axis along which to perform normalization.</strong></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A tensor.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.learning_phase">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">learning_phase</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#learning_phase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.learning_phase" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the learning phase flag.</p>
<p>The learning phase flag is a bool tensor (0 = test, 1 = train)
to be passed as input to any Keras function
that uses a different behavior at train time and test time.</p>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.logits">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">logits</code><span class="sig-paren">(</span><em>features</em>, <em>num_classes=2</em>, <em>weight_init=None</em>, <em>bias_init=None</em>, <em>dropout_prob=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.logits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a logits tensor for a single classification task.</p>
<p>You almost certainly don&#8217;t want dropout on there &#8211; it&#8217;s like randomly setting
the (unscaled) probability of a target class to 0.5.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">features: A 2D tensor with dimensions batch_size x num_features.
num_classes: Number of classes for each task.
weight_init: Weight initializer.
bias_init: Bias initializer.
dropout_prob: Float giving dropout probability for weights (NOT keep</p>
<blockquote>
<div>probability).</div></blockquote>
<p class="last">name: Name for this op.</p>
</dd>
<dt>Returns:</dt>
<dd>A logits tensor with shape batch_size x num_classes.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.lrelu">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">lrelu</code><span class="sig-paren">(</span><em>alpha=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#lrelu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.lrelu" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a leaky rectified linear unit function.</p>
<p>This function returns a new function that implements the LReLU with a
specified alpha.  The returned value can be used as an activation function in
network layers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>alpha: float</strong></p>
<blockquote>
<div><p>the slope of the function when x&lt;0</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">a function f(x) that returns alpha*x when x&lt;0, and x when x&gt;0.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.max">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">max</code><span class="sig-paren">(</span><em>x</em>, <em>axis=None</em>, <em>keepdims=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#max"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.max" title="Permalink to this definition">¶</a></dt>
<dd><p>Maximum value in a tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: A tensor or variable.</strong></p>
<p><strong>axis: An integer, the axis to find maximum values.</strong></p>
<p><strong>keepdims: A boolean, whether to keep the dimensions or not.</strong></p>
<blockquote>
<div><p>If <cite>keepdims</cite> is <cite>False</cite>, the rank of the tensor is reduced
by 1. If <cite>keepdims</cite> is <cite>True</cite>,
the reduced dimension is retained with length 1.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A tensor with maximum values of <cite>x</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.mean">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">mean</code><span class="sig-paren">(</span><em>x</em>, <em>axis=None</em>, <em>keepdims=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#mean"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean of a tensor, alongside the specified axis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: A tensor or variable.</strong></p>
<p><strong>axis: A list of integer. Axes to compute the mean.</strong></p>
<p><strong>keepdims: A boolean, whether to keep the dimensions or not.</strong></p>
<blockquote>
<div><p>If keepdims is False, the rank of the tensor is reduced
by 1 for each entry in axis. If keep_dims is True,
the reduced dimensions are retained with length 1.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A tensor with the mean of elements of x.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.moving_average_update">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">moving_average_update</code><span class="sig-paren">(</span><em>variable</em>, <em>value</em>, <em>momentum</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#moving_average_update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.moving_average_update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.multitask_logits">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">multitask_logits</code><span class="sig-paren">(</span><em>features</em>, <em>num_tasks</em>, <em>num_classes=2</em>, <em>weight_init=None</em>, <em>bias_init=None</em>, <em>dropout_prob=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#multitask_logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.multitask_logits" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a logit tensor for each classification task.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">features: A 2D tensor with dimensions batch_size x num_features.
num_tasks: Number of classification tasks.
num_classes: Number of classes for each task.
weight_init: Weight initializer.
bias_init: Bias initializer.
dropout_prob: Float giving dropout probability for weights (NOT keep</p>
<blockquote>
<div>probability).</div></blockquote>
<p class="last">name: Name for this op. Defaults to &#8216;multitask_logits&#8217;.</p>
</dd>
<dt>Returns:</dt>
<dd>A list of logit tensors; one for each classification task.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.normalize_batch_in_training">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">normalize_batch_in_training</code><span class="sig-paren">(</span><em>x</em>, <em>gamma</em>, <em>beta</em>, <em>reduction_axes</em>, <em>epsilon=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#normalize_batch_in_training"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.normalize_batch_in_training" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes mean and std for batch then apply batch_normalization on batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">A tuple length of 3, (normalized_tensor, mean, variance).</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.ones">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">ones</code><span class="sig-paren">(</span><em>shape</em>, <em>dtype=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#ones"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.ones" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates an all-ones tensor variable and returns it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: Tuple of integers, shape of returned Keras variable.</strong></p>
<p><strong>dtype: Tensorflow dtype</strong></p>
<p><strong>name: String, name of returned Keras variable.</strong></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Keras variable, filled with <cite>1.0</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.optimizer">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">optimizer</code><span class="sig-paren">(</span><em>optimizer='adam'</em>, <em>learning_rate=0.001</em>, <em>momentum=0.9</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#optimizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Create model optimizer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>optimizer: str, optional</strong></p>
<blockquote>
<div><p>Name of optimizer</p>
</div></blockquote>
<p><strong>learning_rate: float, optional</strong></p>
<blockquote>
<div><p>Learning rate for algorithm</p>
</div></blockquote>
<p><strong>momentum: float, optional</strong></p>
<blockquote>
<div><p>Momentum rate</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A training Optimizer.</p>
<p>Raises:</p>
<blockquote class="last">
<div><p>NotImplementedError: If an unsupported optimizer is requested.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.random_normal_variable">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">random_normal_variable</code><span class="sig-paren">(</span><em>shape</em>, <em>mean</em>, <em>scale</em>, <em>dtype=tf.float32</em>, <em>name=None</em>, <em>seed=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#random_normal_variable"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.random_normal_variable" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates an Keras variable filled with
samples drawn from a normal distribution and returns it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: Tuple of integers, shape of returned Keras variable.</strong></p>
<p><strong>mean: Float, mean of the normal distribution.</strong></p>
<p><strong>scale: Float, standard deviation of the normal distribution.</strong></p>
<p><strong>dtype: Tensorflow dtype</strong></p>
<p><strong>name: String, name of returned Keras variable.</strong></p>
<p><strong>seed: Integer, random seed.</strong></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A tf.Variable, filled with drawn samples.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.random_uniform_variable">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">random_uniform_variable</code><span class="sig-paren">(</span><em>shape</em>, <em>low</em>, <em>high</em>, <em>dtype=tf.float32</em>, <em>name=None</em>, <em>seed=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#random_uniform_variable"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.random_uniform_variable" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates an variable filled with
samples drawn from a uniform distribution and returns it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: Tuple of integers, shape of returned variable.</strong></p>
<p><strong>low: Float, lower boundary of the output inteval.</strong></p>
<p><strong>high: Float, upper boundary of the output interval.</strong></p>
<p><strong>dtype: Tensorflow dtype</strong></p>
<p><strong>name: String, name of returned variable.</strong></p>
<p><strong>seed: Integer, random seed.</strong></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A tf.Variable, filled with drawn samples.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.relu">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">relu</code><span class="sig-paren">(</span><em>x</em>, <em>alpha=0.0</em>, <em>max_value=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#relu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.relu" title="Permalink to this definition">¶</a></dt>
<dd><p>Rectified linear unit.
With default values, it returns element-wise <cite>max(x, 0)</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: A tensor or variable.</strong></p>
<p><strong>alpha: A scalar, slope of negative section (default=`0.`).</strong></p>
<p><strong>max_value: Saturation threshold.</strong></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A tensor.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.selu">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">selu</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#selu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.selu" title="Permalink to this definition">¶</a></dt>
<dd><p>Scaled Exponential Linear unit.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x: A tensor or variable.</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A tensor.</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<ul class="simple">
<li>[Self-Normalizing Neural Networks](<a class="reference external" href="https://arxiv.org/abs/1706.02515">https://arxiv.org/abs/1706.02515</a>)</li>
</ul>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.softmax_N">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">softmax_N</code><span class="sig-paren">(</span><em>tensor</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#softmax_N"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.softmax_N" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply softmax across last dimension of a tensor.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>tensor: Input tensor.
name: Name for this op. If None, defaults to &#8216;softmax_N&#8217;.</dd>
<dt>Returns:</dt>
<dd>A tensor with softmax-normalized values on the last dimension.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.sparse_categorical_crossentropy">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">sparse_categorical_crossentropy</code><span class="sig-paren">(</span><em>output</em>, <em>target</em>, <em>from_logits=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#sparse_categorical_crossentropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.sparse_categorical_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Categorical crossentropy between an output tensor
and a target tensor, where the target is an integer tensor.</p>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.sqrt">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">sqrt</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#sqrt"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.sqrt" title="Permalink to this definition">¶</a></dt>
<dd><p>Element-wise square root.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x: input tensor.</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A tensor.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.sum">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">sum</code><span class="sig-paren">(</span><em>x</em>, <em>axis=None</em>, <em>keepdims=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#sum"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.sum" title="Permalink to this definition">¶</a></dt>
<dd><p>Sum of the values in a tensor, alongside the specified axis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: A tensor or variable.</strong></p>
<p><strong>axis: An integer, the axis to sum over.</strong></p>
<p><strong>keepdims: A boolean, whether to keep the dimensions or not.</strong></p>
<blockquote>
<div><p>If keepdims is False, the rank of the tensor is reduced
by 1. If keepdims is True,
the reduced dimension is retained with length 1.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A tensor with sum of x.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.switch">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">switch</code><span class="sig-paren">(</span><em>condition</em>, <em>then_expression</em>, <em>else_expression</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#switch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.switch" title="Permalink to this definition">¶</a></dt>
<dd><p>Switches between two operations
depending on a scalar value (<cite>int</cite> or <cite>bool</cite>).
Note that both <cite>then_expression</cite> and <cite>else_expression</cite>
should be symbolic tensors of the <em>same shape</em>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>condition: scalar tensor.</strong></p>
<p><strong>then_expression: either a tensor, or a callable that returns a tensor.</strong></p>
<p><strong>else_expression: either a tensor, or a callable that returns a tensor.</strong></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">The selected tensor.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.var">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">var</code><span class="sig-paren">(</span><em>x</em>, <em>axis=None</em>, <em>keepdims=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#var"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.var" title="Permalink to this definition">¶</a></dt>
<dd><p>Variance of a tensor, alongside the specified axis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: A tensor or variable.</strong></p>
<p><strong>axis: An integer, the axis to compute the variance.</strong></p>
<p><strong>keepdims: A boolean, whether to keep the dimensions or not.</strong></p>
<blockquote>
<div><p>If keepdims is False, the rank of the tensor is reduced
by 1. If keepdims is True,
the reduced dimension is retained with length 1.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A tensor with the variance of elements of <cite>x</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.weight_decay">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">weight_decay</code><span class="sig-paren">(</span><em>penalty_type</em>, <em>penalty</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#weight_decay"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.weight_decay" title="Permalink to this definition">¶</a></dt>
<dd><p>Add weight decay.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>model: TensorflowGraph.</dd>
<dt>Returns:</dt>
<dd>A scalar tensor containing the weight decay cost.</dd>
<dt>Raises:</dt>
<dd>NotImplementedError: If an unsupported penalty type is requested.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.model_ops.zeros">
<code class="descclassname">deepchem.nn.model_ops.</code><code class="descname">zeros</code><span class="sig-paren">(</span><em>shape</em>, <em>dtype=tf.float32</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/model_ops.html#zeros"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.model_ops.zeros" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates an all-zeros variable and returns it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: Tuple of integers, shape of returned Keras variable</strong></p>
<p><strong>dtype: Tensorflow dtype</strong></p>
<p><strong>name: String, name of returned Keras variable</strong></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A variable (including Keras metadata), filled with <cite>0.0</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-deepchem.nn.objectives">
<span id="deepchem-nn-objectives-module"></span><h2>deepchem.nn.objectives module<a class="headerlink" href="#module-deepchem.nn.objectives" title="Permalink to this headline">¶</a></h2>
<p>Ops for objectives</p>
<p>Code borrowed from Keras.</p>
<dl class="function">
<dt id="deepchem.nn.objectives.KLD">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">KLD</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.KLD" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.MAE">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">MAE</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.MAE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.MAPE">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">MAPE</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.MAPE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.MSE">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">MSE</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.MSE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.MSLE">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">MSLE</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.MSLE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.binary_crossentropy">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">binary_crossentropy</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#binary_crossentropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.binary_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.categorical_crossentropy">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">categorical_crossentropy</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#categorical_crossentropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.categorical_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.cosine">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">cosine</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.cosine" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.cosine_proximity">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">cosine_proximity</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#cosine_proximity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.cosine_proximity" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.hinge">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">hinge</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#hinge"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.hinge" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.kld">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">kld</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.kld" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.kullback_leibler_divergence">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">kullback_leibler_divergence</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#kullback_leibler_divergence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.kullback_leibler_divergence" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.mae">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">mae</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.mae" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.mape">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">mape</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.mape" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.mean_absolute_error">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">mean_absolute_error</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#mean_absolute_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.mean_absolute_error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.mean_absolute_percentage_error">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">mean_absolute_percentage_error</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#mean_absolute_percentage_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.mean_absolute_percentage_error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.mean_squared_error">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">mean_squared_error</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#mean_squared_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.mean_squared_error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.mean_squared_logarithmic_error">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">mean_squared_logarithmic_error</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#mean_squared_logarithmic_error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.mean_squared_logarithmic_error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.mse">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">mse</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.mse" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.msle">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">msle</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.objectives.msle" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.poisson">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">poisson</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#poisson"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.poisson" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.sparse_categorical_crossentropy">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">sparse_categorical_crossentropy</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#sparse_categorical_crossentropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.sparse_categorical_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.objectives.squared_hinge">
<code class="descclassname">deepchem.nn.objectives.</code><code class="descname">squared_hinge</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/objectives.html#squared_hinge"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.objectives.squared_hinge" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-deepchem.nn.regularizers">
<span id="deepchem-nn-regularizers-module"></span><h2>deepchem.nn.regularizers module<a class="headerlink" href="#module-deepchem.nn.regularizers" title="Permalink to this headline">¶</a></h2>
<p>Ops for regularizers</p>
<p>Code borrowed from Keras.</p>
<dl class="attribute">
<dt id="deepchem.nn.regularizers.ActivityRegularizer">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">ActivityRegularizer</code><a class="headerlink" href="#deepchem.nn.regularizers.ActivityRegularizer" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#deepchem.nn.regularizers.L1L2Regularizer" title="deepchem.nn.regularizers.L1L2Regularizer"><code class="xref py py-class docutils literal"><span class="pre">L1L2Regularizer</span></code></a></p>
</dd></dl>

<dl class="class">
<dt id="deepchem.nn.regularizers.L1L2Regularizer">
<em class="property">class </em><code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">L1L2Regularizer</code><span class="sig-paren">(</span><em>l1=0.0</em>, <em>l2=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#L1L2Regularizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.L1L2Regularizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.regularizers.Regularizer" title="deepchem.nn.regularizers.Regularizer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.regularizers.Regularizer</span></code></a></p>
<p>Regularizer for L1 and L2 regularization.</p>
<dl class="docutils">
<dt># Arguments</dt>
<dd>l1: Float; L1 regularization factor.
l2: Float; L2 regularization factor.</dd>
</dl>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="deepchem.nn.regularizers.Regularizer">
<em class="property">class </em><code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">Regularizer</code><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#Regularizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.Regularizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.nn.regularizers.WeightRegularizer">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">WeightRegularizer</code><a class="headerlink" href="#deepchem.nn.regularizers.WeightRegularizer" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#deepchem.nn.regularizers.L1L2Regularizer" title="deepchem.nn.regularizers.L1L2Regularizer"><code class="xref py py-class docutils literal"><span class="pre">L1L2Regularizer</span></code></a></p>
</dd></dl>

<dl class="function">
<dt id="deepchem.nn.regularizers.activity_l1">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">activity_l1</code><span class="sig-paren">(</span><em>l=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#activity_l1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.activity_l1" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.regularizers.activity_l1l2">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">activity_l1l2</code><span class="sig-paren">(</span><em>l1=0.01</em>, <em>l2=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#activity_l1l2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.activity_l1l2" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.regularizers.activity_l2">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">activity_l2</code><span class="sig-paren">(</span><em>l=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#activity_l2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.activity_l2" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.regularizers.l1">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">l1</code><span class="sig-paren">(</span><em>l=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#l1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.l1" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.regularizers.l1l2">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">l1l2</code><span class="sig-paren">(</span><em>l1=0.01</em>, <em>l2=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#l1l2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.l1l2" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="deepchem.nn.regularizers.l2">
<code class="descclassname">deepchem.nn.regularizers.</code><code class="descname">l2</code><span class="sig-paren">(</span><em>l=0.01</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/regularizers.html#l2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.regularizers.l2" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-deepchem.nn.weave_layers">
<span id="deepchem-nn-weave-layers-module"></span><h2>deepchem.nn.weave_layers module<a class="headerlink" href="#module-deepchem.nn.weave_layers" title="Permalink to this headline">¶</a></h2>
<p>Created on Thu Mar 30 14:02:04 2017</p>
<p>&#64;author: michael</p>
<dl class="class">
<dt id="deepchem.nn.weave_layers.AlternateWeaveGather">
<em class="property">class </em><code class="descclassname">deepchem.nn.weave_layers.</code><code class="descname">AlternateWeaveGather</code><span class="sig-paren">(</span><em>batch_size</em>, <em>n_input=128</em>, <em>gaussian_expand=False</em>, <em>init='glorot_uniform'</em>, <em>activation='tanh'</em>, <em>epsilon=0.001</em>, <em>momentum=0.99</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#AlternateWeaveGather"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveGather" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.weave_layers.WeaveGather" title="deepchem.nn.weave_layers.WeaveGather"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.weave_layers.WeaveGather</span></code></a></p>
<p>Alternate implementation of weave gather layer
corresponding to AlternateWeaveLayer</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.weave_layers.AlternateWeaveGather.add_loss" title="deepchem.nn.weave_layers.AlternateWeaveGather.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.weave_layers.AlternateWeaveGather.add_weight" title="deepchem.nn.weave_layers.AlternateWeaveGather.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.weave_layers.AlternateWeaveGather.build" title="deepchem.nn.weave_layers.AlternateWeaveGather.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.weave_layers.AlternateWeaveGather.call" title="deepchem.nn.weave_layers.AlternateWeaveGather.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x[,&nbsp;mask])</td>
<td>Execute this layer on input tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.weave_layers.AlternateWeaveGather.gaussian_histogram" title="deepchem.nn.weave_layers.AlternateWeaveGather.gaussian_histogram"><code class="xref py py-obj docutils literal"><span class="pre">gaussian_histogram</span></code></a>(x)</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveGather.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveGather.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveGather.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveGather.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveGather.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveGather.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveGather.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#AlternateWeaveGather.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveGather.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>x = [atom_features, atom_split]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: list</strong></p>
<blockquote>
<div><p>Tensors as listed above</p>
</div></blockquote>
<p><strong>mask: bool, optional</strong></p>
<blockquote>
<div><p>Ignored. Present only to shadow superclass call() method.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">outputs: Tensor</p>
<blockquote class="last">
<div><p>Tensor of molecular features</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveGather.gaussian_histogram">
<code class="descname">gaussian_histogram</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveGather.gaussian_histogram" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.weave_layers.AlternateWeaveLayer">
<em class="property">class </em><code class="descclassname">deepchem.nn.weave_layers.</code><code class="descname">AlternateWeaveLayer</code><span class="sig-paren">(</span><em>max_atoms</em>, <em>n_atom_input_feat=75</em>, <em>n_pair_input_feat=14</em>, <em>n_atom_output_feat=50</em>, <em>n_pair_output_feat=50</em>, <em>n_hidden_AA=50</em>, <em>n_hidden_PA=50</em>, <em>n_hidden_AP=50</em>, <em>n_hidden_PP=50</em>, <em>update_pair=True</em>, <em>init='glorot_uniform'</em>, <em>activation='relu'</em>, <em>dropout=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#AlternateWeaveLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.weave_layers.WeaveLayer" title="deepchem.nn.weave_layers.WeaveLayer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.weave_layers.WeaveLayer</span></code></a></p>
<p>Alternate implementation of weave module
same variables, different graph structures</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.weave_layers.AlternateWeaveLayer.add_loss" title="deepchem.nn.weave_layers.AlternateWeaveLayer.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.weave_layers.AlternateWeaveLayer.add_weight" title="deepchem.nn.weave_layers.AlternateWeaveLayer.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.weave_layers.AlternateWeaveLayer.build" title="deepchem.nn.weave_layers.AlternateWeaveLayer.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td>&#8220;Construct internal trainable weights.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.weave_layers.AlternateWeaveLayer.call" title="deepchem.nn.weave_layers.AlternateWeaveLayer.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x[,&nbsp;mask])</td>
<td>Execute this layer on input tensors.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveLayer.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveLayer.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveLayer.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveLayer.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveLayer.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveLayer.build" title="Permalink to this definition">¶</a></dt>
<dd><p>&#8220;Construct internal trainable weights.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.AlternateWeaveLayer.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#AlternateWeaveLayer.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.AlternateWeaveLayer.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>x = [atom_features, pair_features, pair_split, atom_split, atom_to_pair]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: list</strong></p>
<blockquote>
<div><p>list of Tensors of form described above.</p>
</div></blockquote>
<p><strong>mask: bool, optional</strong></p>
<blockquote>
<div><p>Ignored. Present only to shadow superclass call() method.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A: Tensor</p>
<blockquote>
<div><p>Tensor of atom_features</p>
</div></blockquote>
<p>P: Tensor</p>
<blockquote class="last">
<div><p>Tensor of pair_features</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.weave_layers.WeaveConcat">
<em class="property">class </em><code class="descclassname">deepchem.nn.weave_layers.</code><code class="descname">WeaveConcat</code><span class="sig-paren">(</span><em>batch_size</em>, <em>n_atom_input_feat=50</em>, <em>n_output=128</em>, <em>init='glorot_uniform'</em>, <em>activation='tanh'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveConcat"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveConcat" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>&#8221; Concat a batch of molecules into a batch of atoms</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.weave_layers.WeaveConcat.add_loss" title="deepchem.nn.weave_layers.WeaveConcat.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.weave_layers.WeaveConcat.add_weight" title="deepchem.nn.weave_layers.WeaveConcat.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.weave_layers.WeaveConcat.build" title="deepchem.nn.weave_layers.WeaveConcat.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td>&#8220;Construct internal trainable weights.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.weave_layers.WeaveConcat.call" title="deepchem.nn.weave_layers.WeaveConcat.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x[,&nbsp;mask])</td>
<td>Execute this layer on input tensors.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveConcat.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveConcat.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveConcat.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveConcat.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveConcat.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveConcat.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveConcat.build" title="Permalink to this definition">¶</a></dt>
<dd><p>&#8220;Construct internal trainable weights.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveConcat.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveConcat.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveConcat.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>x = [atom_features, atom_mask]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: list</strong></p>
<blockquote>
<div><p>Tensors as listed above</p>
</div></blockquote>
<p><strong>mask: bool, optional</strong></p>
<blockquote>
<div><p>Ignored. Present only to shadow superclass call() method.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">outputs: Tensor</p>
<blockquote class="last">
<div><p>Tensor of concatenated atom features</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.weave_layers.WeaveGather">
<em class="property">class </em><code class="descclassname">deepchem.nn.weave_layers.</code><code class="descname">WeaveGather</code><span class="sig-paren">(</span><em>batch_size</em>, <em>n_input=128</em>, <em>gaussian_expand=False</em>, <em>init='glorot_uniform'</em>, <em>activation='tanh'</em>, <em>epsilon=0.001</em>, <em>momentum=0.99</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveGather"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveGather" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>&#8221; Gather layer of Weave model
a batch of normalized atom features go through a hidden layer,
then summed to form molecular features</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.weave_layers.WeaveGather.add_loss" title="deepchem.nn.weave_layers.WeaveGather.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.weave_layers.WeaveGather.add_weight" title="deepchem.nn.weave_layers.WeaveGather.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.weave_layers.WeaveGather.build" title="deepchem.nn.weave_layers.WeaveGather.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.weave_layers.WeaveGather.call" title="deepchem.nn.weave_layers.WeaveGather.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x[,&nbsp;mask])</td>
<td>Execute this layer on input tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.weave_layers.WeaveGather.gaussian_histogram" title="deepchem.nn.weave_layers.WeaveGather.gaussian_histogram"><code class="xref py py-obj docutils literal"><span class="pre">gaussian_histogram</span></code></a>(x)</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveGather.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveGather.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveGather.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveGather.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveGather.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveGather.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveGather.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveGather.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveGather.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveGather.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>x = [atom_features, membership]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: list</strong></p>
<blockquote>
<div><p>Tensors as listed above</p>
</div></blockquote>
<p><strong>mask: bool, optional</strong></p>
<blockquote>
<div><p>Ignored. Present only to shadow superclass call() method.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">outputs: Tensor</p>
<blockquote class="last">
<div><p>Tensor of molecular features</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveGather.gaussian_histogram">
<code class="descname">gaussian_histogram</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveGather.gaussian_histogram"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveGather.gaussian_histogram" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.nn.weave_layers.WeaveLayer">
<em class="property">class </em><code class="descclassname">deepchem.nn.weave_layers.</code><code class="descname">WeaveLayer</code><span class="sig-paren">(</span><em>max_atoms</em>, <em>n_atom_input_feat=75</em>, <em>n_pair_input_feat=14</em>, <em>n_atom_output_feat=50</em>, <em>n_pair_output_feat=50</em>, <em>n_hidden_AA=50</em>, <em>n_hidden_PA=50</em>, <em>n_hidden_AP=50</em>, <em>n_hidden_PP=50</em>, <em>update_pair=True</em>, <em>init='glorot_uniform'</em>, <em>activation='relu'</em>, <em>dropout=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.nn.copy.Layer</span></code></a></p>
<p>&#8221; Main layer of Weave model
For each molecule, atom features and pair features are recombined to
generate new atom(pair) features</p>
<p>Detailed structure and explanations:
<a class="reference external" href="https://arxiv.org/abs/1603.00856">https://arxiv.org/abs/1603.00856</a></p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(x)</td>
<td>Wrapper around self.call(), for handling Parameters &#8212;&#8212;&#8212;- x: Can be a tensor or list/tuple of tensors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.weave_layers.WeaveLayer.add_loss" title="deepchem.nn.weave_layers.WeaveLayer.add_loss"><code class="xref py py-obj docutils literal"><span class="pre">add_loss</span></code></a>(losses[,&nbsp;inputs])</td>
<td>Adds losses to model.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.weave_layers.WeaveLayer.add_weight" title="deepchem.nn.weave_layers.WeaveLayer.add_weight"><code class="xref py py-obj docutils literal"><span class="pre">add_weight</span></code></a>(shape,&nbsp;initializer[,&nbsp;...])</td>
<td>Adds a weight variable to the layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.nn.weave_layers.WeaveLayer.build" title="deepchem.nn.weave_layers.WeaveLayer.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td>&#8220;Construct internal trainable weights.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.nn.weave_layers.WeaveLayer.call" title="deepchem.nn.weave_layers.WeaveLayer.call"><code class="xref py py-obj docutils literal"><span class="pre">call</span></code></a>(x[,&nbsp;mask])</td>
<td>Execute this layer on input tensors.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveLayer.add_loss">
<code class="descname">add_loss</code><span class="sig-paren">(</span><em>losses</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveLayer.add_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds losses to model.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveLayer.add_weight">
<code class="descname">add_weight</code><span class="sig-paren">(</span><em>shape</em>, <em>initializer</em>, <em>regularizer=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveLayer.add_weight" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a weight variable to the layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>shape: The shape tuple of the weight.</strong></p>
<p><strong>initializer: An Initializer instance (callable).</strong></p>
<p class="last"><strong>regularizer: An optional Regularizer instance.</strong></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveLayer.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveLayer.build"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveLayer.build" title="Permalink to this definition">¶</a></dt>
<dd><p>&#8220;Construct internal trainable weights.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.nn.weave_layers.WeaveLayer.call">
<code class="descname">call</code><span class="sig-paren">(</span><em>x</em>, <em>mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/nn/weave_layers.html#WeaveLayer.call"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.nn.weave_layers.WeaveLayer.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute this layer on input tensors.</p>
<p>x = [atom_features, pair_features, atom_mask, pair_mask]</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x: list</strong></p>
<blockquote>
<div><p>list of Tensors of form described above.</p>
</div></blockquote>
<p><strong>mask: bool, optional</strong></p>
<blockquote>
<div><p>Ignored. Present only to shadow superclass call() method.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A: Tensor</p>
<blockquote>
<div><p>Tensor of atom_features</p>
</div></blockquote>
<p>P: Tensor</p>
<blockquote class="last">
<div><p>Tensor of pair_features</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.nn">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-deepchem.nn" title="Permalink to this headline">¶</a></h2>
<p>Imports a number of useful deep learning primitives into one place.</p>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="_sources/deepchem.nn.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2016, Stanford University and the Authors.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>