<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>deepchem.models.tensorgraph.models package &mdash; deepchem 1.2 documentation</title>
    
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="deepchem 1.2 documentation" href="index.html" />
    <link rel="up" title="deepchem.models.tensorgraph package" href="deepchem.models.tensorgraph.html" />
    <link rel="next" title="deepchem.models.tf_new_models package" href="deepchem.models.tf_new_models.html" />
    <link rel="prev" title="deepchem.models.tensorgraph package" href="deepchem.models.tensorgraph.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-inverse navbar-default ">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html"><span><img src="_static/logo.png"></span>
          deepchem</a>
        <span class="navbar-text navbar-version pull-left"><b>1.2</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="notebooks/index.html">Notebooks</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="deepchem.html">deepchem package</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">deepchem.models.tensorgraph.models package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-deepchem.models.tensorgraph.models.atomic_conv">deepchem.models.tensorgraph.models.atomic_conv module</a></li>
<li><a class="reference internal" href="#module-deepchem.models.tensorgraph.models.gan">deepchem.models.tensorgraph.models.gan module</a></li>
<li><a class="reference internal" href="#module-deepchem.models.tensorgraph.models.graph_models">deepchem.models.tensorgraph.models.graph_models module</a></li>
<li><a class="reference internal" href="#module-deepchem.models.tensorgraph.models.robust_multitask">deepchem.models.tensorgraph.models.robust_multitask module</a></li>
<li><a class="reference internal" href="#module-deepchem.models.tensorgraph.models.seqtoseq">deepchem.models.tensorgraph.models.seqtoseq module</a></li>
<li><a class="reference internal" href="#module-deepchem.models.tensorgraph.models.symmetry_function_regression">deepchem.models.tensorgraph.models.symmetry_function_regression module</a></li>
<li><a class="reference internal" href="#module-deepchem.models.tensorgraph.models.test_graph_models">deepchem.models.tensorgraph.models.test_graph_models module</a></li>
<li><a class="reference internal" href="#module-deepchem.models.tensorgraph.models.test_symmetry_functions">deepchem.models.tensorgraph.models.test_symmetry_functions module</a></li>
<li><a class="reference internal" href="#module-deepchem.models.tensorgraph.models.text_cnn">deepchem.models.tensorgraph.models.text_cnn module</a></li>
<li><a class="reference internal" href="#module-deepchem.models.tensorgraph.models">Module contents</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="deepchem-models-tensorgraph-models-package">
<h1>deepchem.models.tensorgraph.models package<a class="headerlink" href="#deepchem-models-tensorgraph-models-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.atomic_conv">
<span id="deepchem-models-tensorgraph-models-atomic-conv-module"></span><h2>deepchem.models.tensorgraph.models.atomic_conv module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.atomic_conv" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.atomic_conv.</code><code class="descname">AtomicConvScore</code><span class="sig-paren">(</span><em>atom_types</em>, <em>layer_sizes</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/atomic_conv.html#AtomicConvScore"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.layers.Layer" title="deepchem.models.tensorgraph.layers.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.layers.Layer</span></code></a></p>
<p class="rubric">Attributes</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.shape" title="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.shape"><code class="xref py py-obj docutils literal"><span class="pre">shape</span></code></a></td>
<td>Get the shape of this Layer&#8217;s output.</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(*in_layers)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.add_summary_to_tg" title="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.add_summary_to_tg"><code class="xref py py-obj docutils literal"><span class="pre">add_summary_to_tg</span></code></a>()</td>
<td>Can only be called after self.create_layer to gaurentee that name is not none</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.clone" title="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.clone"><code class="xref py py-obj docutils literal"><span class="pre">clone</span></code></a>(in_layers)</td>
<td>Create a copy of this layer with different inputs.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.copy" title="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.copy"><code class="xref py py-obj docutils literal"><span class="pre">copy</span></code></a>([replacements,&nbsp;variables_graph,&nbsp;shared])</td>
<td>Duplicate this Layer and all its inputs.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.create_tensor" title="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.create_tensor"><code class="xref py py-obj docutils literal"><span class="pre">create_tensor</span></code></a>([in_layers,&nbsp;set_tensors])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.none_tensors" title="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.none_tensors"><code class="xref py py-obj docutils literal"><span class="pre">none_tensors</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_summary" title="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_summary"><code class="xref py py-obj docutils literal"><span class="pre">set_summary</span></code></a>(summary_op[,&nbsp;...])</td>
<td>Annotates a tensor with a tf.summary operation</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_tensors" title="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_tensors"><code class="xref py py-obj docutils literal"><span class="pre">set_tensors</span></code></a>(tensor)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_variable_initial_values" title="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_variable_initial_values"><code class="xref py py-obj docutils literal"><span class="pre">set_variable_initial_values</span></code></a>(values)</td>
<td>Set the initial values of all variables.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.shared" title="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.shared"><code class="xref py py-obj docutils literal"><span class="pre">shared</span></code></a>(in_layers)</td>
<td>Create a copy of this layer that shares variables with it.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.add_summary_to_tg">
<code class="descname">add_summary_to_tg</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.add_summary_to_tg" title="Permalink to this definition">¶</a></dt>
<dd><p>Can only be called after self.create_layer to gaurentee that name is not none</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.clone">
<code class="descname">clone</code><span class="sig-paren">(</span><em>in_layers</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.clone" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of this layer with different inputs.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.copy">
<code class="descname">copy</code><span class="sig-paren">(</span><em>replacements={}</em>, <em>variables_graph=None</em>, <em>shared=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Duplicate this Layer and all its inputs.</p>
<p>This is similar to clone(), but instead of only cloning one layer, it also
recursively calls copy() on all of this layer&#8217;s inputs to clone the entire
hierarchy of layers.  In the process, you can optionally tell it to replace
particular layers with specific existing ones.  For example, you can clone a
stack of layers, while connecting the topmost ones to different inputs.</p>
<p>For example, consider a stack of dense layers that depend on an input:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense3</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense2</span><span class="p">)</span>
</pre></div>
</div>
<p>The following will clone all three dense layers, but not the input layer.
Instead, the input to the first dense layer will be a different layer
specified in the replacements map.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">replacements</span> <span class="o">=</span> <span class="p">{</span><span class="nb">input</span><span class="p">:</span> <span class="n">new_input</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense3_copy</span> <span class="o">=</span> <span class="n">dense3</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">replacements</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>replacements: map</strong></p>
<blockquote>
<div><p>specifies existing layers, and the layers to replace them with (instead of
cloning them).  This argument serves two purposes.  First, you can pass in
a list of replacements to control which layers get cloned.  In addition,
as each layer is cloned, it is added to this map.  On exit, it therefore
contains a complete record of all layers that were copied, and a reference
to the copy of each one.</p>
</div></blockquote>
<p><strong>variables_graph: TensorGraph</strong></p>
<blockquote>
<div><p>an optional TensorGraph from which to take variables.  If this is specified,
the current value of each variable in each layer is recorded, and the copy
has that value specified as its initial value.  This allows a piece of a
pre-trained model to be copied to another model.</p>
</div></blockquote>
<p><strong>shared: bool</strong></p>
<blockquote class="last">
<div><p>if True, create new layers by calling shared() on the input layers.
This means the newly created layers will share variables with the original
ones.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.create_tensor">
<code class="descname">create_tensor</code><span class="sig-paren">(</span><em>in_layers=None</em>, <em>set_tensors=True</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/atomic_conv.html#AtomicConvScore.create_tensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.create_tensor" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.layer_number_dict">
<code class="descname">layer_number_dict</code><em class="property"> = {}</em><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.layer_number_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.none_tensors">
<code class="descname">none_tensors</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.none_tensors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_summary">
<code class="descname">set_summary</code><span class="sig-paren">(</span><em>summary_op</em>, <em>summary_description=None</em>, <em>collections=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Annotates a tensor with a tf.summary operation
Collects data from self.out_tensor by default but can be changed by setting
self.tb_input to another tensor in create_tensor</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>summary_op: str</strong></p>
<blockquote>
<div><p>summary operation to annotate node</p>
</div></blockquote>
<p><strong>summary_description: object, optional</strong></p>
<blockquote>
<div><p>Optional summary_pb2.SummaryDescription()</p>
</div></blockquote>
<p><strong>collections: list of graph collections keys, optional</strong></p>
<blockquote class="last">
<div><p>New summary op is added to these collections. Defaults to [GraphKeys.SUMMARIES]</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_tensors">
<code class="descname">set_tensors</code><span class="sig-paren">(</span><em>tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_tensors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_variable_initial_values">
<code class="descname">set_variable_initial_values</code><span class="sig-paren">(</span><em>values</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.set_variable_initial_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the initial values of all variables.</p>
<p>This takes a list, which contains the initial values to use for all of
this layer&#8217;s values (in the same order retured by
TensorGraph.get_layer_variables()).  When this layer is used in a
TensorGraph, it will automatically initialize each variable to the value
specified in the list.  Note that some layers also have separate mechanisms
for specifying variable initializers; this method overrides them. The
purpose of this method is to let a Layer object represent a pre-trained
layer, complete with trained values for its variables.</p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.shape">
<code class="descname">shape</code><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shape of this Layer&#8217;s output.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.shared">
<code class="descname">shared</code><span class="sig-paren">(</span><em>in_layers</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.AtomicConvScore.shared" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of this layer that shares variables with it.</p>
<p>This is similar to clone(), but where clone() creates two independent layers,
this causes the layers to share variables with each other.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>in_layers: list tensor</strong></p>
<p><strong>List in tensors for the shared layer</strong></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">Layer</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.InitializeWeightsBiases">
<code class="descclassname">deepchem.models.tensorgraph.models.atomic_conv.</code><code class="descname">InitializeWeightsBiases</code><span class="sig-paren">(</span><em>prev_layer_size</em>, <em>size</em>, <em>weights=None</em>, <em>biases=None</em>, <em>name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/atomic_conv.html#InitializeWeightsBiases"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.InitializeWeightsBiases" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes weights and biases to be used in a fully-connected layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>prev_layer_size: int</strong></p>
<blockquote>
<div><p>Number of features in previous layer.</p>
</div></blockquote>
<p><strong>size: int</strong></p>
<blockquote>
<div><p>Number of nodes in this layer.</p>
</div></blockquote>
<p><strong>weights: tf.Tensor, optional (Default None)</strong></p>
<blockquote>
<div><p>Weight tensor.</p>
</div></blockquote>
<p><strong>biases: tf.Tensor, optional (Default None)</strong></p>
<blockquote>
<div><p>Bias tensor.</p>
</div></blockquote>
<p><strong>name: str</strong></p>
<blockquote>
<div><p>Name for this op, optional (Defaults to &#8216;fully_connected&#8217; if None)</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">weights: tf.Variable</p>
<blockquote>
<div><p>Initialized weights.</p>
</div></blockquote>
<p>biases: tf.Variable</p>
<blockquote class="last">
<div><p>Initialized biases.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="deepchem.models.tensorgraph.models.atomic_conv.atomic_conv_model">
<code class="descclassname">deepchem.models.tensorgraph.models.atomic_conv.</code><code class="descname">atomic_conv_model</code><span class="sig-paren">(</span><em>frag1_num_atoms=70, frag2_num_atoms=634, complex_num_atoms=701, max_num_neighbors=12, batch_size=24, at=[6, 7.0, 8.0, 9.0, 11.0, 12.0, 15.0, 16.0, 17.0, 20.0, 25.0, 30.0, 35.0, 53.0, -1.0], radial=[[1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0, 10.5, 11.0, 11.5, 12.0], [0.0, 4.0, 8.0], [0.4]], layer_sizes=[32, 32, 16], learning_rate=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/atomic_conv.html#atomic_conv_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.atomic_conv.atomic_conv_model" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.gan">
<span id="deepchem-models-tensorgraph-models-gan-module"></span><h2>deepchem.models.tensorgraph.models.gan module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.gan" title="Permalink to this headline">¶</a></h2>
<p>Generative Adversarial Networks.</p>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.gan.GAN">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.gan.</code><code class="descname">GAN</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p>Implements Generative Adversarial Networks.</p>
<p>A Generative Adversarial Network (GAN) is a type of generative model.  It
consists of two parts called the &#8220;generator&#8221; and the &#8220;discriminator&#8221;.  The
generator takes random noise as input and transforms it into an output that
(hopefully) resembles the training data.  The discriminator takes a set of
samples as input and tries to distinguish the real training samples from the
ones created by the generator.  Both of them are trained together.  The
discriminator tries to get better and better at telling real from false data,
while the generator tries to get better and better at fooling the discriminator.</p>
<p>In many cases there also are additional inputs to the generator and
discriminator.  In that case it is known as a Conditional GAN (CGAN), since it
learns a distribution that is conditional on the values of those inputs.  They
are referred to as &#8220;conditional inputs&#8221;.</p>
<p>Many variations on this idea have been proposed, and new varieties of GANs are
constantly being proposed.  This class tries to make it very easy to implement
straightforward GANs of the most conventional types.  At the same time, it
tries to be flexible enough that it can be used to implement many (but
certainly not all) variations on the concept.</p>
<p>To define a GAN, you must create a subclass that provides implementations of
the following methods:</p>
<p>get_noise_input_shape()
get_data_input_shapes()
create_generator()
create_discriminator()</p>
<p>If you want your GAN to have any conditional inputs you must also implement:</p>
<p>get_conditional_input_shapes()</p>
<p>The following methods have default implementations that are suitable for most
conventional GANs.  You can override them if you want to customize their
behavior:</p>
<p>create_generator_loss()
create_discriminator_loss()
get_noise_batch()</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.add_output" title="deepchem.models.tensorgraph.models.gan.GAN.add_output"><code class="xref py py-obj docutils literal"><span class="pre">add_output</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.build" title="deepchem.models.tensorgraph.models.gan.GAN.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.create_discriminator" title="deepchem.models.tensorgraph.models.gan.GAN.create_discriminator"><code class="xref py py-obj docutils literal"><span class="pre">create_discriminator</span></code></a>(data_inputs,&nbsp;...)</td>
<td>Create the discriminator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.create_discriminator_loss" title="deepchem.models.tensorgraph.models.gan.GAN.create_discriminator_loss"><code class="xref py py-obj docutils literal"><span class="pre">create_discriminator_loss</span></code></a>(...)</td>
<td>Create the loss function for the discriminator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.create_generator" title="deepchem.models.tensorgraph.models.gan.GAN.create_generator"><code class="xref py py-obj docutils literal"><span class="pre">create_generator</span></code></a>(noise_input,&nbsp;conditional_inputs)</td>
<td>Create the generator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.create_generator_loss" title="deepchem.models.tensorgraph.models.gan.GAN.create_generator_loss"><code class="xref py py-obj docutils literal"><span class="pre">create_generator_loss</span></code></a>(discrim_output)</td>
<td>Create the loss function for the generator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.create_submodel" title="deepchem.models.tensorgraph.models.gan.GAN.create_submodel"><code class="xref py py-obj docutils literal"><span class="pre">create_submodel</span></code></a>([layers,&nbsp;loss,&nbsp;optimizer])</td>
<td>Create an alternate objective for training one piece of a TensorGraph.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.default_generator" title="deepchem.models.tensorgraph.models.gan.GAN.default_generator"><code class="xref py py-obj docutils literal"><span class="pre">default_generator</span></code></a>(dataset[,&nbsp;epochs,&nbsp;...])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.evaluate" title="deepchem.models.tensorgraph.models.gan.GAN.evaluate"><code class="xref py py-obj docutils literal"><span class="pre">evaluate</span></code></a>(dataset,&nbsp;metrics[,&nbsp;transformers,&nbsp;...])</td>
<td>Evaluates the performance of this model on specified dataset.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.evaluate_generator" title="deepchem.models.tensorgraph.models.gan.GAN.evaluate_generator"><code class="xref py py-obj docutils literal"><span class="pre">evaluate_generator</span></code></a>(feed_dict_generator,&nbsp;metrics)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.fit" title="deepchem.models.tensorgraph.models.gan.GAN.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(dataset[,&nbsp;nb_epoch,&nbsp;...])</td>
<td>Train this model on a dataset.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.fit_gan" title="deepchem.models.tensorgraph.models.gan.GAN.fit_gan"><code class="xref py py-obj docutils literal"><span class="pre">fit_gan</span></code></a>(batches[,&nbsp;generator_steps,&nbsp;...])</td>
<td>Train this model on data.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.fit_generator" title="deepchem.models.tensorgraph.models.gan.GAN.fit_generator"><code class="xref py py-obj docutils literal"><span class="pre">fit_generator</span></code></a>(feed_dict_generator[,&nbsp;...])</td>
<td>Train this model on data from a generator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.fit_on_batch" title="deepchem.models.tensorgraph.models.gan.GAN.fit_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">fit_on_batch</span></code></a>(X,&nbsp;y,&nbsp;w[,&nbsp;submodel])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.get_conditional_input_shapes" title="deepchem.models.tensorgraph.models.gan.GAN.get_conditional_input_shapes"><code class="xref py py-obj docutils literal"><span class="pre">get_conditional_input_shapes</span></code></a>()</td>
<td>Get the shapes of any conditional inputs.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.get_data_input_shapes" title="deepchem.models.tensorgraph.models.gan.GAN.get_data_input_shapes"><code class="xref py py-obj docutils literal"><span class="pre">get_data_input_shapes</span></code></a>()</td>
<td>Get the shapes of the inputs for training data.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.get_global_step" title="deepchem.models.tensorgraph.models.gan.GAN.get_global_step"><code class="xref py py-obj docutils literal"><span class="pre">get_global_step</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.get_layer_variables" title="deepchem.models.tensorgraph.models.gan.GAN.get_layer_variables"><code class="xref py py-obj docutils literal"><span class="pre">get_layer_variables</span></code></a>(layer)</td>
<td>Get the list of trainable variables in a layer of the graph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.get_model_filename" title="deepchem.models.tensorgraph.models.gan.GAN.get_model_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_model_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.get_noise_batch" title="deepchem.models.tensorgraph.models.gan.GAN.get_noise_batch"><code class="xref py py-obj docutils literal"><span class="pre">get_noise_batch</span></code></a>(batch_size)</td>
<td>Get a batch of random noise to pass to the generator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.get_noise_input_shape" title="deepchem.models.tensorgraph.models.gan.GAN.get_noise_input_shape"><code class="xref py py-obj docutils literal"><span class="pre">get_noise_input_shape</span></code></a>()</td>
<td>Get the shape of the generator&#8217;s noise input layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.get_num_tasks" title="deepchem.models.tensorgraph.models.gan.GAN.get_num_tasks"><code class="xref py py-obj docutils literal"><span class="pre">get_num_tasks</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.get_params" title="deepchem.models.tensorgraph.models.gan.GAN.get_params"><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.get_params_filename" title="deepchem.models.tensorgraph.models.gan.GAN.get_params_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_params_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.get_pickling_errors" title="deepchem.models.tensorgraph.models.gan.GAN.get_pickling_errors"><code class="xref py py-obj docutils literal"><span class="pre">get_pickling_errors</span></code></a>(obj[,&nbsp;seen])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.get_pre_q_input" title="deepchem.models.tensorgraph.models.gan.GAN.get_pre_q_input"><code class="xref py py-obj docutils literal"><span class="pre">get_pre_q_input</span></code></a>(input_layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.get_task_type" title="deepchem.models.tensorgraph.models.gan.GAN.get_task_type"><code class="xref py py-obj docutils literal"><span class="pre">get_task_type</span></code></a>()</td>
<td>Currently models can only be classifiers or regressors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.load_from_dir" title="deepchem.models.tensorgraph.models.gan.GAN.load_from_dir"><code class="xref py py-obj docutils literal"><span class="pre">load_from_dir</span></code></a>(model_dir)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.predict" title="deepchem.models.tensorgraph.models.gan.GAN.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Uses self to make predictions on provided Dataset object.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_gan_generator" title="deepchem.models.tensorgraph.models.gan.GAN.predict_gan_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_gan_generator</span></code></a>([batch_size,&nbsp;...])</td>
<td>Use the GAN to generate a batch of samples.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_on_batch" title="deepchem.models.tensorgraph.models.gan.GAN.predict_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_on_generator" title="deepchem.models.tensorgraph.models.gan.GAN.predict_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_proba" title="deepchem.models.tensorgraph.models.gan.GAN.predict_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_proba_on_batch" title="deepchem.models.tensorgraph.models.gan.GAN.predict_proba_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;...])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_proba_on_generator" title="deepchem.models.tensorgraph.models.gan.GAN.predict_proba_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td>Returns:</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.reload" title="deepchem.models.tensorgraph.models.gan.GAN.reload"><code class="xref py py-obj docutils literal"><span class="pre">reload</span></code></a>()</td>
<td>Reload trained model from disk.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.restore" title="deepchem.models.tensorgraph.models.gan.GAN.restore"><code class="xref py py-obj docutils literal"><span class="pre">restore</span></code></a>()</td>
<td>Reload the values of all variables from the most recent checkpoint file.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.save" title="deepchem.models.tensorgraph.models.gan.GAN.save"><code class="xref py py-obj docutils literal"><span class="pre">save</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.save_checkpoint" title="deepchem.models.tensorgraph.models.gan.GAN.save_checkpoint"><code class="xref py py-obj docutils literal"><span class="pre">save_checkpoint</span></code></a>([max_checkpoints_to_keep])</td>
<td>Save a checkpoint to disk.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.set_loss" title="deepchem.models.tensorgraph.models.gan.GAN.set_loss"><code class="xref py py-obj docutils literal"><span class="pre">set_loss</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.set_optimizer" title="deepchem.models.tensorgraph.models.gan.GAN.set_optimizer"><code class="xref py py-obj docutils literal"><span class="pre">set_optimizer</span></code></a>(optimizer)</td>
<td>Set the optimizer to use for fitting.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.set_params" title="deepchem.models.tensorgraph.models.gan.GAN.set_params"><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code></a>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN.topsort" title="deepchem.models.tensorgraph.models.gan.GAN.topsort"><code class="xref py py-obj docutils literal"><span class="pre">topsort</span></code></a>()</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.create_discriminator">
<code class="descname">create_discriminator</code><span class="sig-paren">(</span><em>data_inputs</em>, <em>conditional_inputs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.create_discriminator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.create_discriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the discriminator.</p>
<p>Subclasses must override this to construct the discriminator and return its
output layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>data_inputs: list</strong></p>
<blockquote>
<div><p>the Input layers from which the discriminator can read the input data.
The number and shapes of these inputs will match the return value from
get_data_input_shapes().  The samples read from these layers may be either
training data or generated data.</p>
</div></blockquote>
<p><strong>conditional_inputs: list</strong></p>
<blockquote>
<div><p>the Input layers for any conditional inputs to the network.  The number
and shapes of these inputs will match the return value from
get_conditional_input_shapes().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Layer object that outputs the probability of each sample being a training</p>
<p>sample.  The shape of this layer must be [None].  That is, it must output a</p>
<p class="last">one dimensional tensor whose length equals the batch size.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.create_discriminator_loss">
<code class="descname">create_discriminator_loss</code><span class="sig-paren">(</span><em>discrim_output_train</em>, <em>discrim_output_gen</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.create_discriminator_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.create_discriminator_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the loss function for the discriminator.</p>
<p>The default implementation is appropriate for most cases.  Subclasses can
override this if the need to customize it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>discrim_output_train: Layer</strong></p>
<blockquote>
<div><p>the output from the discriminator on a batch of generated data.  This is
its estimate of the probability that each sample is training data.</p>
</div></blockquote>
<p><strong>discrim_output_gen: Layer</strong></p>
<blockquote>
<div><p>the output from the discriminator on a batch of training data.  This is
its estimate of the probability that each sample is training data.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Layer object that outputs the loss function to use for optimizing the</p>
<p class="last">discriminator.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.create_generator">
<code class="descname">create_generator</code><span class="sig-paren">(</span><em>noise_input</em>, <em>conditional_inputs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.create_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.create_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the generator.</p>
<p>Subclasses must override this to construct the generator and return its
output layers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>noise_input: Input</strong></p>
<blockquote>
<div><p>the Input layer from which the generator can read random noise.  The shape
will match the return value from get_noise_input_shape().</p>
</div></blockquote>
<p><strong>conditional_inputs: list</strong></p>
<blockquote>
<div><p>the Input layers for any conditional inputs to the network.  The number
and shapes of these inputs will match the return value from
get_conditional_input_shapes().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A list of Layer objects that produce the generator&#8217;s outputs.  The number and</p>
<p>shapes of these layers must match the return value from get_data_input_shapes(),</p>
<p class="last">since generated data must have the same form as training data.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.create_generator_loss">
<code class="descname">create_generator_loss</code><span class="sig-paren">(</span><em>discrim_output</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.create_generator_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.create_generator_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the loss function for the generator.</p>
<p>The default implementation is appropriate for most cases.  Subclasses can
override this if the need to customize it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>discrim_output: Layer</strong></p>
<blockquote>
<div><p>the output from the discriminator on a batch of generated data.  This is
its estimate of the probability that each sample is training data.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Layer object that outputs the loss function to use for optimizing the</p>
<p class="last">generator.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>layers: list</strong></p>
<blockquote>
<div><p>the list of layers to train.  If None, all layers in the model will be
trained.</p>
</div></blockquote>
<p><strong>loss: Layer</strong></p>
<blockquote>
<div><p>the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</p>
</div></blockquote>
<p><strong>optimizer: Optimizer</strong></p>
<blockquote>
<div><p>the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the newly created submodel, which can be passed to any of the fitting</p>
<p class="last">methods.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset object.</p>
</div></blockquote>
<p><strong>metric: deepchem.metrics.Metric</strong></p>
<blockquote>
<div><p>Evaluation metric</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of deepchem.transformers.Transformer</p>
</div></blockquote>
<p><strong>per_task_metrics: bool</strong></p>
<blockquote>
<div><p>If True, return per-task scores.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">dict</p>
<blockquote class="last">
<div><p>Maps tasks to scores under metric.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: Dataset</strong></p>
<blockquote>
<div><p>the Dataset to train on</p>
</div></blockquote>
<p><strong>nb_epoch: int</strong></p>
<blockquote>
<div><p>the number of epochs to train for</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>deterministic: bool</strong></p>
<blockquote>
<div><p>if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote class="last">
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.fit_gan">
<code class="descname">fit_gan</code><span class="sig-paren">(</span><em>batches</em>, <em>generator_steps=1.0</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.fit_gan"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.fit_gan" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>batches: iterable</strong></p>
<blockquote>
<div><p>batches of data to train the discriminator on, each represented as a dict
that maps Layers to values.  It should specify values for all members of
data_inputs and conditional_inputs.</p>
</div></blockquote>
<p><strong>generator_steps: float</strong></p>
<blockquote>
<div><p>the number of training steps to perform for the generator for each batch.
This can be used to adjust the ratio of training steps for the generator
and discriminator.  For example, 2.0 will perform two training steps for
every batch, while 0.5 will only perform one training step for every two
batches.</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in batches.  Set
this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote class="last">
<div><p>if True, restore the model from the most recent checkpoint before training
it.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>feed_dict_generator: generator</strong></p>
<blockquote>
<div><p>this should generate batches, each represented as a dict that maps
Layers to values.</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote>
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_conditional_input_shapes">
<code class="descname">get_conditional_input_shapes</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.get_conditional_input_shapes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_conditional_input_shapes" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shapes of any conditional inputs.</p>
<p>Subclasses may override this to return a list of tuples, each giving the
shape of one of the conditional inputs.  The actual Input layers will be
created automatically.  The first dimension of each shape must be None,
since it will correspond to the batch size.</p>
<p>The default implementation returns an empty list, meaning there are no
conditional inputs.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_data_input_shapes">
<code class="descname">get_data_input_shapes</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.get_data_input_shapes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_data_input_shapes" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shapes of the inputs for training data.</p>
<p>Subclasses must override this to return a list of tuples, each giving the
shape of one of the inputs.  The actual Input layers will be created
automatically.  This list of shapes must also match the shapes of the
generator&#8217;s outputs.  The first dimension of each shape must be None, since
it will correspond to the batch size.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_noise_batch">
<code class="descname">get_noise_batch</code><span class="sig-paren">(</span><em>batch_size</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.get_noise_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_noise_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a batch of random noise to pass to the generator.</p>
<p>This should return a NumPy array whose shape matches the one returned by
get_noise_input_shape().  The default implementation returns normally
distributed values.  Subclasses can override this to implement a different
distribution.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_noise_input_shape">
<code class="descname">get_noise_input_shape</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.get_noise_input_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_noise_input_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shape of the generator&#8217;s noise input layer.</p>
<p>Subclasses must override this to return a tuple giving the shape of the
noise input.  The actual Input layer will be created automatically.  The
first dimension must be None, since it will correspond to the batch size.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">results: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.predict_gan_generator">
<code class="descname">predict_gan_generator</code><span class="sig-paren">(</span><em>batch_size=1</em>, <em>noise_input=None</em>, <em>conditional_inputs=[]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GAN.predict_gan_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_gan_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the GAN to generate a batch of samples.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>batch_size: int</strong></p>
<blockquote>
<div><p>the number of samples to generate.  If either noise_input or
conditional_inputs is specified, this argument is ignored since the batch
size is then determined by the size of that argument.</p>
</div></blockquote>
<p><strong>noise_input: array</strong></p>
<blockquote>
<div><p>the value to use for the generator&#8217;s noise input.  If None (the default),
get_noise_batch() is called to generate a random input, so each call will
produce a new set of samples.</p>
</div></blockquote>
<p><strong>conditional_inputs: list of arrays</strong></p>
<blockquote>
<div><p>the values to use for all conditional inputs.  This must be specified if
the GAN has any conditional inputs.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">An array (if the generator has only one output) or list of arrays (if it has</p>
<p class="last">multiple outputs) containing the generated samples.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>generator: Generator</strong></p>
<blockquote>
<div><p>Generator that constructs feed dictionaries for TensorGraph.</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
<p><strong>Returns:</strong></p>
<blockquote class="last">
<div><p>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">y_pred: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Returns:</dt>
<dd>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote class="last">
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GAN.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GAN.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.gan.</code><code class="descname">GradientPenaltyLayer</code><span class="sig-paren">(</span><em>discrim_output_train</em>, <em>gan</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GradientPenaltyLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.layers.Layer" title="deepchem.models.tensorgraph.layers.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.layers.Layer</span></code></a></p>
<p>Implements the gradient penalty loss term for WGANs.</p>
<p class="rubric">Attributes</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.shape" title="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.shape"><code class="xref py py-obj docutils literal"><span class="pre">shape</span></code></a></td>
<td>Get the shape of this Layer&#8217;s output.</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(*in_layers)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.add_summary_to_tg" title="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.add_summary_to_tg"><code class="xref py py-obj docutils literal"><span class="pre">add_summary_to_tg</span></code></a>()</td>
<td>Can only be called after self.create_layer to gaurentee that name is not none</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.clone" title="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.clone"><code class="xref py py-obj docutils literal"><span class="pre">clone</span></code></a>(in_layers)</td>
<td>Create a copy of this layer with different inputs.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.copy" title="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.copy"><code class="xref py py-obj docutils literal"><span class="pre">copy</span></code></a>([replacements,&nbsp;variables_graph,&nbsp;shared])</td>
<td>Duplicate this Layer and all its inputs.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.create_tensor" title="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.create_tensor"><code class="xref py py-obj docutils literal"><span class="pre">create_tensor</span></code></a>([in_layers,&nbsp;set_tensors])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.none_tensors" title="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.none_tensors"><code class="xref py py-obj docutils literal"><span class="pre">none_tensors</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_summary" title="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_summary"><code class="xref py py-obj docutils literal"><span class="pre">set_summary</span></code></a>(summary_op[,&nbsp;...])</td>
<td>Annotates a tensor with a tf.summary operation</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_tensors" title="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_tensors"><code class="xref py py-obj docutils literal"><span class="pre">set_tensors</span></code></a>(tensor)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_variable_initial_values" title="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_variable_initial_values"><code class="xref py py-obj docutils literal"><span class="pre">set_variable_initial_values</span></code></a>(values)</td>
<td>Set the initial values of all variables.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.shared" title="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.shared"><code class="xref py py-obj docutils literal"><span class="pre">shared</span></code></a>(in_layers)</td>
<td>Create a copy of this layer that shares variables with it.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.add_summary_to_tg">
<code class="descname">add_summary_to_tg</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.add_summary_to_tg" title="Permalink to this definition">¶</a></dt>
<dd><p>Can only be called after self.create_layer to gaurentee that name is not none</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.clone">
<code class="descname">clone</code><span class="sig-paren">(</span><em>in_layers</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.clone" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of this layer with different inputs.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.copy">
<code class="descname">copy</code><span class="sig-paren">(</span><em>replacements={}</em>, <em>variables_graph=None</em>, <em>shared=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Duplicate this Layer and all its inputs.</p>
<p>This is similar to clone(), but instead of only cloning one layer, it also
recursively calls copy() on all of this layer&#8217;s inputs to clone the entire
hierarchy of layers.  In the process, you can optionally tell it to replace
particular layers with specific existing ones.  For example, you can clone a
stack of layers, while connecting the topmost ones to different inputs.</p>
<p>For example, consider a stack of dense layers that depend on an input:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense3</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense2</span><span class="p">)</span>
</pre></div>
</div>
<p>The following will clone all three dense layers, but not the input layer.
Instead, the input to the first dense layer will be a different layer
specified in the replacements map.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">replacements</span> <span class="o">=</span> <span class="p">{</span><span class="nb">input</span><span class="p">:</span> <span class="n">new_input</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense3_copy</span> <span class="o">=</span> <span class="n">dense3</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">replacements</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>replacements: map</strong></p>
<blockquote>
<div><p>specifies existing layers, and the layers to replace them with (instead of
cloning them).  This argument serves two purposes.  First, you can pass in
a list of replacements to control which layers get cloned.  In addition,
as each layer is cloned, it is added to this map.  On exit, it therefore
contains a complete record of all layers that were copied, and a reference
to the copy of each one.</p>
</div></blockquote>
<p><strong>variables_graph: TensorGraph</strong></p>
<blockquote>
<div><p>an optional TensorGraph from which to take variables.  If this is specified,
the current value of each variable in each layer is recorded, and the copy
has that value specified as its initial value.  This allows a piece of a
pre-trained model to be copied to another model.</p>
</div></blockquote>
<p><strong>shared: bool</strong></p>
<blockquote class="last">
<div><p>if True, create new layers by calling shared() on the input layers.
This means the newly created layers will share variables with the original
ones.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.create_tensor">
<code class="descname">create_tensor</code><span class="sig-paren">(</span><em>in_layers=None</em>, <em>set_tensors=True</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#GradientPenaltyLayer.create_tensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.create_tensor" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.layer_number_dict">
<code class="descname">layer_number_dict</code><em class="property"> = {}</em><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.layer_number_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.none_tensors">
<code class="descname">none_tensors</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.none_tensors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_summary">
<code class="descname">set_summary</code><span class="sig-paren">(</span><em>summary_op</em>, <em>summary_description=None</em>, <em>collections=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Annotates a tensor with a tf.summary operation
Collects data from self.out_tensor by default but can be changed by setting
self.tb_input to another tensor in create_tensor</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>summary_op: str</strong></p>
<blockquote>
<div><p>summary operation to annotate node</p>
</div></blockquote>
<p><strong>summary_description: object, optional</strong></p>
<blockquote>
<div><p>Optional summary_pb2.SummaryDescription()</p>
</div></blockquote>
<p><strong>collections: list of graph collections keys, optional</strong></p>
<blockquote class="last">
<div><p>New summary op is added to these collections. Defaults to [GraphKeys.SUMMARIES]</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_tensors">
<code class="descname">set_tensors</code><span class="sig-paren">(</span><em>tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_tensors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_variable_initial_values">
<code class="descname">set_variable_initial_values</code><span class="sig-paren">(</span><em>values</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.set_variable_initial_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the initial values of all variables.</p>
<p>This takes a list, which contains the initial values to use for all of
this layer&#8217;s values (in the same order retured by
TensorGraph.get_layer_variables()).  When this layer is used in a
TensorGraph, it will automatically initialize each variable to the value
specified in the list.  Note that some layers also have separate mechanisms
for specifying variable initializers; this method overrides them. The
purpose of this method is to let a Layer object represent a pre-trained
layer, complete with trained values for its variables.</p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.shape">
<code class="descname">shape</code><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shape of this Layer&#8217;s output.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.shared">
<code class="descname">shared</code><span class="sig-paren">(</span><em>in_layers</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.GradientPenaltyLayer.shared" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of this layer that shares variables with it.</p>
<p>This is similar to clone(), but where clone() creates two independent layers,
this causes the layers to share variables with each other.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>in_layers: list tensor</strong></p>
<p><strong>List in tensors for the shared layer</strong></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">Layer</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.gan.</code><code class="descname">WGAN</code><span class="sig-paren">(</span><em>gradient_penalty=10.0</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#WGAN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.GAN" title="deepchem.models.tensorgraph.models.gan.GAN"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.models.gan.GAN</span></code></a></p>
<p>Implements Wasserstein Generative Adversarial Networks.</p>
<p>This class implements Wasserstein Generative Adversarial Networks (WGANs) as
described in Arjovsky et al., &#8220;Wasserstein GAN&#8221; (<a class="reference external" href="https://arxiv.org/abs/1701.07875">https://arxiv.org/abs/1701.07875</a>).
A WGAN is conceptually rather different from a conventional GAN, but in
practical terms very similar.  It reinterprets the discriminator (often called
the &#8220;critic&#8221; in this context) as learning an approximation to the Earth Mover
distance between the training and generated distributions.  The generator is
then trained to minimize that distance.  In practice, this just means using
slightly different loss functions for training the generator and discriminator.</p>
<p>WGANs have theoretical advantages over conventional GANs, and they often work
better in practice.  In addition, the discriminator&#8217;s loss function can be
directly interpreted as a measure of the quality of the model.  That is an
advantage over conventional GANs, where the loss does not directly convey
information about the quality of the model.</p>
<p>The theory WGANs are based on requires the discriminator&#8217;s gradient to be
bounded.  The original paper achieved this by clipping its weights.  This
class instead does it by adding a penalty term to the discriminator&#8217;s loss, as
described in <a class="reference external" href="https://arxiv.org/abs/1704.00028">https://arxiv.org/abs/1704.00028</a>.  This is sometimes found to
produce better results.</p>
<p>There are a few other practical differences between GANs and WGANs.  In a
conventional GAN, the discriminator&#8217;s output must be between 0 and 1 so it can
be interpreted as a probability.  In a WGAN, it should produce an unbounded
output that can be interpreted as a distance.</p>
<p>When training a WGAN, you also should usually use a smaller value for
generator_steps.  Conventional GANs rely on keeping the generator and
discriminator &#8220;in balance&#8221; with each other.  If the discriminator ever gets
too good, it becomes impossible for the generator to fool it and training
stalls.  WGANs do not have this problem, and in fact the better the
discriminator is, the easier it is for the generator to improve.  It therefore
usually works best to perform several training steps on the discriminator for
each training step on the generator.</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.add_output" title="deepchem.models.tensorgraph.models.gan.WGAN.add_output"><code class="xref py py-obj docutils literal"><span class="pre">add_output</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.build" title="deepchem.models.tensorgraph.models.gan.WGAN.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.create_discriminator" title="deepchem.models.tensorgraph.models.gan.WGAN.create_discriminator"><code class="xref py py-obj docutils literal"><span class="pre">create_discriminator</span></code></a>(data_inputs,&nbsp;...)</td>
<td>Create the discriminator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.create_discriminator_loss" title="deepchem.models.tensorgraph.models.gan.WGAN.create_discriminator_loss"><code class="xref py py-obj docutils literal"><span class="pre">create_discriminator_loss</span></code></a>(...)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.create_generator" title="deepchem.models.tensorgraph.models.gan.WGAN.create_generator"><code class="xref py py-obj docutils literal"><span class="pre">create_generator</span></code></a>(noise_input,&nbsp;conditional_inputs)</td>
<td>Create the generator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.create_generator_loss" title="deepchem.models.tensorgraph.models.gan.WGAN.create_generator_loss"><code class="xref py py-obj docutils literal"><span class="pre">create_generator_loss</span></code></a>(discrim_output)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.create_submodel" title="deepchem.models.tensorgraph.models.gan.WGAN.create_submodel"><code class="xref py py-obj docutils literal"><span class="pre">create_submodel</span></code></a>([layers,&nbsp;loss,&nbsp;optimizer])</td>
<td>Create an alternate objective for training one piece of a TensorGraph.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.default_generator" title="deepchem.models.tensorgraph.models.gan.WGAN.default_generator"><code class="xref py py-obj docutils literal"><span class="pre">default_generator</span></code></a>(dataset[,&nbsp;epochs,&nbsp;...])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.evaluate" title="deepchem.models.tensorgraph.models.gan.WGAN.evaluate"><code class="xref py py-obj docutils literal"><span class="pre">evaluate</span></code></a>(dataset,&nbsp;metrics[,&nbsp;transformers,&nbsp;...])</td>
<td>Evaluates the performance of this model on specified dataset.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.evaluate_generator" title="deepchem.models.tensorgraph.models.gan.WGAN.evaluate_generator"><code class="xref py py-obj docutils literal"><span class="pre">evaluate_generator</span></code></a>(feed_dict_generator,&nbsp;metrics)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.fit" title="deepchem.models.tensorgraph.models.gan.WGAN.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(dataset[,&nbsp;nb_epoch,&nbsp;...])</td>
<td>Train this model on a dataset.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.fit_gan" title="deepchem.models.tensorgraph.models.gan.WGAN.fit_gan"><code class="xref py py-obj docutils literal"><span class="pre">fit_gan</span></code></a>(batches[,&nbsp;generator_steps,&nbsp;...])</td>
<td>Train this model on data.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.fit_generator" title="deepchem.models.tensorgraph.models.gan.WGAN.fit_generator"><code class="xref py py-obj docutils literal"><span class="pre">fit_generator</span></code></a>(feed_dict_generator[,&nbsp;...])</td>
<td>Train this model on data from a generator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.fit_on_batch" title="deepchem.models.tensorgraph.models.gan.WGAN.fit_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">fit_on_batch</span></code></a>(X,&nbsp;y,&nbsp;w[,&nbsp;submodel])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_conditional_input_shapes" title="deepchem.models.tensorgraph.models.gan.WGAN.get_conditional_input_shapes"><code class="xref py py-obj docutils literal"><span class="pre">get_conditional_input_shapes</span></code></a>()</td>
<td>Get the shapes of any conditional inputs.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_data_input_shapes" title="deepchem.models.tensorgraph.models.gan.WGAN.get_data_input_shapes"><code class="xref py py-obj docutils literal"><span class="pre">get_data_input_shapes</span></code></a>()</td>
<td>Get the shapes of the inputs for training data.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_global_step" title="deepchem.models.tensorgraph.models.gan.WGAN.get_global_step"><code class="xref py py-obj docutils literal"><span class="pre">get_global_step</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_layer_variables" title="deepchem.models.tensorgraph.models.gan.WGAN.get_layer_variables"><code class="xref py py-obj docutils literal"><span class="pre">get_layer_variables</span></code></a>(layer)</td>
<td>Get the list of trainable variables in a layer of the graph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_model_filename" title="deepchem.models.tensorgraph.models.gan.WGAN.get_model_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_model_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_noise_batch" title="deepchem.models.tensorgraph.models.gan.WGAN.get_noise_batch"><code class="xref py py-obj docutils literal"><span class="pre">get_noise_batch</span></code></a>(batch_size)</td>
<td>Get a batch of random noise to pass to the generator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_noise_input_shape" title="deepchem.models.tensorgraph.models.gan.WGAN.get_noise_input_shape"><code class="xref py py-obj docutils literal"><span class="pre">get_noise_input_shape</span></code></a>()</td>
<td>Get the shape of the generator&#8217;s noise input layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_num_tasks" title="deepchem.models.tensorgraph.models.gan.WGAN.get_num_tasks"><code class="xref py py-obj docutils literal"><span class="pre">get_num_tasks</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_params" title="deepchem.models.tensorgraph.models.gan.WGAN.get_params"><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_params_filename" title="deepchem.models.tensorgraph.models.gan.WGAN.get_params_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_params_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_pickling_errors" title="deepchem.models.tensorgraph.models.gan.WGAN.get_pickling_errors"><code class="xref py py-obj docutils literal"><span class="pre">get_pickling_errors</span></code></a>(obj[,&nbsp;seen])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_pre_q_input" title="deepchem.models.tensorgraph.models.gan.WGAN.get_pre_q_input"><code class="xref py py-obj docutils literal"><span class="pre">get_pre_q_input</span></code></a>(input_layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_task_type" title="deepchem.models.tensorgraph.models.gan.WGAN.get_task_type"><code class="xref py py-obj docutils literal"><span class="pre">get_task_type</span></code></a>()</td>
<td>Currently models can only be classifiers or regressors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.load_from_dir" title="deepchem.models.tensorgraph.models.gan.WGAN.load_from_dir"><code class="xref py py-obj docutils literal"><span class="pre">load_from_dir</span></code></a>(model_dir)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict" title="deepchem.models.tensorgraph.models.gan.WGAN.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Uses self to make predictions on provided Dataset object.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_gan_generator" title="deepchem.models.tensorgraph.models.gan.WGAN.predict_gan_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_gan_generator</span></code></a>([batch_size,&nbsp;...])</td>
<td>Use the GAN to generate a batch of samples.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_on_batch" title="deepchem.models.tensorgraph.models.gan.WGAN.predict_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_on_generator" title="deepchem.models.tensorgraph.models.gan.WGAN.predict_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_proba" title="deepchem.models.tensorgraph.models.gan.WGAN.predict_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_proba_on_batch" title="deepchem.models.tensorgraph.models.gan.WGAN.predict_proba_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;...])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_proba_on_generator" title="deepchem.models.tensorgraph.models.gan.WGAN.predict_proba_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td>Returns:</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.reload" title="deepchem.models.tensorgraph.models.gan.WGAN.reload"><code class="xref py py-obj docutils literal"><span class="pre">reload</span></code></a>()</td>
<td>Reload trained model from disk.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.restore" title="deepchem.models.tensorgraph.models.gan.WGAN.restore"><code class="xref py py-obj docutils literal"><span class="pre">restore</span></code></a>()</td>
<td>Reload the values of all variables from the most recent checkpoint file.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.save" title="deepchem.models.tensorgraph.models.gan.WGAN.save"><code class="xref py py-obj docutils literal"><span class="pre">save</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.save_checkpoint" title="deepchem.models.tensorgraph.models.gan.WGAN.save_checkpoint"><code class="xref py py-obj docutils literal"><span class="pre">save_checkpoint</span></code></a>([max_checkpoints_to_keep])</td>
<td>Save a checkpoint to disk.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.set_loss" title="deepchem.models.tensorgraph.models.gan.WGAN.set_loss"><code class="xref py py-obj docutils literal"><span class="pre">set_loss</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.set_optimizer" title="deepchem.models.tensorgraph.models.gan.WGAN.set_optimizer"><code class="xref py py-obj docutils literal"><span class="pre">set_optimizer</span></code></a>(optimizer)</td>
<td>Set the optimizer to use for fitting.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.set_params" title="deepchem.models.tensorgraph.models.gan.WGAN.set_params"><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code></a>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.gan.WGAN.topsort" title="deepchem.models.tensorgraph.models.gan.WGAN.topsort"><code class="xref py py-obj docutils literal"><span class="pre">topsort</span></code></a>()</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.create_discriminator">
<code class="descname">create_discriminator</code><span class="sig-paren">(</span><em>data_inputs</em>, <em>conditional_inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.create_discriminator" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the discriminator.</p>
<p>Subclasses must override this to construct the discriminator and return its
output layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>data_inputs: list</strong></p>
<blockquote>
<div><p>the Input layers from which the discriminator can read the input data.
The number and shapes of these inputs will match the return value from
get_data_input_shapes().  The samples read from these layers may be either
training data or generated data.</p>
</div></blockquote>
<p><strong>conditional_inputs: list</strong></p>
<blockquote>
<div><p>the Input layers for any conditional inputs to the network.  The number
and shapes of these inputs will match the return value from
get_conditional_input_shapes().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Layer object that outputs the probability of each sample being a training</p>
<p>sample.  The shape of this layer must be [None].  That is, it must output a</p>
<p class="last">one dimensional tensor whose length equals the batch size.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.create_discriminator_loss">
<code class="descname">create_discriminator_loss</code><span class="sig-paren">(</span><em>discrim_output_train</em>, <em>discrim_output_gen</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#WGAN.create_discriminator_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.create_discriminator_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.create_generator">
<code class="descname">create_generator</code><span class="sig-paren">(</span><em>noise_input</em>, <em>conditional_inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.create_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the generator.</p>
<p>Subclasses must override this to construct the generator and return its
output layers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>noise_input: Input</strong></p>
<blockquote>
<div><p>the Input layer from which the generator can read random noise.  The shape
will match the return value from get_noise_input_shape().</p>
</div></blockquote>
<p><strong>conditional_inputs: list</strong></p>
<blockquote>
<div><p>the Input layers for any conditional inputs to the network.  The number
and shapes of these inputs will match the return value from
get_conditional_input_shapes().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A list of Layer objects that produce the generator&#8217;s outputs.  The number and</p>
<p>shapes of these layers must match the return value from get_data_input_shapes(),</p>
<p class="last">since generated data must have the same form as training data.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.create_generator_loss">
<code class="descname">create_generator_loss</code><span class="sig-paren">(</span><em>discrim_output</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/gan.html#WGAN.create_generator_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.create_generator_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>layers: list</strong></p>
<blockquote>
<div><p>the list of layers to train.  If None, all layers in the model will be
trained.</p>
</div></blockquote>
<p><strong>loss: Layer</strong></p>
<blockquote>
<div><p>the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</p>
</div></blockquote>
<p><strong>optimizer: Optimizer</strong></p>
<blockquote>
<div><p>the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the newly created submodel, which can be passed to any of the fitting</p>
<p class="last">methods.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset object.</p>
</div></blockquote>
<p><strong>metric: deepchem.metrics.Metric</strong></p>
<blockquote>
<div><p>Evaluation metric</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of deepchem.transformers.Transformer</p>
</div></blockquote>
<p><strong>per_task_metrics: bool</strong></p>
<blockquote>
<div><p>If True, return per-task scores.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">dict</p>
<blockquote class="last">
<div><p>Maps tasks to scores under metric.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: Dataset</strong></p>
<blockquote>
<div><p>the Dataset to train on</p>
</div></blockquote>
<p><strong>nb_epoch: int</strong></p>
<blockquote>
<div><p>the number of epochs to train for</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>deterministic: bool</strong></p>
<blockquote>
<div><p>if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote class="last">
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.fit_gan">
<code class="descname">fit_gan</code><span class="sig-paren">(</span><em>batches</em>, <em>generator_steps=1.0</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.fit_gan" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>batches: iterable</strong></p>
<blockquote>
<div><p>batches of data to train the discriminator on, each represented as a dict
that maps Layers to values.  It should specify values for all members of
data_inputs and conditional_inputs.</p>
</div></blockquote>
<p><strong>generator_steps: float</strong></p>
<blockquote>
<div><p>the number of training steps to perform for the generator for each batch.
This can be used to adjust the ratio of training steps for the generator
and discriminator.  For example, 2.0 will perform two training steps for
every batch, while 0.5 will only perform one training step for every two
batches.</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in batches.  Set
this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote class="last">
<div><p>if True, restore the model from the most recent checkpoint before training
it.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>feed_dict_generator: generator</strong></p>
<blockquote>
<div><p>this should generate batches, each represented as a dict that maps
Layers to values.</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote>
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_conditional_input_shapes">
<code class="descname">get_conditional_input_shapes</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_conditional_input_shapes" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shapes of any conditional inputs.</p>
<p>Subclasses may override this to return a list of tuples, each giving the
shape of one of the conditional inputs.  The actual Input layers will be
created automatically.  The first dimension of each shape must be None,
since it will correspond to the batch size.</p>
<p>The default implementation returns an empty list, meaning there are no
conditional inputs.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_data_input_shapes">
<code class="descname">get_data_input_shapes</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_data_input_shapes" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shapes of the inputs for training data.</p>
<p>Subclasses must override this to return a list of tuples, each giving the
shape of one of the inputs.  The actual Input layers will be created
automatically.  This list of shapes must also match the shapes of the
generator&#8217;s outputs.  The first dimension of each shape must be None, since
it will correspond to the batch size.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_noise_batch">
<code class="descname">get_noise_batch</code><span class="sig-paren">(</span><em>batch_size</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_noise_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a batch of random noise to pass to the generator.</p>
<p>This should return a NumPy array whose shape matches the one returned by
get_noise_input_shape().  The default implementation returns normally
distributed values.  Subclasses can override this to implement a different
distribution.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_noise_input_shape">
<code class="descname">get_noise_input_shape</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_noise_input_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shape of the generator&#8217;s noise input layer.</p>
<p>Subclasses must override this to return a tuple giving the shape of the
noise input.  The actual Input layer will be created automatically.  The
first dimension must be None, since it will correspond to the batch size.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">results: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.predict_gan_generator">
<code class="descname">predict_gan_generator</code><span class="sig-paren">(</span><em>batch_size=1</em>, <em>noise_input=None</em>, <em>conditional_inputs=[]</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_gan_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the GAN to generate a batch of samples.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>batch_size: int</strong></p>
<blockquote>
<div><p>the number of samples to generate.  If either noise_input or
conditional_inputs is specified, this argument is ignored since the batch
size is then determined by the size of that argument.</p>
</div></blockquote>
<p><strong>noise_input: array</strong></p>
<blockquote>
<div><p>the value to use for the generator&#8217;s noise input.  If None (the default),
get_noise_batch() is called to generate a random input, so each call will
produce a new set of samples.</p>
</div></blockquote>
<p><strong>conditional_inputs: list of arrays</strong></p>
<blockquote>
<div><p>the values to use for all conditional inputs.  This must be specified if
the GAN has any conditional inputs.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">An array (if the generator has only one output) or list of arrays (if it has</p>
<p class="last">multiple outputs) containing the generated samples.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>generator: Generator</strong></p>
<blockquote>
<div><p>Generator that constructs feed dictionaries for TensorGraph.</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
<p><strong>Returns:</strong></p>
<blockquote class="last">
<div><p>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">y_pred: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Returns:</dt>
<dd>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote class="last">
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.gan.WGAN.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.gan.WGAN.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.graph_models">
<span id="deepchem-models-tensorgraph-models-graph-models-module"></span><h2>deepchem.models.tensorgraph.models.graph_models module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.graph_models" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.graph_models.</code><code class="descname">DAGTensorGraph</code><span class="sig-paren">(</span><em>n_tasks</em>, <em>max_atoms=50</em>, <em>n_atom_feat=75</em>, <em>n_graph_feat=30</em>, <em>n_outputs=30</em>, <em>mode='classification'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#DAGTensorGraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.add_output" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.add_output"><code class="xref py py-obj docutils literal"><span class="pre">add_output</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.build" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.build_graph" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.build_graph"><code class="xref py py-obj docutils literal"><span class="pre">build_graph</span></code></a>()</td>
<td>Building graph structures:</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.create_submodel" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.create_submodel"><code class="xref py py-obj docutils literal"><span class="pre">create_submodel</span></code></a>([layers,&nbsp;loss,&nbsp;optimizer])</td>
<td>Create an alternate objective for training one piece of a TensorGraph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.default_generator" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.default_generator"><code class="xref py py-obj docutils literal"><span class="pre">default_generator</span></code></a>(dataset[,&nbsp;epochs,&nbsp;...])</td>
<td>TensorGraph style implementation</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.evaluate" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.evaluate"><code class="xref py py-obj docutils literal"><span class="pre">evaluate</span></code></a>(dataset,&nbsp;metrics[,&nbsp;transformers,&nbsp;...])</td>
<td>Evaluates the performance of this model on specified dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.evaluate_generator" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.evaluate_generator"><code class="xref py py-obj docutils literal"><span class="pre">evaluate_generator</span></code></a>(feed_dict_generator,&nbsp;metrics)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(dataset[,&nbsp;nb_epoch,&nbsp;...])</td>
<td>Train this model on a dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit_generator" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit_generator"><code class="xref py py-obj docutils literal"><span class="pre">fit_generator</span></code></a>(feed_dict_generator[,&nbsp;...])</td>
<td>Train this model on data from a generator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit_on_batch" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">fit_on_batch</span></code></a>(X,&nbsp;y,&nbsp;w[,&nbsp;submodel])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_global_step" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_global_step"><code class="xref py py-obj docutils literal"><span class="pre">get_global_step</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_layer_variables" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_layer_variables"><code class="xref py py-obj docutils literal"><span class="pre">get_layer_variables</span></code></a>(layer)</td>
<td>Get the list of trainable variables in a layer of the graph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_model_filename" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_model_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_model_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_num_tasks" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_num_tasks"><code class="xref py py-obj docutils literal"><span class="pre">get_num_tasks</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_params" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_params"><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_params_filename" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_params_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_params_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_pickling_errors" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_pickling_errors"><code class="xref py py-obj docutils literal"><span class="pre">get_pickling_errors</span></code></a>(obj[,&nbsp;seen])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_pre_q_input" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_pre_q_input"><code class="xref py py-obj docutils literal"><span class="pre">get_pre_q_input</span></code></a>(input_layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_task_type" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_task_type"><code class="xref py py-obj docutils literal"><span class="pre">get_task_type</span></code></a>()</td>
<td>Currently models can only be classifiers or regressors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.load_from_dir" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.load_from_dir"><code class="xref py py-obj docutils literal"><span class="pre">load_from_dir</span></code></a>(model_dir)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Uses self to make predictions on provided Dataset object.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_on_batch" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_on_generator" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba_on_batch" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;...])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba_on_generator" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td>Returns:</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.reload" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.reload"><code class="xref py py-obj docutils literal"><span class="pre">reload</span></code></a>()</td>
<td>Reload trained model from disk.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.restore" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.restore"><code class="xref py py-obj docutils literal"><span class="pre">restore</span></code></a>()</td>
<td>Reload the values of all variables from the most recent checkpoint file.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.save" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.save"><code class="xref py py-obj docutils literal"><span class="pre">save</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.save_checkpoint" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.save_checkpoint"><code class="xref py py-obj docutils literal"><span class="pre">save_checkpoint</span></code></a>([max_checkpoints_to_keep])</td>
<td>Save a checkpoint to disk.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_loss" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_loss"><code class="xref py py-obj docutils literal"><span class="pre">set_loss</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_optimizer" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_optimizer"><code class="xref py py-obj docutils literal"><span class="pre">set_optimizer</span></code></a>(optimizer)</td>
<td>Set the optimizer to use for fitting.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_params" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_params"><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code></a>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.topsort" title="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.topsort"><code class="xref py py-obj docutils literal"><span class="pre">topsort</span></code></a>()</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#DAGTensorGraph.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Building graph structures:
Features =&gt; DAGLayer =&gt; DAGGather =&gt; Classification or Regression</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>layers: list</strong></p>
<blockquote>
<div><p>the list of layers to train.  If None, all layers in the model will be
trained.</p>
</div></blockquote>
<p><strong>loss: Layer</strong></p>
<blockquote>
<div><p>the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</p>
</div></blockquote>
<p><strong>optimizer: Optimizer</strong></p>
<blockquote>
<div><p>the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the newly created submodel, which can be passed to any of the fitting</p>
<p class="last">methods.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#DAGTensorGraph.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.default_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>TensorGraph style implementation
similar to deepchem.models.tf_new_models.graph_topology.DAGGraphTopology.batch_to_feed_dict</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset object.</p>
</div></blockquote>
<p><strong>metric: deepchem.metrics.Metric</strong></p>
<blockquote>
<div><p>Evaluation metric</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of deepchem.transformers.Transformer</p>
</div></blockquote>
<p><strong>per_task_metrics: bool</strong></p>
<blockquote>
<div><p>If True, return per-task scores.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">dict</p>
<blockquote class="last">
<div><p>Maps tasks to scores under metric.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: Dataset</strong></p>
<blockquote>
<div><p>the Dataset to train on</p>
</div></blockquote>
<p><strong>nb_epoch: int</strong></p>
<blockquote>
<div><p>the number of epochs to train for</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>deterministic: bool</strong></p>
<blockquote>
<div><p>if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote class="last">
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>feed_dict_generator: generator</strong></p>
<blockquote>
<div><p>this should generate batches, each represented as a dict that maps
Layers to values.</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote>
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">results: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>generator: Generator</strong></p>
<blockquote>
<div><p>Generator that constructs feed dictionaries for TensorGraph.</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
<p><strong>Returns:</strong></p>
<blockquote class="last">
<div><p>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">y_pred: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Returns:</dt>
<dd>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote class="last">
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DAGTensorGraph.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.graph_models.</code><code class="descname">DTNNTensorGraph</code><span class="sig-paren">(</span><em>n_tasks</em>, <em>n_embedding=30</em>, <em>n_hidden=100</em>, <em>n_distance=100</em>, <em>distance_min=-1</em>, <em>distance_max=18</em>, <em>output_activation=True</em>, <em>mode='classification'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#DTNNTensorGraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.add_output" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.add_output"><code class="xref py py-obj docutils literal"><span class="pre">add_output</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.build" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.build_graph" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.build_graph"><code class="xref py py-obj docutils literal"><span class="pre">build_graph</span></code></a>()</td>
<td>Building graph structures:</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.create_submodel" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.create_submodel"><code class="xref py py-obj docutils literal"><span class="pre">create_submodel</span></code></a>([layers,&nbsp;loss,&nbsp;optimizer])</td>
<td>Create an alternate objective for training one piece of a TensorGraph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.default_generator" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.default_generator"><code class="xref py py-obj docutils literal"><span class="pre">default_generator</span></code></a>(dataset[,&nbsp;epochs,&nbsp;...])</td>
<td>TensorGraph style implementation</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.evaluate" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.evaluate"><code class="xref py py-obj docutils literal"><span class="pre">evaluate</span></code></a>(dataset,&nbsp;metrics[,&nbsp;transformers,&nbsp;...])</td>
<td>Evaluates the performance of this model on specified dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.evaluate_generator" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.evaluate_generator"><code class="xref py py-obj docutils literal"><span class="pre">evaluate_generator</span></code></a>(feed_dict_generator,&nbsp;metrics)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(dataset[,&nbsp;nb_epoch,&nbsp;...])</td>
<td>Train this model on a dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit_generator" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit_generator"><code class="xref py py-obj docutils literal"><span class="pre">fit_generator</span></code></a>(feed_dict_generator[,&nbsp;...])</td>
<td>Train this model on data from a generator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit_on_batch" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">fit_on_batch</span></code></a>(X,&nbsp;y,&nbsp;w[,&nbsp;submodel])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_global_step" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_global_step"><code class="xref py py-obj docutils literal"><span class="pre">get_global_step</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_layer_variables" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_layer_variables"><code class="xref py py-obj docutils literal"><span class="pre">get_layer_variables</span></code></a>(layer)</td>
<td>Get the list of trainable variables in a layer of the graph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_model_filename" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_model_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_model_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_num_tasks" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_num_tasks"><code class="xref py py-obj docutils literal"><span class="pre">get_num_tasks</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_params" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_params"><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_params_filename" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_params_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_params_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_pickling_errors" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_pickling_errors"><code class="xref py py-obj docutils literal"><span class="pre">get_pickling_errors</span></code></a>(obj[,&nbsp;seen])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_pre_q_input" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_pre_q_input"><code class="xref py py-obj docutils literal"><span class="pre">get_pre_q_input</span></code></a>(input_layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_task_type" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_task_type"><code class="xref py py-obj docutils literal"><span class="pre">get_task_type</span></code></a>()</td>
<td>Currently models can only be classifiers or regressors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.load_from_dir" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.load_from_dir"><code class="xref py py-obj docutils literal"><span class="pre">load_from_dir</span></code></a>(model_dir)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Uses self to make predictions on provided Dataset object.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_on_batch" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_on_generator" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba_on_batch" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;...])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba_on_generator" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td>Returns:</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.reload" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.reload"><code class="xref py py-obj docutils literal"><span class="pre">reload</span></code></a>()</td>
<td>Reload trained model from disk.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.restore" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.restore"><code class="xref py py-obj docutils literal"><span class="pre">restore</span></code></a>()</td>
<td>Reload the values of all variables from the most recent checkpoint file.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.save" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.save"><code class="xref py py-obj docutils literal"><span class="pre">save</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.save_checkpoint" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.save_checkpoint"><code class="xref py py-obj docutils literal"><span class="pre">save_checkpoint</span></code></a>([max_checkpoints_to_keep])</td>
<td>Save a checkpoint to disk.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_loss" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_loss"><code class="xref py py-obj docutils literal"><span class="pre">set_loss</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_optimizer" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_optimizer"><code class="xref py py-obj docutils literal"><span class="pre">set_optimizer</span></code></a>(optimizer)</td>
<td>Set the optimizer to use for fitting.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_params" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_params"><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code></a>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.topsort" title="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.topsort"><code class="xref py py-obj docutils literal"><span class="pre">topsort</span></code></a>()</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#DTNNTensorGraph.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Building graph structures:
Features =&gt; DTNNEmbedding =&gt; DTNNStep =&gt; DTNNStep =&gt; DTNNGather =&gt; Regression</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>layers: list</strong></p>
<blockquote>
<div><p>the list of layers to train.  If None, all layers in the model will be
trained.</p>
</div></blockquote>
<p><strong>loss: Layer</strong></p>
<blockquote>
<div><p>the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</p>
</div></blockquote>
<p><strong>optimizer: Optimizer</strong></p>
<blockquote>
<div><p>the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the newly created submodel, which can be passed to any of the fitting</p>
<p class="last">methods.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#DTNNTensorGraph.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.default_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>TensorGraph style implementation
similar to deepchem.models.tf_new_models.graph_topology.DTNNGraphTopology.batch_to_feed_dict</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset object.</p>
</div></blockquote>
<p><strong>metric: deepchem.metrics.Metric</strong></p>
<blockquote>
<div><p>Evaluation metric</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of deepchem.transformers.Transformer</p>
</div></blockquote>
<p><strong>per_task_metrics: bool</strong></p>
<blockquote>
<div><p>If True, return per-task scores.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">dict</p>
<blockquote class="last">
<div><p>Maps tasks to scores under metric.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: Dataset</strong></p>
<blockquote>
<div><p>the Dataset to train on</p>
</div></blockquote>
<p><strong>nb_epoch: int</strong></p>
<blockquote>
<div><p>the number of epochs to train for</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>deterministic: bool</strong></p>
<blockquote>
<div><p>if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote class="last">
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>feed_dict_generator: generator</strong></p>
<blockquote>
<div><p>this should generate batches, each represented as a dict that maps
Layers to values.</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote>
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">results: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>generator: Generator</strong></p>
<blockquote>
<div><p>Generator that constructs feed dictionaries for TensorGraph.</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
<p><strong>Returns:</strong></p>
<blockquote class="last">
<div><p>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">y_pred: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Returns:</dt>
<dd>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote class="last">
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.DTNNTensorGraph.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.graph_models.</code><code class="descname">GraphConvTensorGraph</code><span class="sig-paren">(</span><em>n_tasks</em>, <em>mode='classification'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.add_output" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.add_output"><code class="xref py py-obj docutils literal"><span class="pre">add_output</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.bayesian_predict" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.bayesian_predict"><code class="xref py py-obj docutils literal"><span class="pre">bayesian_predict</span></code></a>(dataset[,&nbsp;transformers,&nbsp;...])</td>
<td>Generates predictions and confidences on a dataset object</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.bayesian_predict_on_batch" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.bayesian_predict_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">bayesian_predict_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;...])</td>
<td>Returns:</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.build" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.build_graph" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.build_graph"><code class="xref py py-obj docutils literal"><span class="pre">build_graph</span></code></a>()</td>
<td>Building graph structures:</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.create_submodel" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.create_submodel"><code class="xref py py-obj docutils literal"><span class="pre">create_submodel</span></code></a>([layers,&nbsp;loss,&nbsp;optimizer])</td>
<td>Create an alternate objective for training one piece of a TensorGraph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.default_generator" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.default_generator"><code class="xref py py-obj docutils literal"><span class="pre">default_generator</span></code></a>(dataset[,&nbsp;epochs,&nbsp;...])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.evaluate" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.evaluate"><code class="xref py py-obj docutils literal"><span class="pre">evaluate</span></code></a>(dataset,&nbsp;metrics[,&nbsp;transformers,&nbsp;...])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.evaluate_generator" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.evaluate_generator"><code class="xref py py-obj docutils literal"><span class="pre">evaluate_generator</span></code></a>(feed_dict_generator,&nbsp;metrics)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(dataset[,&nbsp;nb_epoch,&nbsp;...])</td>
<td>Train this model on a dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit_generator" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit_generator"><code class="xref py py-obj docutils literal"><span class="pre">fit_generator</span></code></a>(feed_dict_generator[,&nbsp;...])</td>
<td>Train this model on data from a generator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit_on_batch" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">fit_on_batch</span></code></a>(X,&nbsp;y,&nbsp;w[,&nbsp;submodel])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_global_step" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_global_step"><code class="xref py py-obj docutils literal"><span class="pre">get_global_step</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_layer_variables" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_layer_variables"><code class="xref py py-obj docutils literal"><span class="pre">get_layer_variables</span></code></a>(layer)</td>
<td>Get the list of trainable variables in a layer of the graph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_model_filename" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_model_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_model_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_num_tasks" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_num_tasks"><code class="xref py py-obj docutils literal"><span class="pre">get_num_tasks</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_params" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_params"><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_params_filename" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_params_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_params_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_pickling_errors" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_pickling_errors"><code class="xref py py-obj docutils literal"><span class="pre">get_pickling_errors</span></code></a>(obj[,&nbsp;seen])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_pre_q_input" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_pre_q_input"><code class="xref py py-obj docutils literal"><span class="pre">get_pre_q_input</span></code></a>(input_layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_task_type" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_task_type"><code class="xref py py-obj docutils literal"><span class="pre">get_task_type</span></code></a>()</td>
<td>Currently models can only be classifiers or regressors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.load_from_dir" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.load_from_dir"><code class="xref py py-obj docutils literal"><span class="pre">load_from_dir</span></code></a>(model_dir)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Uses self to make predictions on provided Dataset object.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_batch" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_generator" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_smiles" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_smiles"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_smiles</span></code></a>(smiles[,&nbsp;transformers,&nbsp;...])</td>
<td>Generates predictions on a numpy array of smile strings</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba_on_batch" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;...])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba_on_generator" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.reload" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.reload"><code class="xref py py-obj docutils literal"><span class="pre">reload</span></code></a>()</td>
<td>Reload trained model from disk.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.restore" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.restore"><code class="xref py py-obj docutils literal"><span class="pre">restore</span></code></a>()</td>
<td>Reload the values of all variables from the most recent checkpoint file.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.save" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.save"><code class="xref py py-obj docutils literal"><span class="pre">save</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.save_checkpoint" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.save_checkpoint"><code class="xref py py-obj docutils literal"><span class="pre">save_checkpoint</span></code></a>([max_checkpoints_to_keep])</td>
<td>Save a checkpoint to disk.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_loss" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_loss"><code class="xref py py-obj docutils literal"><span class="pre">set_loss</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_optimizer" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_optimizer"><code class="xref py py-obj docutils literal"><span class="pre">set_optimizer</span></code></a>(optimizer)</td>
<td>Set the optimizer to use for fitting.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_params" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_params"><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code></a>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.topsort" title="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.topsort"><code class="xref py py-obj docutils literal"><span class="pre">topsort</span></code></a>()</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.bayesian_predict">
<code class="descname">bayesian_predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>n_passes=4</em>, <em>untransform=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.bayesian_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.bayesian_predict" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Generates predictions and confidences on a dataset object</dt>
<dd><a class="reference external" href="https://arxiv.org/pdf/1506.02142.pdf">https://arxiv.org/pdf/1506.02142.pdf</a></dd>
<dt># Returns:</dt>
<dd>mu: numpy ndarray of shape (n_samples, n_tasks)
sigma: numpy ndarray of shape (n_samples, n_tasks)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.bayesian_predict_on_batch">
<code class="descname">bayesian_predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>n_passes=4</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.bayesian_predict_on_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.bayesian_predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Returns:</dt>
<dd>mu: numpy ndarray of shape (n_samples, n_tasks)
sigma: numpy ndarray of shape (n_samples, n_tasks)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Building graph structures:</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>layers: list</strong></p>
<blockquote>
<div><p>the list of layers to train.  If None, all layers in the model will be
trained.</p>
</div></blockquote>
<p><strong>loss: Layer</strong></p>
<blockquote>
<div><p>the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</p>
</div></blockquote>
<p><strong>optimizer: Optimizer</strong></p>
<blockquote>
<div><p>the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the newly created submodel, which can be passed to any of the fitting</p>
<p class="last">methods.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.evaluate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: Dataset</strong></p>
<blockquote>
<div><p>the Dataset to train on</p>
</div></blockquote>
<p><strong>nb_epoch: int</strong></p>
<blockquote>
<div><p>the number of epochs to train for</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>deterministic: bool</strong></p>
<blockquote>
<div><p>if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote class="last">
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>feed_dict_generator: generator</strong></p>
<blockquote>
<div><p>this should generate batches, each represented as a dict that maps
Layers to values.</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote>
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">results: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.predict_on_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_smiles">
<code class="descname">predict_on_smiles</code><span class="sig-paren">(</span><em>smiles</em>, <em>transformers=[]</em>, <em>untransform=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.predict_on_smiles"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_on_smiles" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions on a numpy array of smile strings</p>
<dl class="docutils">
<dt># Returns:</dt>
<dd><a href="#id1"><span class="problematic" id="id2">y_</span></a>: numpy ndarray of shape (n_samples, n_tasks)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">y_pred: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#GraphConvTensorGraph.predict_proba_on_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote class="last">
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.GraphConvTensorGraph.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.graph_models.</code><code class="descname">MPNNTensorGraph</code><span class="sig-paren">(</span><em>n_tasks</em>, <em>n_atom_feat=70</em>, <em>n_pair_feat=8</em>, <em>n_hidden=100</em>, <em>T=5</em>, <em>M=10</em>, <em>mode='regression'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#MPNNTensorGraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p>Message Passing Neural Network,
default structures built according to <a class="reference external" href="https://arxiv.org/abs/1511.06391">https://arxiv.org/abs/1511.06391</a></p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.add_output" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.add_output"><code class="xref py py-obj docutils literal"><span class="pre">add_output</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.build" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.build_graph" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.build_graph"><code class="xref py py-obj docutils literal"><span class="pre">build_graph</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.create_submodel" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.create_submodel"><code class="xref py py-obj docutils literal"><span class="pre">create_submodel</span></code></a>([layers,&nbsp;loss,&nbsp;optimizer])</td>
<td>Create an alternate objective for training one piece of a TensorGraph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.default_generator" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.default_generator"><code class="xref py py-obj docutils literal"><span class="pre">default_generator</span></code></a>(dataset[,&nbsp;epochs,&nbsp;...])</td>
<td>Same generator as Weave models</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.evaluate" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.evaluate"><code class="xref py py-obj docutils literal"><span class="pre">evaluate</span></code></a>(dataset,&nbsp;metrics[,&nbsp;transformers,&nbsp;...])</td>
<td>Evaluates the performance of this model on specified dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.evaluate_generator" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.evaluate_generator"><code class="xref py py-obj docutils literal"><span class="pre">evaluate_generator</span></code></a>(feed_dict_generator,&nbsp;metrics)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(dataset[,&nbsp;nb_epoch,&nbsp;...])</td>
<td>Train this model on a dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit_generator" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit_generator"><code class="xref py py-obj docutils literal"><span class="pre">fit_generator</span></code></a>(feed_dict_generator[,&nbsp;...])</td>
<td>Train this model on data from a generator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit_on_batch" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">fit_on_batch</span></code></a>(X,&nbsp;y,&nbsp;w[,&nbsp;submodel])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_global_step" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_global_step"><code class="xref py py-obj docutils literal"><span class="pre">get_global_step</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_layer_variables" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_layer_variables"><code class="xref py py-obj docutils literal"><span class="pre">get_layer_variables</span></code></a>(layer)</td>
<td>Get the list of trainable variables in a layer of the graph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_model_filename" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_model_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_model_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_num_tasks" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_num_tasks"><code class="xref py py-obj docutils literal"><span class="pre">get_num_tasks</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_params" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_params"><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_params_filename" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_params_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_params_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_pickling_errors" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_pickling_errors"><code class="xref py py-obj docutils literal"><span class="pre">get_pickling_errors</span></code></a>(obj[,&nbsp;seen])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_pre_q_input" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_pre_q_input"><code class="xref py py-obj docutils literal"><span class="pre">get_pre_q_input</span></code></a>(input_layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_task_type" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_task_type"><code class="xref py py-obj docutils literal"><span class="pre">get_task_type</span></code></a>()</td>
<td>Currently models can only be classifiers or regressors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.load_from_dir" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.load_from_dir"><code class="xref py py-obj docutils literal"><span class="pre">load_from_dir</span></code></a>(model_dir)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>(dataset[,&nbsp;transformers,&nbsp;batch_size])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_on_batch" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_on_generator" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_generator</span></code></a>(generator[,&nbsp;transformers])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></code></a>(dataset[,&nbsp;transformers,&nbsp;...])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba_on_batch" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;...])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba_on_generator" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td>Returns:</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.reload" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.reload"><code class="xref py py-obj docutils literal"><span class="pre">reload</span></code></a>()</td>
<td>Reload trained model from disk.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.restore" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.restore"><code class="xref py py-obj docutils literal"><span class="pre">restore</span></code></a>()</td>
<td>Reload the values of all variables from the most recent checkpoint file.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.save" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.save"><code class="xref py py-obj docutils literal"><span class="pre">save</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.save_checkpoint" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.save_checkpoint"><code class="xref py py-obj docutils literal"><span class="pre">save_checkpoint</span></code></a>([max_checkpoints_to_keep])</td>
<td>Save a checkpoint to disk.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_loss" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_loss"><code class="xref py py-obj docutils literal"><span class="pre">set_loss</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_optimizer" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_optimizer"><code class="xref py py-obj docutils literal"><span class="pre">set_optimizer</span></code></a>(optimizer)</td>
<td>Set the optimizer to use for fitting.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_params" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_params"><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code></a>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.topsort" title="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.topsort"><code class="xref py py-obj docutils literal"><span class="pre">topsort</span></code></a>()</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#MPNNTensorGraph.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.build_graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>layers: list</strong></p>
<blockquote>
<div><p>the list of layers to train.  If None, all layers in the model will be
trained.</p>
</div></blockquote>
<p><strong>loss: Layer</strong></p>
<blockquote>
<div><p>the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</p>
</div></blockquote>
<p><strong>optimizer: Optimizer</strong></p>
<blockquote>
<div><p>the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the newly created submodel, which can be passed to any of the fitting</p>
<p class="last">methods.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#MPNNTensorGraph.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.default_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Same generator as Weave models</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset object.</p>
</div></blockquote>
<p><strong>metric: deepchem.metrics.Metric</strong></p>
<blockquote>
<div><p>Evaluation metric</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of deepchem.transformers.Transformer</p>
</div></blockquote>
<p><strong>per_task_metrics: bool</strong></p>
<blockquote>
<div><p>If True, return per-task scores.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">dict</p>
<blockquote class="last">
<div><p>Maps tasks to scores under metric.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: Dataset</strong></p>
<blockquote>
<div><p>the Dataset to train on</p>
</div></blockquote>
<p><strong>nb_epoch: int</strong></p>
<blockquote>
<div><p>the number of epochs to train for</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>deterministic: bool</strong></p>
<blockquote>
<div><p>if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote class="last">
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>feed_dict_generator: generator</strong></p>
<blockquote>
<div><p>this should generate batches, each represented as a dict that maps
Layers to values.</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote>
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>batch_size=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#MPNNTensorGraph.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#MPNNTensorGraph.predict_on_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>batch_size=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#MPNNTensorGraph.predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#MPNNTensorGraph.predict_proba_on_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Returns:</dt>
<dd>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote class="last">
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.MPNNTensorGraph.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.graph_models.</code><code class="descname">PetroskiSuchTensorGraph</code><span class="sig-paren">(</span><em>n_tasks</em>, <em>max_atoms=200</em>, <em>dropout=0.0</em>, <em>mode='classification'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#PetroskiSuchTensorGraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p>Model from Robust Spatial Filtering with Graph Convolutional Neural Networks
<a class="reference external" href="https://arxiv.org/abs/1703.00792">https://arxiv.org/abs/1703.00792</a></p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.add_output" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.add_output"><code class="xref py py-obj docutils literal"><span class="pre">add_output</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.build" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.build_graph" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.build_graph"><code class="xref py py-obj docutils literal"><span class="pre">build_graph</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.create_submodel" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.create_submodel"><code class="xref py py-obj docutils literal"><span class="pre">create_submodel</span></code></a>([layers,&nbsp;loss,&nbsp;optimizer])</td>
<td>Create an alternate objective for training one piece of a TensorGraph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.default_generator" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.default_generator"><code class="xref py py-obj docutils literal"><span class="pre">default_generator</span></code></a>(dataset[,&nbsp;epochs,&nbsp;...])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.evaluate" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.evaluate"><code class="xref py py-obj docutils literal"><span class="pre">evaluate</span></code></a>(dataset,&nbsp;metrics[,&nbsp;transformers,&nbsp;...])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.evaluate_generator" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.evaluate_generator"><code class="xref py py-obj docutils literal"><span class="pre">evaluate_generator</span></code></a>(feed_dict_generator,&nbsp;metrics)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(dataset[,&nbsp;nb_epoch,&nbsp;...])</td>
<td>Train this model on a dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit_generator" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit_generator"><code class="xref py py-obj docutils literal"><span class="pre">fit_generator</span></code></a>(feed_dict_generator[,&nbsp;...])</td>
<td>Train this model on data from a generator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit_on_batch" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">fit_on_batch</span></code></a>(X,&nbsp;y,&nbsp;w[,&nbsp;submodel])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_global_step" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_global_step"><code class="xref py py-obj docutils literal"><span class="pre">get_global_step</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_layer_variables" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_layer_variables"><code class="xref py py-obj docutils literal"><span class="pre">get_layer_variables</span></code></a>(layer)</td>
<td>Get the list of trainable variables in a layer of the graph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_model_filename" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_model_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_model_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_num_tasks" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_num_tasks"><code class="xref py py-obj docutils literal"><span class="pre">get_num_tasks</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_params" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_params"><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_params_filename" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_params_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_params_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_pickling_errors" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_pickling_errors"><code class="xref py py-obj docutils literal"><span class="pre">get_pickling_errors</span></code></a>(obj[,&nbsp;seen])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_pre_q_input" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_pre_q_input"><code class="xref py py-obj docutils literal"><span class="pre">get_pre_q_input</span></code></a>(input_layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_task_type" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_task_type"><code class="xref py py-obj docutils literal"><span class="pre">get_task_type</span></code></a>()</td>
<td>Currently models can only be classifiers or regressors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.load_from_dir" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.load_from_dir"><code class="xref py py-obj docutils literal"><span class="pre">load_from_dir</span></code></a>(model_dir)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Uses self to make predictions on provided Dataset object.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_on_batch" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_on_generator" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba_on_batch" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;...])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba_on_generator" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.reload" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.reload"><code class="xref py py-obj docutils literal"><span class="pre">reload</span></code></a>()</td>
<td>Reload trained model from disk.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.restore" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.restore"><code class="xref py py-obj docutils literal"><span class="pre">restore</span></code></a>()</td>
<td>Reload the values of all variables from the most recent checkpoint file.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.save" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.save"><code class="xref py py-obj docutils literal"><span class="pre">save</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.save_checkpoint" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.save_checkpoint"><code class="xref py py-obj docutils literal"><span class="pre">save_checkpoint</span></code></a>([max_checkpoints_to_keep])</td>
<td>Save a checkpoint to disk.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_loss" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_loss"><code class="xref py py-obj docutils literal"><span class="pre">set_loss</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_optimizer" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_optimizer"><code class="xref py py-obj docutils literal"><span class="pre">set_optimizer</span></code></a>(optimizer)</td>
<td>Set the optimizer to use for fitting.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_params" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_params"><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code></a>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.topsort" title="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.topsort"><code class="xref py py-obj docutils literal"><span class="pre">topsort</span></code></a>()</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#PetroskiSuchTensorGraph.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.build_graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>layers: list</strong></p>
<blockquote>
<div><p>the list of layers to train.  If None, all layers in the model will be
trained.</p>
</div></blockquote>
<p><strong>loss: Layer</strong></p>
<blockquote>
<div><p>the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</p>
</div></blockquote>
<p><strong>optimizer: Optimizer</strong></p>
<blockquote>
<div><p>the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the newly created submodel, which can be passed to any of the fitting</p>
<p class="last">methods.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#PetroskiSuchTensorGraph.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#PetroskiSuchTensorGraph.evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.evaluate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: Dataset</strong></p>
<blockquote>
<div><p>the Dataset to train on</p>
</div></blockquote>
<p><strong>nb_epoch: int</strong></p>
<blockquote>
<div><p>the number of epochs to train for</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>deterministic: bool</strong></p>
<blockquote>
<div><p>if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote class="last">
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>feed_dict_generator: generator</strong></p>
<blockquote>
<div><p>this should generate batches, each represented as a dict that maps
Layers to values.</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote>
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">results: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>generator: Generator</strong></p>
<blockquote>
<div><p>Generator that constructs feed dictionaries for TensorGraph.</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
<p><strong>Returns:</strong></p>
<blockquote class="last">
<div><p>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">y_pred: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#PetroskiSuchTensorGraph.predict_proba_on_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote class="last">
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.PetroskiSuchTensorGraph.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.graph_models.</code><code class="descname">WeaveTensorGraph</code><span class="sig-paren">(</span><em>n_tasks</em>, <em>n_atom_feat=75</em>, <em>n_pair_feat=14</em>, <em>n_hidden=50</em>, <em>n_graph_feat=128</em>, <em>mode='classification'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#WeaveTensorGraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.add_output" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.add_output"><code class="xref py py-obj docutils literal"><span class="pre">add_output</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.build" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.build_graph" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.build_graph"><code class="xref py py-obj docutils literal"><span class="pre">build_graph</span></code></a>()</td>
<td>Building graph structures:</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.create_submodel" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.create_submodel"><code class="xref py py-obj docutils literal"><span class="pre">create_submodel</span></code></a>([layers,&nbsp;loss,&nbsp;optimizer])</td>
<td>Create an alternate objective for training one piece of a TensorGraph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.default_generator" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.default_generator"><code class="xref py py-obj docutils literal"><span class="pre">default_generator</span></code></a>(dataset[,&nbsp;epochs,&nbsp;...])</td>
<td>TensorGraph style implementation</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.evaluate" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.evaluate"><code class="xref py py-obj docutils literal"><span class="pre">evaluate</span></code></a>(dataset,&nbsp;metrics[,&nbsp;transformers,&nbsp;...])</td>
<td>Evaluates the performance of this model on specified dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.evaluate_generator" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.evaluate_generator"><code class="xref py py-obj docutils literal"><span class="pre">evaluate_generator</span></code></a>(feed_dict_generator,&nbsp;metrics)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(dataset[,&nbsp;nb_epoch,&nbsp;...])</td>
<td>Train this model on a dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit_generator" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit_generator"><code class="xref py py-obj docutils literal"><span class="pre">fit_generator</span></code></a>(feed_dict_generator[,&nbsp;...])</td>
<td>Train this model on data from a generator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit_on_batch" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">fit_on_batch</span></code></a>(X,&nbsp;y,&nbsp;w[,&nbsp;submodel])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_global_step" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_global_step"><code class="xref py py-obj docutils literal"><span class="pre">get_global_step</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_layer_variables" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_layer_variables"><code class="xref py py-obj docutils literal"><span class="pre">get_layer_variables</span></code></a>(layer)</td>
<td>Get the list of trainable variables in a layer of the graph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_model_filename" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_model_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_model_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_num_tasks" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_num_tasks"><code class="xref py py-obj docutils literal"><span class="pre">get_num_tasks</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_params" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_params"><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_params_filename" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_params_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_params_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_pickling_errors" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_pickling_errors"><code class="xref py py-obj docutils literal"><span class="pre">get_pickling_errors</span></code></a>(obj[,&nbsp;seen])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_pre_q_input" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_pre_q_input"><code class="xref py py-obj docutils literal"><span class="pre">get_pre_q_input</span></code></a>(input_layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_task_type" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_task_type"><code class="xref py py-obj docutils literal"><span class="pre">get_task_type</span></code></a>()</td>
<td>Currently models can only be classifiers or regressors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.load_from_dir" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.load_from_dir"><code class="xref py py-obj docutils literal"><span class="pre">load_from_dir</span></code></a>(model_dir)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Uses self to make predictions on provided Dataset object.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_on_batch" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_on_generator" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba_on_batch" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;...])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba_on_generator" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td>Returns:</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.reload" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.reload"><code class="xref py py-obj docutils literal"><span class="pre">reload</span></code></a>()</td>
<td>Reload trained model from disk.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.restore" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.restore"><code class="xref py py-obj docutils literal"><span class="pre">restore</span></code></a>()</td>
<td>Reload the values of all variables from the most recent checkpoint file.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.save" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.save"><code class="xref py py-obj docutils literal"><span class="pre">save</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.save_checkpoint" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.save_checkpoint"><code class="xref py py-obj docutils literal"><span class="pre">save_checkpoint</span></code></a>([max_checkpoints_to_keep])</td>
<td>Save a checkpoint to disk.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_loss" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_loss"><code class="xref py py-obj docutils literal"><span class="pre">set_loss</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_optimizer" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_optimizer"><code class="xref py py-obj docutils literal"><span class="pre">set_optimizer</span></code></a>(optimizer)</td>
<td>Set the optimizer to use for fitting.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_params" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_params"><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code></a>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.topsort" title="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.topsort"><code class="xref py py-obj docutils literal"><span class="pre">topsort</span></code></a>()</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#WeaveTensorGraph.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.build_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Building graph structures:
Features =&gt; WeaveLayer =&gt; WeaveLayer =&gt; Dense =&gt; WeaveGather =&gt; Classification or Regression</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>layers: list</strong></p>
<blockquote>
<div><p>the list of layers to train.  If None, all layers in the model will be
trained.</p>
</div></blockquote>
<p><strong>loss: Layer</strong></p>
<blockquote>
<div><p>the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</p>
</div></blockquote>
<p><strong>optimizer: Optimizer</strong></p>
<blockquote>
<div><p>the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the newly created submodel, which can be passed to any of the fitting</p>
<p class="last">methods.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/graph_models.html#WeaveTensorGraph.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.default_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>TensorGraph style implementation
similar to deepchem.models.tf_new_models.graph_topology.AlternateWeaveTopology.batch_to_feed_dict</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset object.</p>
</div></blockquote>
<p><strong>metric: deepchem.metrics.Metric</strong></p>
<blockquote>
<div><p>Evaluation metric</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of deepchem.transformers.Transformer</p>
</div></blockquote>
<p><strong>per_task_metrics: bool</strong></p>
<blockquote>
<div><p>If True, return per-task scores.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">dict</p>
<blockquote class="last">
<div><p>Maps tasks to scores under metric.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: Dataset</strong></p>
<blockquote>
<div><p>the Dataset to train on</p>
</div></blockquote>
<p><strong>nb_epoch: int</strong></p>
<blockquote>
<div><p>the number of epochs to train for</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>deterministic: bool</strong></p>
<blockquote>
<div><p>if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote class="last">
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>feed_dict_generator: generator</strong></p>
<blockquote>
<div><p>this should generate batches, each represented as a dict that maps
Layers to values.</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote>
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">results: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>generator: Generator</strong></p>
<blockquote>
<div><p>Generator that constructs feed dictionaries for TensorGraph.</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
<p><strong>Returns:</strong></p>
<blockquote class="last">
<div><p>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">y_pred: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Returns:</dt>
<dd>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote class="last">
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.graph_models.WeaveTensorGraph.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.robust_multitask">
<span id="deepchem-models-tensorgraph-models-robust-multitask-module"></span><h2>deepchem.models.tensorgraph.models.robust_multitask module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.robust_multitask" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.seqtoseq">
<span id="deepchem-models-tensorgraph-models-seqtoseq-module"></span><h2>deepchem.models.tensorgraph.models.seqtoseq module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.seqtoseq" title="Permalink to this headline">¶</a></h2>
<p>Sequence to sequence translation models.</p>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.seqtoseq.</code><code class="descname">SeqToSeq</code><span class="sig-paren">(</span><em>input_tokens</em>, <em>output_tokens</em>, <em>max_output_length</em>, <em>encoder_layers=4</em>, <em>decoder_layers=4</em>, <em>embedding_dimension=512</em>, <em>dropout=0.0</em>, <em>reverse_input=True</em>, <em>variational=False</em>, <em>annealing_start_step=5000</em>, <em>annealing_final_step=10000</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/seqtoseq.html#SeqToSeq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p>Implements sequence to sequence translation models.</p>
<p>The model is based on the description in Sutskever et al., &#8220;Sequence to
Sequence Learning with Neural Networks&#8221; (<a class="reference external" href="https://arxiv.org/abs/1409.3215">https://arxiv.org/abs/1409.3215</a>),
although this implementation uses GRUs instead of LSTMs.  The goal is to
take sequences of tokens as input, and translate each one into a different
output sequence.  The input and output sequences can both be of variable
length, and an output sequence need not have the same length as the input
sequence it was generated from.  For example, these models were originally
developed for use in natural language processing.  In that context, the
input might be a sequence of English words, and the output might be a
sequence of French words.  The goal would be to train the model to translate
sentences from English to French.</p>
<p>The model consists of two parts called the &#8220;encoder&#8221; and &#8220;decoder&#8221;.  Each one
consists of a stack of recurrent layers.  The job of the encoder is to
transform the input sequence into a single, fixed length vector called the
&#8220;embedding&#8221;.  That vector contains all relevant information from the input
sequence.  The decoder then transforms the embedding vector into the output
sequence.</p>
<p>These models can be used for various purposes.  First and most obviously,
they can be used for sequence to sequence translation.  In any case where you
have sequences of tokens, and you want to translate each one into a different
sequence, a SeqToSeq model can be trained to perform the translation.</p>
<p>Another possible use case is transforming variable length sequences into
fixed length vectors.  Many types of models require their inputs to have a
fixed shape, which makes it difficult to use them with variable sized inputs
(for example, when the input is a molecule, and different molecules have
different numbers of atoms).  In that case, you can train a SeqToSeq model as
an autoencoder, so that it tries to make the output sequence identical to the
input one.  That forces the embedding vector to contain all information from
the original sequence.  You can then use the encoder for transforming
sequences into fixed length embedding vectors, suitable to use as inputs to
other types of models.</p>
<p>Another use case is to train the decoder for use as a generative model.  Here
again you begin by training the SeqToSeq model as an autoencoder.  Once
training is complete, you can supply arbitrary embedding vectors, and
transform each one into an output sequence.  When used in this way, you
typically train it as a variational autoencoder.  This adds random noise to
the encoder, and also adds a constraint term to the loss that forces the
embedding vector to have a unit Gaussian distribution.  You can then pick
random vectors from a Gaussian distribution, and the output sequences should
follow the same distribution as the training data.</p>
<p>When training as a variational autoencoder, it is best to use KL cost
annealing, as described in <a class="reference external" href="https://arxiv.org/abs/1511.06349">https://arxiv.org/abs/1511.06349</a>.  The constraint
term in the loss is initially set to 0, so the optimizer just tries to
minimize the reconstruction loss.  Once it has made reasonable progress
toward that, the constraint term can be gradually turned back on.  The range
of steps over which this happens is configurable.</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.add_output" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.add_output"><code class="xref py py-obj docutils literal"><span class="pre">add_output</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.build" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.create_submodel" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.create_submodel"><code class="xref py py-obj docutils literal"><span class="pre">create_submodel</span></code></a>([layers,&nbsp;loss,&nbsp;optimizer])</td>
<td>Create an alternate objective for training one piece of a TensorGraph.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.default_generator" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.default_generator"><code class="xref py py-obj docutils literal"><span class="pre">default_generator</span></code></a>(dataset[,&nbsp;epochs,&nbsp;...])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.evaluate" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.evaluate"><code class="xref py py-obj docutils literal"><span class="pre">evaluate</span></code></a>(dataset,&nbsp;metrics[,&nbsp;transformers,&nbsp;...])</td>
<td>Evaluates the performance of this model on specified dataset.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.evaluate_generator" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.evaluate_generator"><code class="xref py py-obj docutils literal"><span class="pre">evaluate_generator</span></code></a>(feed_dict_generator,&nbsp;metrics)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(dataset[,&nbsp;nb_epoch,&nbsp;...])</td>
<td>Train this model on a dataset.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_generator" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_generator"><code class="xref py py-obj docutils literal"><span class="pre">fit_generator</span></code></a>(feed_dict_generator[,&nbsp;...])</td>
<td>Train this model on data from a generator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_on_batch" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">fit_on_batch</span></code></a>(X,&nbsp;y,&nbsp;w[,&nbsp;submodel])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_sequences" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_sequences"><code class="xref py py-obj docutils literal"><span class="pre">fit_sequences</span></code></a>(sequences[,&nbsp;...])</td>
<td>Train this model on a set of sequences</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_global_step" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_global_step"><code class="xref py py-obj docutils literal"><span class="pre">get_global_step</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_layer_variables" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_layer_variables"><code class="xref py py-obj docutils literal"><span class="pre">get_layer_variables</span></code></a>(layer)</td>
<td>Get the list of trainable variables in a layer of the graph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_model_filename" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_model_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_model_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_num_tasks" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_num_tasks"><code class="xref py py-obj docutils literal"><span class="pre">get_num_tasks</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_params" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_params"><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_params_filename" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_params_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_params_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_pickling_errors" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_pickling_errors"><code class="xref py py-obj docutils literal"><span class="pre">get_pickling_errors</span></code></a>(obj[,&nbsp;seen])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_pre_q_input" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_pre_q_input"><code class="xref py py-obj docutils literal"><span class="pre">get_pre_q_input</span></code></a>(input_layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_task_type" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_task_type"><code class="xref py py-obj docutils literal"><span class="pre">get_task_type</span></code></a>()</td>
<td>Currently models can only be classifiers or regressors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.load_from_dir" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.load_from_dir"><code class="xref py py-obj docutils literal"><span class="pre">load_from_dir</span></code></a>(model_dir)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Uses self to make predictions on provided Dataset object.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_embeddings" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_embeddings"><code class="xref py py-obj docutils literal"><span class="pre">predict_embeddings</span></code></a>(sequences)</td>
<td>Given a set of input sequences, compute the embedding vectors.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_from_embeddings" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_from_embeddings"><code class="xref py py-obj docutils literal"><span class="pre">predict_from_embeddings</span></code></a>(embeddings[,&nbsp;beam_width])</td>
<td>Given a set of embedding vectors, predict the output sequences.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_from_sequences" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_from_sequences"><code class="xref py py-obj docutils literal"><span class="pre">predict_from_sequences</span></code></a>(sequences[,&nbsp;beam_width])</td>
<td>Given a set of input sequences, predict the output sequences.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_on_batch" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_on_generator" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba_on_batch" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;...])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba_on_generator" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td>Returns:</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.reload" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.reload"><code class="xref py py-obj docutils literal"><span class="pre">reload</span></code></a>()</td>
<td>Reload trained model from disk.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.restore" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.restore"><code class="xref py py-obj docutils literal"><span class="pre">restore</span></code></a>()</td>
<td>Reload the values of all variables from the most recent checkpoint file.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.save" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.save"><code class="xref py py-obj docutils literal"><span class="pre">save</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.save_checkpoint" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.save_checkpoint"><code class="xref py py-obj docutils literal"><span class="pre">save_checkpoint</span></code></a>([max_checkpoints_to_keep])</td>
<td>Save a checkpoint to disk.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_loss" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_loss"><code class="xref py py-obj docutils literal"><span class="pre">set_loss</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_optimizer" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_optimizer"><code class="xref py py-obj docutils literal"><span class="pre">set_optimizer</span></code></a>(optimizer)</td>
<td>Set the optimizer to use for fitting.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_params" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_params"><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code></a>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.topsort" title="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.topsort"><code class="xref py py-obj docutils literal"><span class="pre">topsort</span></code></a>()</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>layers: list</strong></p>
<blockquote>
<div><p>the list of layers to train.  If None, all layers in the model will be
trained.</p>
</div></blockquote>
<p><strong>loss: Layer</strong></p>
<blockquote>
<div><p>the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</p>
</div></blockquote>
<p><strong>optimizer: Optimizer</strong></p>
<blockquote>
<div><p>the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the newly created submodel, which can be passed to any of the fitting</p>
<p class="last">methods.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset object.</p>
</div></blockquote>
<p><strong>metric: deepchem.metrics.Metric</strong></p>
<blockquote>
<div><p>Evaluation metric</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of deepchem.transformers.Transformer</p>
</div></blockquote>
<p><strong>per_task_metrics: bool</strong></p>
<blockquote>
<div><p>If True, return per-task scores.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">dict</p>
<blockquote class="last">
<div><p>Maps tasks to scores under metric.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: Dataset</strong></p>
<blockquote>
<div><p>the Dataset to train on</p>
</div></blockquote>
<p><strong>nb_epoch: int</strong></p>
<blockquote>
<div><p>the number of epochs to train for</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>deterministic: bool</strong></p>
<blockquote>
<div><p>if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote class="last">
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>feed_dict_generator: generator</strong></p>
<blockquote>
<div><p>this should generate batches, each represented as a dict that maps
Layers to values.</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote>
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_sequences">
<code class="descname">fit_sequences</code><span class="sig-paren">(</span><em>sequences</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/seqtoseq.html#SeqToSeq.fit_sequences"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_sequences" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a set of sequences</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>sequences: iterable</strong></p>
<blockquote>
<div><p>the training samples to fit to.  Each sample should be
represented as a tuple of the form (input_sequence, output_sequence).</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote class="last">
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">results: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_embeddings">
<code class="descname">predict_embeddings</code><span class="sig-paren">(</span><em>sequences</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/seqtoseq.html#SeqToSeq.predict_embeddings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of input sequences, compute the embedding vectors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>sequences: iterable</strong></p>
<blockquote class="last">
<div><p>the input sequences to generate an embedding vector for</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_from_embeddings">
<code class="descname">predict_from_embeddings</code><span class="sig-paren">(</span><em>embeddings</em>, <em>beam_width=5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/seqtoseq.html#SeqToSeq.predict_from_embeddings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_from_embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of embedding vectors, predict the output sequences.</p>
<p>The prediction is done using a beam search with length normalization.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>embeddings: iterable</strong></p>
<blockquote>
<div><p>the embedding vectors to generate predictions for</p>
</div></blockquote>
<p><strong>beam_width: int</strong></p>
<blockquote class="last">
<div><p>the beam width to use for searching.  Set to 1 to use a simple greedy search.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_from_sequences">
<code class="descname">predict_from_sequences</code><span class="sig-paren">(</span><em>sequences</em>, <em>beam_width=5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/seqtoseq.html#SeqToSeq.predict_from_sequences"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_from_sequences" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of input sequences, predict the output sequences.</p>
<p>The prediction is done using a beam search with length normalization.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>sequences: iterable</strong></p>
<blockquote>
<div><p>the input sequences to generate a prediction for</p>
</div></blockquote>
<p><strong>beam_width: int</strong></p>
<blockquote class="last">
<div><p>the beam width to use for searching.  Set to 1 to use a simple greedy search.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>generator: Generator</strong></p>
<blockquote>
<div><p>Generator that constructs feed dictionaries for TensorGraph.</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
<p><strong>Returns:</strong></p>
<blockquote class="last">
<div><p>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">y_pred: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Returns:</dt>
<dd>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote class="last">
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.sequence_end">
<code class="descname">sequence_end</code><em class="property"> = &lt;object object&gt;</em><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.sequence_end" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.symmetry_function_regression">
<span id="deepchem-models-tensorgraph-models-symmetry-function-regression-module"></span><h2>deepchem.models.tensorgraph.models.symmetry_function_regression module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.symmetry_function_regression" title="Permalink to this headline">¶</a></h2>
<p>Created on Thu Jul  6 20:31:47 2017</p>
<p>&#64;author: zqwu
&#64;contributors: ytz</p>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.symmetry_function_regression.</code><code class="descname">ANIRegression</code><span class="sig-paren">(</span><em>n_tasks, max_atoms, layer_structures=[128, 64], atom_number_cases=[1, 6, 7, 8, 16], **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.add_output" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.add_output"><code class="xref py py-obj docutils literal"><span class="pre">add_output</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build_grad" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build_grad"><code class="xref py py-obj docutils literal"><span class="pre">build_grad</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build_graph" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build_graph"><code class="xref py py-obj docutils literal"><span class="pre">build_graph</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.compute_grad" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.compute_grad"><code class="xref py py-obj docutils literal"><span class="pre">compute_grad</span></code></a>(dataset[,&nbsp;upper_lim])</td>
<td>Computes a batched gradients given an input dataset.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.create_submodel" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.create_submodel"><code class="xref py py-obj docutils literal"><span class="pre">create_submodel</span></code></a>([layers,&nbsp;loss,&nbsp;optimizer])</td>
<td>Create an alternate objective for training one piece of a TensorGraph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.default_generator" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.default_generator"><code class="xref py py-obj docutils literal"><span class="pre">default_generator</span></code></a>(dataset[,&nbsp;epochs,&nbsp;...])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.evaluate" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.evaluate"><code class="xref py py-obj docutils literal"><span class="pre">evaluate</span></code></a>(dataset,&nbsp;metrics[,&nbsp;transformers,&nbsp;...])</td>
<td>Evaluates the performance of this model on specified dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.evaluate_generator" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.evaluate_generator"><code class="xref py py-obj docutils literal"><span class="pre">evaluate_generator</span></code></a>(feed_dict_generator,&nbsp;metrics)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(dataset[,&nbsp;nb_epoch,&nbsp;...])</td>
<td>Train this model on a dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit_generator" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit_generator"><code class="xref py py-obj docutils literal"><span class="pre">fit_generator</span></code></a>(feed_dict_generator[,&nbsp;...])</td>
<td>Train this model on data from a generator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit_on_batch" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">fit_on_batch</span></code></a>(X,&nbsp;y,&nbsp;w[,&nbsp;submodel])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_global_step" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_global_step"><code class="xref py py-obj docutils literal"><span class="pre">get_global_step</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_layer_variables" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_layer_variables"><code class="xref py py-obj docutils literal"><span class="pre">get_layer_variables</span></code></a>(layer)</td>
<td>Get the list of trainable variables in a layer of the graph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_model_filename" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_model_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_model_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_num_tasks" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_num_tasks"><code class="xref py py-obj docutils literal"><span class="pre">get_num_tasks</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_params" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_params"><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_params_filename" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_params_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_params_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_pickling_errors" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_pickling_errors"><code class="xref py py-obj docutils literal"><span class="pre">get_pickling_errors</span></code></a>(obj[,&nbsp;seen])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_pre_q_input" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_pre_q_input"><code class="xref py py-obj docutils literal"><span class="pre">get_pre_q_input</span></code></a>(input_layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_task_type" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_task_type"><code class="xref py py-obj docutils literal"><span class="pre">get_task_type</span></code></a>()</td>
<td>Currently models can only be classifiers or regressors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.grad_one" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.grad_one"><code class="xref py py-obj docutils literal"><span class="pre">grad_one</span></code></a>(X,&nbsp;atomic_nums[,&nbsp;constraints])</td>
<td>Computes gradients for that of a single structure.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.load_from_dir" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.load_from_dir"><code class="xref py py-obj docutils literal"><span class="pre">load_from_dir</span></code></a>(model_dir)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.load_numpy" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.load_numpy"><code class="xref py py-obj docutils literal"><span class="pre">load_numpy</span></code></a>(model_dir)</td>
<td>Load from a portable numpy file.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.minimize_structure" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.minimize_structure"><code class="xref py py-obj docutils literal"><span class="pre">minimize_structure</span></code></a>(X,&nbsp;atomic_nums[,&nbsp;constraints])</td>
<td>Minimizes a structure, as defined by a set of coordinates and their atomic numbers.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.pred_one" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.pred_one"><code class="xref py py-obj docutils literal"><span class="pre">pred_one</span></code></a>(X,&nbsp;atomic_nums[,&nbsp;constraints])</td>
<td>Makes an energy prediction for a set of atomic coordinates.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Uses self to make predictions on provided Dataset object.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_on_batch" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_on_generator" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba_on_batch" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;...])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba_on_generator" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td>Returns:</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.reload" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.reload"><code class="xref py py-obj docutils literal"><span class="pre">reload</span></code></a>()</td>
<td>Reload trained model from disk.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.restore" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.restore"><code class="xref py py-obj docutils literal"><span class="pre">restore</span></code></a>()</td>
<td>Reload the values of all variables from the most recent checkpoint file.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save"><code class="xref py py-obj docutils literal"><span class="pre">save</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save_checkpoint" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save_checkpoint"><code class="xref py py-obj docutils literal"><span class="pre">save_checkpoint</span></code></a>([max_checkpoints_to_keep])</td>
<td>Save a checkpoint to disk.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save_numpy" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save_numpy"><code class="xref py py-obj docutils literal"><span class="pre">save_numpy</span></code></a>()</td>
<td>Save to a portable numpy file.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_loss" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_loss"><code class="xref py py-obj docutils literal"><span class="pre">set_loss</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_optimizer" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_optimizer"><code class="xref py py-obj docutils literal"><span class="pre">set_optimizer</span></code></a>(optimizer)</td>
<td>Set the optimizer to use for fitting.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_params" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_params"><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code></a>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.topsort" title="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.topsort"><code class="xref py py-obj docutils literal"><span class="pre">topsort</span></code></a>()</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build_grad">
<code class="descname">build_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.build_grad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build_grad" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.build_graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.compute_grad">
<code class="descname">compute_grad</code><span class="sig-paren">(</span><em>dataset</em>, <em>upper_lim=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.compute_grad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.compute_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a batched gradients given an input dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.Dataset</strong></p>
<blockquote>
<div><p>dataset-like object whose X values will be used to compute
gradients from</p>
</div></blockquote>
<p><strong>upper_lim: int</strong></p>
<blockquote>
<div><p>subset of dataset used.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">np.array</p>
<blockquote class="last">
<div><p>Gradients of the input of shape (max_atoms, 4). Note that it is up to
the end user to slice this matrix into the correct shape, since it&#8217;s very
likely the derivatives with respect to the atomic numbers are zero.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>layers: list</strong></p>
<blockquote>
<div><p>the list of layers to train.  If None, all layers in the model will be
trained.</p>
</div></blockquote>
<p><strong>loss: Layer</strong></p>
<blockquote>
<div><p>the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</p>
</div></blockquote>
<p><strong>optimizer: Optimizer</strong></p>
<blockquote>
<div><p>the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the newly created submodel, which can be passed to any of the fitting</p>
<p class="last">methods.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset object.</p>
</div></blockquote>
<p><strong>metric: deepchem.metrics.Metric</strong></p>
<blockquote>
<div><p>Evaluation metric</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of deepchem.transformers.Transformer</p>
</div></blockquote>
<p><strong>per_task_metrics: bool</strong></p>
<blockquote>
<div><p>If True, return per-task scores.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">dict</p>
<blockquote class="last">
<div><p>Maps tasks to scores under metric.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: Dataset</strong></p>
<blockquote>
<div><p>the Dataset to train on</p>
</div></blockquote>
<p><strong>nb_epoch: int</strong></p>
<blockquote>
<div><p>the number of epochs to train for</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>deterministic: bool</strong></p>
<blockquote>
<div><p>if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote class="last">
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>feed_dict_generator: generator</strong></p>
<blockquote>
<div><p>this should generate batches, each represented as a dict that maps
Layers to values.</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote>
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.grad_one">
<code class="descname">grad_one</code><span class="sig-paren">(</span><em>X</em>, <em>atomic_nums</em>, <em>constraints=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.grad_one"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.grad_one" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes gradients for that of a single structure.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: np.array</strong></p>
<blockquote>
<div><p>numpy array of shape (a, 3) where a &lt;= max_atoms and
dtype is float-like</p>
</div></blockquote>
<p><strong>atomic_nums: np.array</strong></p>
<blockquote>
<div><p>numpy array of shape (a,) where a is the same as that of X.</p>
</div></blockquote>
<p><strong>constraints: np.array</strong></p>
<blockquote>
<div><p>numpy array of indices of X used for constraining a subset
of the atoms of the molecule.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">np.array</p>
<blockquote class="last">
<div><p>derivatives of the same shape and type as input parameter X.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.load_numpy">
<em class="property">classmethod </em><code class="descname">load_numpy</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.load_numpy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.load_numpy" title="Permalink to this definition">¶</a></dt>
<dd><p>Load from a portable numpy file.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>model_dir: str</strong></p>
<blockquote class="last">
<div><p>Location of the model directory.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.minimize_structure">
<code class="descname">minimize_structure</code><span class="sig-paren">(</span><em>X</em>, <em>atomic_nums</em>, <em>constraints=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.minimize_structure"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.minimize_structure" title="Permalink to this definition">¶</a></dt>
<dd><p>Minimizes a structure, as defined by a set of coordinates and their atomic
numbers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: np.array</strong></p>
<blockquote>
<div><p>numpy array of shape (a, 3) where a &lt;= max_atoms and
dtype is float-like</p>
</div></blockquote>
<p><strong>atomic_nums: np.array</strong></p>
<blockquote>
<div><p>numpy array of shape (a,) where a is the same as that of X.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">np.array</p>
<blockquote class="last">
<div><p>minimized coordinates of the same shape and type as input parameter X.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.pred_one">
<code class="descname">pred_one</code><span class="sig-paren">(</span><em>X</em>, <em>atomic_nums</em>, <em>constraints=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.pred_one"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.pred_one" title="Permalink to this definition">¶</a></dt>
<dd><p>Makes an energy prediction for a set of atomic coordinates.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: np.array</strong></p>
<blockquote>
<div><p>numpy array of shape (a, 3) where a &lt;= max_atoms and
dtype is float-like</p>
</div></blockquote>
<p><strong>atomic_nums: np.array</strong></p>
<blockquote>
<div><p>numpy array of shape (a,) where a is the same as that of X.</p>
</div></blockquote>
<p><strong>constraints: unused</strong></p>
<blockquote>
<div><p>This parameter is mainly for compatibility purposes for scipy optimize</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">float</p>
<blockquote class="last">
<div><p>Predicted energy. Note that the meaning of the returned value is
dependent on the training y-values both in semantics (relative vs absolute)
and units (kcal/mol vs Hartrees)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">results: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>generator: Generator</strong></p>
<blockquote>
<div><p>Generator that constructs feed dictionaries for TensorGraph.</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
<p><strong>Returns:</strong></p>
<blockquote class="last">
<div><p>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">y_pred: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Returns:</dt>
<dd>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote class="last">
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save_numpy">
<code class="descname">save_numpy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#ANIRegression.save_numpy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.save_numpy" title="Permalink to this definition">¶</a></dt>
<dd><p>Save to a portable numpy file. Note that this relies on the names to be consistent
across different versions. The file is saved as save_pickle.npz under the model_dir.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.ANIRegression.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.symmetry_function_regression.</code><code class="descname">BPSymmetryFunctionRegression</code><span class="sig-paren">(</span><em>n_tasks, max_atoms, n_feat=96, layer_structures=[128, 64], **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#BPSymmetryFunctionRegression"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.add_output" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.add_output"><code class="xref py py-obj docutils literal"><span class="pre">add_output</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.build" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.build_graph" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.build_graph"><code class="xref py py-obj docutils literal"><span class="pre">build_graph</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.create_submodel" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.create_submodel"><code class="xref py py-obj docutils literal"><span class="pre">create_submodel</span></code></a>([layers,&nbsp;loss,&nbsp;optimizer])</td>
<td>Create an alternate objective for training one piece of a TensorGraph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.default_generator" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.default_generator"><code class="xref py py-obj docutils literal"><span class="pre">default_generator</span></code></a>(dataset[,&nbsp;epochs,&nbsp;...])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.evaluate" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.evaluate"><code class="xref py py-obj docutils literal"><span class="pre">evaluate</span></code></a>(dataset,&nbsp;metrics[,&nbsp;transformers,&nbsp;...])</td>
<td>Evaluates the performance of this model on specified dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.evaluate_generator" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.evaluate_generator"><code class="xref py py-obj docutils literal"><span class="pre">evaluate_generator</span></code></a>(feed_dict_generator,&nbsp;metrics)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(dataset[,&nbsp;nb_epoch,&nbsp;...])</td>
<td>Train this model on a dataset.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit_generator" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit_generator"><code class="xref py py-obj docutils literal"><span class="pre">fit_generator</span></code></a>(feed_dict_generator[,&nbsp;...])</td>
<td>Train this model on data from a generator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit_on_batch" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">fit_on_batch</span></code></a>(X,&nbsp;y,&nbsp;w[,&nbsp;submodel])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_global_step" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_global_step"><code class="xref py py-obj docutils literal"><span class="pre">get_global_step</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_layer_variables" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_layer_variables"><code class="xref py py-obj docutils literal"><span class="pre">get_layer_variables</span></code></a>(layer)</td>
<td>Get the list of trainable variables in a layer of the graph.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_model_filename" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_model_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_model_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_num_tasks" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_num_tasks"><code class="xref py py-obj docutils literal"><span class="pre">get_num_tasks</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_params" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_params"><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_params_filename" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_params_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_params_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_pickling_errors" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_pickling_errors"><code class="xref py py-obj docutils literal"><span class="pre">get_pickling_errors</span></code></a>(obj[,&nbsp;seen])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_pre_q_input" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_pre_q_input"><code class="xref py py-obj docutils literal"><span class="pre">get_pre_q_input</span></code></a>(input_layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_task_type" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_task_type"><code class="xref py py-obj docutils literal"><span class="pre">get_task_type</span></code></a>()</td>
<td>Currently models can only be classifiers or regressors.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.load_from_dir" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.load_from_dir"><code class="xref py py-obj docutils literal"><span class="pre">load_from_dir</span></code></a>(model_dir)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Uses self to make predictions on provided Dataset object.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_on_batch" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_on_generator" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba_on_batch" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;...])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba_on_generator" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td>Returns:</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.reload" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.reload"><code class="xref py py-obj docutils literal"><span class="pre">reload</span></code></a>()</td>
<td>Reload trained model from disk.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.restore" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.restore"><code class="xref py py-obj docutils literal"><span class="pre">restore</span></code></a>()</td>
<td>Reload the values of all variables from the most recent checkpoint file.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.save" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.save"><code class="xref py py-obj docutils literal"><span class="pre">save</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.save_checkpoint" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.save_checkpoint"><code class="xref py py-obj docutils literal"><span class="pre">save_checkpoint</span></code></a>([max_checkpoints_to_keep])</td>
<td>Save a checkpoint to disk.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_loss" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_loss"><code class="xref py py-obj docutils literal"><span class="pre">set_loss</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_optimizer" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_optimizer"><code class="xref py py-obj docutils literal"><span class="pre">set_optimizer</span></code></a>(optimizer)</td>
<td>Set the optimizer to use for fitting.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_params" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_params"><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code></a>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.topsort" title="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.topsort"><code class="xref py py-obj docutils literal"><span class="pre">topsort</span></code></a>()</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#BPSymmetryFunctionRegression.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.build_graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>layers: list</strong></p>
<blockquote>
<div><p>the list of layers to train.  If None, all layers in the model will be
trained.</p>
</div></blockquote>
<p><strong>loss: Layer</strong></p>
<blockquote>
<div><p>the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</p>
</div></blockquote>
<p><strong>optimizer: Optimizer</strong></p>
<blockquote>
<div><p>the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the newly created submodel, which can be passed to any of the fitting</p>
<p class="last">methods.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/symmetry_function_regression.html#BPSymmetryFunctionRegression.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset object.</p>
</div></blockquote>
<p><strong>metric: deepchem.metrics.Metric</strong></p>
<blockquote>
<div><p>Evaluation metric</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of deepchem.transformers.Transformer</p>
</div></blockquote>
<p><strong>per_task_metrics: bool</strong></p>
<blockquote>
<div><p>If True, return per-task scores.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">dict</p>
<blockquote class="last">
<div><p>Maps tasks to scores under metric.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: Dataset</strong></p>
<blockquote>
<div><p>the Dataset to train on</p>
</div></blockquote>
<p><strong>nb_epoch: int</strong></p>
<blockquote>
<div><p>the number of epochs to train for</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>deterministic: bool</strong></p>
<blockquote>
<div><p>if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote class="last">
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>feed_dict_generator: generator</strong></p>
<blockquote>
<div><p>this should generate batches, each represented as a dict that maps
Layers to values.</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote>
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">results: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>generator: Generator</strong></p>
<blockquote>
<div><p>Generator that constructs feed dictionaries for TensorGraph.</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
<p><strong>Returns:</strong></p>
<blockquote class="last">
<div><p>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">y_pred: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Returns:</dt>
<dd>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote class="last">
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.symmetry_function_regression.BPSymmetryFunctionRegression.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.test_graph_models">
<span id="deepchem-models-tensorgraph-models-test-graph-models-module"></span><h2>deepchem.models.tensorgraph.models.test_graph_models module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.test_graph_models" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.test_graph_models.</code><code class="descname">TestGraphModels</code><span class="sig-paren">(</span><em>methodName='runTest'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_graph_models.html#TestGraphModels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">unittest.case.TestCase</span></code></p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(*args,&nbsp;**kwds)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.addCleanup" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.addCleanup"><code class="xref py py-obj docutils literal"><span class="pre">addCleanup</span></code></a>(function,&nbsp;*args,&nbsp;**kwargs)</td>
<td>Add a function, with arguments, to be called when the test is completed.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.addTypeEqualityFunc" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.addTypeEqualityFunc"><code class="xref py py-obj docutils literal"><span class="pre">addTypeEqualityFunc</span></code></a>(typeobj,&nbsp;function)</td>
<td>Add a type specific assertEqual style function to compare a type.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertAlmostEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertAlmostEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertAlmostEqual</span></code></a>(first,&nbsp;second[,&nbsp;places,&nbsp;...])</td>
<td>Fail if the two objects are unequal as determined by their difference rounded to the given number of decimal places (default 7) and comparing to zero, or by comparing that the between the two objects is more than the given delta.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertAlmostEquals" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertAlmostEquals"><code class="xref py py-obj docutils literal"><span class="pre">assertAlmostEquals</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertCountEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertCountEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertCountEqual</span></code></a>(first,&nbsp;second[,&nbsp;msg])</td>
<td>An unordered sequence comparison asserting that the same elements, regardless of order.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertDictContainsSubset" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertDictContainsSubset"><code class="xref py py-obj docutils literal"><span class="pre">assertDictContainsSubset</span></code></a>(subset,&nbsp;dictionary)</td>
<td>Checks whether dictionary is a superset of subset.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertDictEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertDictEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertDictEqual</span></code></a>(d1,&nbsp;d2[,&nbsp;msg])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertEqual</span></code></a>(first,&nbsp;second[,&nbsp;msg])</td>
<td>Fail if the two objects are unequal as determined by the &#8216;==&#8217; operator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertEquals" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertEquals"><code class="xref py py-obj docutils literal"><span class="pre">assertEquals</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertFalse" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertFalse"><code class="xref py py-obj docutils literal"><span class="pre">assertFalse</span></code></a>(expr[,&nbsp;msg])</td>
<td>Check that the expression is false.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertGreater" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertGreater"><code class="xref py py-obj docutils literal"><span class="pre">assertGreater</span></code></a>(a,&nbsp;b[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a &gt; b), but with a nicer default message.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertGreaterEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertGreaterEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertGreaterEqual</span></code></a>(a,&nbsp;b[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a &gt;= b), but with a nicer default message.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIn" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIn"><code class="xref py py-obj docutils literal"><span class="pre">assertIn</span></code></a>(member,&nbsp;container[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a in b), but with a nicer default message.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIs" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIs"><code class="xref py py-obj docutils literal"><span class="pre">assertIs</span></code></a>(expr1,&nbsp;expr2[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a is b), but with a nicer default message.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsInstance" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsInstance"><code class="xref py py-obj docutils literal"><span class="pre">assertIsInstance</span></code></a>(obj,&nbsp;cls[,&nbsp;msg])</td>
<td>Same as self.assertTrue(isinstance(obj, cls)), with a nicer default message.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNone" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNone"><code class="xref py py-obj docutils literal"><span class="pre">assertIsNone</span></code></a>(obj[,&nbsp;msg])</td>
<td>Same as self.assertTrue(obj is None), with a nicer default message.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNot" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNot"><code class="xref py py-obj docutils literal"><span class="pre">assertIsNot</span></code></a>(expr1,&nbsp;expr2[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a is not b), but with a nicer default message.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNotNone" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNotNone"><code class="xref py py-obj docutils literal"><span class="pre">assertIsNotNone</span></code></a>(obj[,&nbsp;msg])</td>
<td>Included for symmetry with assertIsNone.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLess" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLess"><code class="xref py py-obj docutils literal"><span class="pre">assertLess</span></code></a>(a,&nbsp;b[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a &lt; b), but with a nicer default message.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLessEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLessEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertLessEqual</span></code></a>(a,&nbsp;b[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a &lt;= b), but with a nicer default message.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertListEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertListEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertListEqual</span></code></a>(list1,&nbsp;list2[,&nbsp;msg])</td>
<td>A list-specific equality assertion.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLogs" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLogs"><code class="xref py py-obj docutils literal"><span class="pre">assertLogs</span></code></a>([logger,&nbsp;level])</td>
<td>Fail unless a log message of level <em>level</em> or higher is emitted on <em>logger_name</em> or its children.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertMultiLineEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertMultiLineEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertMultiLineEqual</span></code></a>(first,&nbsp;second[,&nbsp;msg])</td>
<td>Assert that two multi-line strings are equal.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotAlmostEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotAlmostEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertNotAlmostEqual</span></code></a>(first,&nbsp;second[,&nbsp;...])</td>
<td>Fail if the two objects are equal as determined by their difference rounded to the given number of decimal places (default 7) and comparing to zero, or by comparing that the between the two objects is less than the given delta.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotAlmostEquals" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotAlmostEquals"><code class="xref py py-obj docutils literal"><span class="pre">assertNotAlmostEquals</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertNotEqual</span></code></a>(first,&nbsp;second[,&nbsp;msg])</td>
<td>Fail if the two objects are equal as determined by the &#8216;!=&#8217; operator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotEquals" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotEquals"><code class="xref py py-obj docutils literal"><span class="pre">assertNotEquals</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotIn" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotIn"><code class="xref py py-obj docutils literal"><span class="pre">assertNotIn</span></code></a>(member,&nbsp;container[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a not in b), but with a nicer default message.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotIsInstance" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotIsInstance"><code class="xref py py-obj docutils literal"><span class="pre">assertNotIsInstance</span></code></a>(obj,&nbsp;cls[,&nbsp;msg])</td>
<td>Included for symmetry with assertIsInstance.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotRegex" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotRegex"><code class="xref py py-obj docutils literal"><span class="pre">assertNotRegex</span></code></a>(text,&nbsp;unexpected_regex[,&nbsp;msg])</td>
<td>Fail the test if the text matches the regular expression.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotRegexpMatches" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotRegexpMatches"><code class="xref py py-obj docutils literal"><span class="pre">assertNotRegexpMatches</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaises" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaises"><code class="xref py py-obj docutils literal"><span class="pre">assertRaises</span></code></a>(expected_exception,&nbsp;*args,&nbsp;**kwargs)</td>
<td>Fail unless an exception of class expected_exception is raised by the callable when invoked with specified positional and keyword arguments.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaisesRegex" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaisesRegex"><code class="xref py py-obj docutils literal"><span class="pre">assertRaisesRegex</span></code></a>(expected_exception,&nbsp;...)</td>
<td>Asserts that the message in a raised exception matches a regex.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaisesRegexp" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaisesRegexp"><code class="xref py py-obj docutils literal"><span class="pre">assertRaisesRegexp</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRegex" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRegex"><code class="xref py py-obj docutils literal"><span class="pre">assertRegex</span></code></a>(text,&nbsp;expected_regex[,&nbsp;msg])</td>
<td>Fail the test unless the text matches the regular expression.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRegexpMatches" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRegexpMatches"><code class="xref py py-obj docutils literal"><span class="pre">assertRegexpMatches</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertSequenceEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertSequenceEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertSequenceEqual</span></code></a>(seq1,&nbsp;seq2[,&nbsp;msg,&nbsp;seq_type])</td>
<td>An equality assertion for ordered sequences (like lists and tuples).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertSetEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertSetEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertSetEqual</span></code></a>(set1,&nbsp;set2[,&nbsp;msg])</td>
<td>A set-specific equality assertion.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertTrue" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertTrue"><code class="xref py py-obj docutils literal"><span class="pre">assertTrue</span></code></a>(expr[,&nbsp;msg])</td>
<td>Check that the expression is true.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertTupleEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertTupleEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertTupleEqual</span></code></a>(tuple1,&nbsp;tuple2[,&nbsp;msg])</td>
<td>A tuple-specific equality assertion.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertWarns" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertWarns"><code class="xref py py-obj docutils literal"><span class="pre">assertWarns</span></code></a>(expected_warning,&nbsp;*args,&nbsp;**kwargs)</td>
<td>Fail unless a warning of class warnClass is triggered by the callable when invoked with specified positional and keyword arguments.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertWarnsRegex" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertWarnsRegex"><code class="xref py py-obj docutils literal"><span class="pre">assertWarnsRegex</span></code></a>(expected_warning,&nbsp;...)</td>
<td>Asserts that the message in a triggered warning matches a regexp.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assert_" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assert_"><code class="xref py py-obj docutils literal"><span class="pre">assert_</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.countTestCases" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.countTestCases"><code class="xref py py-obj docutils literal"><span class="pre">countTestCases</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.debug" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.debug"><code class="xref py py-obj docutils literal"><span class="pre">debug</span></code></a>()</td>
<td>Run the test without collecting errors in a TestResult</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.defaultTestResult" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.defaultTestResult"><code class="xref py py-obj docutils literal"><span class="pre">defaultTestResult</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.doCleanups" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.doCleanups"><code class="xref py py-obj docutils literal"><span class="pre">doCleanups</span></code></a>()</td>
<td>Execute all cleanup functions.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.fail" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.fail"><code class="xref py py-obj docutils literal"><span class="pre">fail</span></code></a>([msg])</td>
<td>Fail immediately, with the given message.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIf" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIf"><code class="xref py py-obj docutils literal"><span class="pre">failIf</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIfAlmostEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIfAlmostEqual"><code class="xref py py-obj docutils literal"><span class="pre">failIfAlmostEqual</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIfEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIfEqual"><code class="xref py py-obj docutils literal"><span class="pre">failIfEqual</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnless" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnless"><code class="xref py py-obj docutils literal"><span class="pre">failUnless</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessAlmostEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessAlmostEqual"><code class="xref py py-obj docutils literal"><span class="pre">failUnlessAlmostEqual</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessEqual" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessEqual"><code class="xref py py-obj docutils literal"><span class="pre">failUnlessEqual</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessRaises" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessRaises"><code class="xref py py-obj docutils literal"><span class="pre">failUnlessRaises</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failureException" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failureException"><code class="xref py py-obj docutils literal"><span class="pre">failureException</span></code></a></td>
<td>alias of <a class="reference external" href="https://docs.python.org/library/exceptions.html#AssertionError" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">AssertionError</span></code></a></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.get_dataset" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.get_dataset"><code class="xref py py-obj docutils literal"><span class="pre">get_dataset</span></code></a>([mode,&nbsp;featurizer])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.id" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.id"><code class="xref py py-obj docutils literal"><span class="pre">id</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.run" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.run"><code class="xref py py-obj docutils literal"><span class="pre">run</span></code></a>([result])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.setUp" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.setUp"><code class="xref py py-obj docutils literal"><span class="pre">setUp</span></code></a>()</td>
<td>Hook method for setting up the test fixture before exercising it.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.setUpClass" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.setUpClass"><code class="xref py py-obj docutils literal"><span class="pre">setUpClass</span></code></a>()</td>
<td>Hook method for setting up class fixture before running tests in the class.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.shortDescription" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.shortDescription"><code class="xref py py-obj docutils literal"><span class="pre">shortDescription</span></code></a>()</td>
<td>Returns a one-line description of the test, or None if no description has been provided.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.skipTest" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.skipTest"><code class="xref py py-obj docutils literal"><span class="pre">skipTest</span></code></a>(reason)</td>
<td>Skip this test.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.subTest" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.subTest"><code class="xref py py-obj docutils literal"><span class="pre">subTest</span></code></a>([msg])</td>
<td>Return a context manager that will return the enclosed block of code in a subtest identified by the optional message and keyword parameters.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.tearDown" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.tearDown"><code class="xref py py-obj docutils literal"><span class="pre">tearDown</span></code></a>()</td>
<td>Hook method for deconstructing the test fixture after testing it.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.tearDownClass" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.tearDownClass"><code class="xref py py-obj docutils literal"><span class="pre">tearDownClass</span></code></a>()</td>
<td>Hook method for deconstructing the class fixture after running all tests in the class.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_error_bars" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_error_bars"><code class="xref py py-obj docutils literal"><span class="pre">test_graph_conv_error_bars</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_model" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_model"><code class="xref py py-obj docutils literal"><span class="pre">test_graph_conv_model</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_regression_model" title="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_regression_model"><code class="xref py py-obj docutils literal"><span class="pre">test_graph_conv_regression_model</span></code></a>()</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.addCleanup">
<code class="descname">addCleanup</code><span class="sig-paren">(</span><em>function</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.addCleanup" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a function, with arguments, to be called when the test is
completed. Functions added are called on a LIFO basis and are
called after tearDown on test failure or success.</p>
<p>Cleanup items are called even if setUp fails (unlike tearDown).</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.addTypeEqualityFunc">
<code class="descname">addTypeEqualityFunc</code><span class="sig-paren">(</span><em>typeobj</em>, <em>function</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.addTypeEqualityFunc" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a type specific assertEqual style function to compare a type.</p>
<p>This method is for use by TestCase subclasses that need to register
their own type equality functions to provide nicer error messages.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first last docutils">
<dt>typeobj: The data type to call this function on when both values</dt>
<dd>are of the same type in assertEqual().</dd>
<dt>function: The callable taking two arguments and an optional</dt>
<dd>msg= argument that raises self.failureException with a
useful error message when the two arguments are not equal.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertAlmostEqual">
<code class="descname">assertAlmostEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>places=None</em>, <em>msg=None</em>, <em>delta=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are unequal as determined by their
difference rounded to the given number of decimal places
(default 7) and comparing to zero, or by comparing that the
between the two objects is more than the given delta.</p>
<p>Note that decimal places (from zero) are usually not the same
as significant digits (measured from the most significant digit).</p>
<p>If the two objects compare equal then they will automatically
compare almost equal.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertAlmostEquals">
<code class="descname">assertAlmostEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertAlmostEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertCountEqual">
<code class="descname">assertCountEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertCountEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>An unordered sequence comparison asserting that the same elements,
regardless of order.  If the same element occurs more than once,
it verifies that the elements occur the same number of times.</p>
<blockquote>
<div><blockquote>
<div><dl class="docutils">
<dt>self.assertEqual(Counter(list(first)),</dt>
<dd>Counter(list(second)))</dd>
</dl>
</div></blockquote>
<dl class="docutils">
<dt>Example:</dt>
<dd><ul class="first last simple">
<li>[0, 1, 1] and [1, 0, 1] compare equal.</li>
<li>[0, 0, 1] and [0, 1] compare unequal.</li>
</ul>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertDictContainsSubset">
<code class="descname">assertDictContainsSubset</code><span class="sig-paren">(</span><em>subset</em>, <em>dictionary</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertDictContainsSubset" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks whether dictionary is a superset of subset.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertDictEqual">
<code class="descname">assertDictEqual</code><span class="sig-paren">(</span><em>d1</em>, <em>d2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertDictEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertEqual">
<code class="descname">assertEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are unequal as determined by the &#8216;==&#8217;
operator.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertEquals">
<code class="descname">assertEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertFalse">
<code class="descname">assertFalse</code><span class="sig-paren">(</span><em>expr</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertFalse" title="Permalink to this definition">¶</a></dt>
<dd><p>Check that the expression is false.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertGreater">
<code class="descname">assertGreater</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertGreater" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &gt; b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertGreaterEqual">
<code class="descname">assertGreaterEqual</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertGreaterEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &gt;= b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIn">
<code class="descname">assertIn</code><span class="sig-paren">(</span><em>member</em>, <em>container</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIn" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a in b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIs">
<code class="descname">assertIs</code><span class="sig-paren">(</span><em>expr1</em>, <em>expr2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIs" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a is b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsInstance">
<code class="descname">assertIsInstance</code><span class="sig-paren">(</span><em>obj</em>, <em>cls</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsInstance" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as self.assertTrue(isinstance(obj, cls)), with a nicer
default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNone">
<code class="descname">assertIsNone</code><span class="sig-paren">(</span><em>obj</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNone" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as self.assertTrue(obj is None), with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNot">
<code class="descname">assertIsNot</code><span class="sig-paren">(</span><em>expr1</em>, <em>expr2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNot" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a is not b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNotNone">
<code class="descname">assertIsNotNone</code><span class="sig-paren">(</span><em>obj</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertIsNotNone" title="Permalink to this definition">¶</a></dt>
<dd><p>Included for symmetry with assertIsNone.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLess">
<code class="descname">assertLess</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLess" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &lt; b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLessEqual">
<code class="descname">assertLessEqual</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLessEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &lt;= b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertListEqual">
<code class="descname">assertListEqual</code><span class="sig-paren">(</span><em>list1</em>, <em>list2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertListEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>A list-specific equality assertion.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">list1: The first list to compare.
list2: The second list to compare.
msg: Optional message to use on failure instead of a list of</p>
<blockquote class="last">
<div>differences.</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLogs">
<code class="descname">assertLogs</code><span class="sig-paren">(</span><em>logger=None</em>, <em>level=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertLogs" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail unless a log message of level <em>level</em> or higher is emitted
on <em>logger_name</em> or its children.  If omitted, <em>level</em> defaults to
INFO and <em>logger</em> defaults to the root logger.</p>
<p>This method must be used as a context manager, and will yield
a recording object with two attributes: <cite>output</cite> and <cite>records</cite>.
At the end of the context manager, the <cite>output</cite> attribute will
be a list of the matching formatted log messages and the
<cite>records</cite> attribute will be a list of the corresponding LogRecord
objects.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertLogs</span><span class="p">(</span><span class="s1">&#39;foo&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="s1">&#39;INFO&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">cm</span><span class="p">:</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;foo&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;first message&#39;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;foo.bar&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s1">&#39;second message&#39;</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;INFO:foo:first message&#39;</span><span class="p">,</span>
                             <span class="s1">&#39;ERROR:foo.bar:second message&#39;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertMultiLineEqual">
<code class="descname">assertMultiLineEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertMultiLineEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Assert that two multi-line strings are equal.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotAlmostEqual">
<code class="descname">assertNotAlmostEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>places=None</em>, <em>msg=None</em>, <em>delta=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are equal as determined by their
difference rounded to the given number of decimal places
(default 7) and comparing to zero, or by comparing that the
between the two objects is less than the given delta.</p>
<p>Note that decimal places (from zero) are usually not the same
as significant digits (measured from the most significant digit).</p>
<p>Objects that are equal automatically fail.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotAlmostEquals">
<code class="descname">assertNotAlmostEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotAlmostEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotEqual">
<code class="descname">assertNotEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are equal as determined by the &#8216;!=&#8217;
operator.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotEquals">
<code class="descname">assertNotEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotIn">
<code class="descname">assertNotIn</code><span class="sig-paren">(</span><em>member</em>, <em>container</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotIn" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a not in b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotIsInstance">
<code class="descname">assertNotIsInstance</code><span class="sig-paren">(</span><em>obj</em>, <em>cls</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotIsInstance" title="Permalink to this definition">¶</a></dt>
<dd><p>Included for symmetry with assertIsInstance.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotRegex">
<code class="descname">assertNotRegex</code><span class="sig-paren">(</span><em>text</em>, <em>unexpected_regex</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail the test if the text matches the regular expression.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotRegexpMatches">
<code class="descname">assertNotRegexpMatches</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertNotRegexpMatches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaises">
<code class="descname">assertRaises</code><span class="sig-paren">(</span><em>expected_exception</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaises" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail unless an exception of class expected_exception is raised
by the callable when invoked with specified positional and
keyword arguments. If a different type of exception is
raised, it will not be caught, and the test case will be
deemed to have suffered an error, exactly as for an
unexpected exception.</p>
<p>If called with the callable and arguments omitted, will return a
context object used like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertRaises</span><span class="p">(</span><span class="n">SomeException</span><span class="p">):</span>
    <span class="n">do_something</span><span class="p">()</span>
</pre></div>
</div>
<p>An optional keyword argument &#8216;msg&#8217; can be provided when assertRaises
is used as a context object.</p>
<p>The context manager keeps a reference to the exception as
the &#8216;exception&#8217; attribute. This allows you to inspect the
exception after the assertion:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertRaises</span><span class="p">(</span><span class="n">SomeException</span><span class="p">)</span> <span class="k">as</span> <span class="n">cm</span><span class="p">:</span>
    <span class="n">do_something</span><span class="p">()</span>
<span class="n">the_exception</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">exception</span>
<span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">the_exception</span><span class="o">.</span><span class="n">error_code</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaisesRegex">
<code class="descname">assertRaisesRegex</code><span class="sig-paren">(</span><em>expected_exception</em>, <em>expected_regex</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaisesRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Asserts that the message in a raised exception matches a regex.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">expected_exception: Exception class expected to be raised.
expected_regex: Regex (re pattern object or string) expected</p>
<blockquote>
<div>to be found in error message.</div></blockquote>
<p>args: Function to be called and extra positional args.
kwargs: Extra kwargs.
msg: Optional message used in case of failure. Can only be used</p>
<blockquote class="last">
<div>when assertRaisesRegex is used as a context manager.</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaisesRegexp">
<code class="descname">assertRaisesRegexp</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRaisesRegexp" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRegex">
<code class="descname">assertRegex</code><span class="sig-paren">(</span><em>text</em>, <em>expected_regex</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail the test unless the text matches the regular expression.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRegexpMatches">
<code class="descname">assertRegexpMatches</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertRegexpMatches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertSequenceEqual">
<code class="descname">assertSequenceEqual</code><span class="sig-paren">(</span><em>seq1</em>, <em>seq2</em>, <em>msg=None</em>, <em>seq_type=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertSequenceEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>An equality assertion for ordered sequences (like lists and tuples).</p>
<p>For the purposes of this function, a valid ordered sequence type is one
which can be indexed, has a length, and has an equality operator.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">seq1: The first sequence to compare.
seq2: The second sequence to compare.
seq_type: The expected datatype of the sequences, or None if no</p>
<blockquote>
<div>datatype should be enforced.</div></blockquote>
<dl class="last docutils">
<dt>msg: Optional message to use on failure instead of a list of</dt>
<dd>differences.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertSetEqual">
<code class="descname">assertSetEqual</code><span class="sig-paren">(</span><em>set1</em>, <em>set2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertSetEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>A set-specific equality assertion.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">set1: The first set to compare.
set2: The second set to compare.
msg: Optional message to use on failure instead of a list of</p>
<blockquote class="last">
<div>differences.</div></blockquote>
</dd>
</dl>
<p>assertSetEqual uses ducktyping to support different types of sets, and
is optimized for sets specifically (parameters must support a
difference method).</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertTrue">
<code class="descname">assertTrue</code><span class="sig-paren">(</span><em>expr</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertTrue" title="Permalink to this definition">¶</a></dt>
<dd><p>Check that the expression is true.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertTupleEqual">
<code class="descname">assertTupleEqual</code><span class="sig-paren">(</span><em>tuple1</em>, <em>tuple2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertTupleEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>A tuple-specific equality assertion.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">tuple1: The first tuple to compare.
tuple2: The second tuple to compare.
msg: Optional message to use on failure instead of a list of</p>
<blockquote class="last">
<div>differences.</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertWarns">
<code class="descname">assertWarns</code><span class="sig-paren">(</span><em>expected_warning</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertWarns" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail unless a warning of class warnClass is triggered
by the callable when invoked with specified positional and
keyword arguments.  If a different type of warning is
triggered, it will not be handled: depending on the other
warning filtering rules in effect, it might be silenced, printed
out, or raised as an exception.</p>
<p>If called with the callable and arguments omitted, will return a
context object used like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertWarns</span><span class="p">(</span><span class="n">SomeWarning</span><span class="p">):</span>
    <span class="n">do_something</span><span class="p">()</span>
</pre></div>
</div>
<p>An optional keyword argument &#8216;msg&#8217; can be provided when assertWarns
is used as a context object.</p>
<p>The context manager keeps a reference to the first matching
warning as the &#8216;warning&#8217; attribute; similarly, the &#8216;filename&#8217;
and &#8216;lineno&#8217; attributes give you information about the line
of Python code from which the warning was triggered.
This allows you to inspect the warning after the assertion:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertWarns</span><span class="p">(</span><span class="n">SomeWarning</span><span class="p">)</span> <span class="k">as</span> <span class="n">cm</span><span class="p">:</span>
    <span class="n">do_something</span><span class="p">()</span>
<span class="n">the_warning</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">warning</span>
<span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">the_warning</span><span class="o">.</span><span class="n">some_attribute</span><span class="p">,</span> <span class="mi">147</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertWarnsRegex">
<code class="descname">assertWarnsRegex</code><span class="sig-paren">(</span><em>expected_warning</em>, <em>expected_regex</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assertWarnsRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Asserts that the message in a triggered warning matches a regexp.
Basic functioning is similar to assertWarns() with the addition
that only warnings whose messages also match the regular expression
are considered successful matches.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">expected_warning: Warning class expected to be triggered.
expected_regex: Regex (re pattern object or string) expected</p>
<blockquote>
<div>to be found in error message.</div></blockquote>
<p>args: Function to be called and extra positional args.
kwargs: Extra kwargs.
msg: Optional message used in case of failure. Can only be used</p>
<blockquote class="last">
<div>when assertWarnsRegex is used as a context manager.</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assert_">
<code class="descname">assert_</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.assert_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.countTestCases">
<code class="descname">countTestCases</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.countTestCases" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.debug">
<code class="descname">debug</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.debug" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the test without collecting errors in a TestResult</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.defaultTestResult">
<code class="descname">defaultTestResult</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.defaultTestResult" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.doCleanups">
<code class="descname">doCleanups</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.doCleanups" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute all cleanup functions. Normally called for you after
tearDown.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.fail">
<code class="descname">fail</code><span class="sig-paren">(</span><em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.fail" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail immediately, with the given message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIf">
<code class="descname">failIf</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIfAlmostEqual">
<code class="descname">failIfAlmostEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIfAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIfEqual">
<code class="descname">failIfEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failIfEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnless">
<code class="descname">failUnless</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnless" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessAlmostEqual">
<code class="descname">failUnlessAlmostEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessEqual">
<code class="descname">failUnlessEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessRaises">
<code class="descname">failUnlessRaises</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failUnlessRaises" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failureException">
<code class="descname">failureException</code><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.failureException" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference external" href="https://docs.python.org/library/exceptions.html#AssertionError" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">AssertionError</span></code></a></p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.get_dataset">
<code class="descname">get_dataset</code><span class="sig-paren">(</span><em>mode='classification'</em>, <em>featurizer='GraphConv'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_graph_models.html#TestGraphModels.get_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.get_dataset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.id">
<code class="descname">id</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.id" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.longMessage">
<code class="descname">longMessage</code><em class="property"> = True</em><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.longMessage" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.maxDiff">
<code class="descname">maxDiff</code><em class="property"> = 640</em><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.maxDiff" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.run">
<code class="descname">run</code><span class="sig-paren">(</span><em>result=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.run" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.setUp">
<code class="descname">setUp</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.setUp" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook method for setting up the test fixture before exercising it.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.setUpClass">
<code class="descname">setUpClass</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.setUpClass" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook method for setting up class fixture before running tests in the class.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.shortDescription">
<code class="descname">shortDescription</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.shortDescription" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a one-line description of the test, or None if no
description has been provided.</p>
<p>The default implementation of this method returns the first line of
the specified test method&#8217;s docstring.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.skipTest">
<code class="descname">skipTest</code><span class="sig-paren">(</span><em>reason</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.skipTest" title="Permalink to this definition">¶</a></dt>
<dd><p>Skip this test.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.subTest">
<code class="descname">subTest</code><span class="sig-paren">(</span><em>msg=&lt;object object&gt;</em>, <em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.subTest" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a context manager that will return the enclosed block
of code in a subtest identified by the optional message and
keyword parameters.  A failure in the subtest marks the test
case as failed but resumes execution at the end of the enclosed
block, allowing further test code to be executed.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.tearDown">
<code class="descname">tearDown</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.tearDown" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook method for deconstructing the test fixture after testing it.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.tearDownClass">
<code class="descname">tearDownClass</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.tearDownClass" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook method for deconstructing the class fixture after running all tests in the class.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_error_bars">
<code class="descname">test_graph_conv_error_bars</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_graph_models.html#TestGraphModels.test_graph_conv_error_bars"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_error_bars" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_model">
<code class="descname">test_graph_conv_model</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_graph_models.html#TestGraphModels.test_graph_conv_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_model" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_regression_model">
<code class="descname">test_graph_conv_regression_model</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_graph_models.html#TestGraphModels.test_graph_conv_regression_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_graph_models.TestGraphModels.test_graph_conv_regression_model" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.test_symmetry_functions">
<span id="deepchem-models-tensorgraph-models-test-symmetry-functions-module"></span><h2>deepchem.models.tensorgraph.models.test_symmetry_functions module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.test_symmetry_functions" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.test_symmetry_functions.</code><code class="descname">TestANIRegression</code><span class="sig-paren">(</span><em>methodName='runTest'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_symmetry_functions.html#TestANIRegression"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">unittest.case.TestCase</span></code></p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><code class="xref py py-obj docutils literal"><span class="pre">__call__</span></code>(*args,&nbsp;**kwds)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.addCleanup" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.addCleanup"><code class="xref py py-obj docutils literal"><span class="pre">addCleanup</span></code></a>(function,&nbsp;*args,&nbsp;**kwargs)</td>
<td>Add a function, with arguments, to be called when the test is completed.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.addTypeEqualityFunc" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.addTypeEqualityFunc"><code class="xref py py-obj docutils literal"><span class="pre">addTypeEqualityFunc</span></code></a>(typeobj,&nbsp;function)</td>
<td>Add a type specific assertEqual style function to compare a type.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertAlmostEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertAlmostEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertAlmostEqual</span></code></a>(first,&nbsp;second[,&nbsp;places,&nbsp;...])</td>
<td>Fail if the two objects are unequal as determined by their difference rounded to the given number of decimal places (default 7) and comparing to zero, or by comparing that the between the two objects is more than the given delta.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertAlmostEquals" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertAlmostEquals"><code class="xref py py-obj docutils literal"><span class="pre">assertAlmostEquals</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertCountEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertCountEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertCountEqual</span></code></a>(first,&nbsp;second[,&nbsp;msg])</td>
<td>An unordered sequence comparison asserting that the same elements, regardless of order.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertDictContainsSubset" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertDictContainsSubset"><code class="xref py py-obj docutils literal"><span class="pre">assertDictContainsSubset</span></code></a>(subset,&nbsp;dictionary)</td>
<td>Checks whether dictionary is a superset of subset.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertDictEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertDictEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertDictEqual</span></code></a>(d1,&nbsp;d2[,&nbsp;msg])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertEqual</span></code></a>(first,&nbsp;second[,&nbsp;msg])</td>
<td>Fail if the two objects are unequal as determined by the &#8216;==&#8217; operator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertEquals" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertEquals"><code class="xref py py-obj docutils literal"><span class="pre">assertEquals</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertFalse" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertFalse"><code class="xref py py-obj docutils literal"><span class="pre">assertFalse</span></code></a>(expr[,&nbsp;msg])</td>
<td>Check that the expression is false.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertGreater" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertGreater"><code class="xref py py-obj docutils literal"><span class="pre">assertGreater</span></code></a>(a,&nbsp;b[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a &gt; b), but with a nicer default message.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertGreaterEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertGreaterEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertGreaterEqual</span></code></a>(a,&nbsp;b[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a &gt;= b), but with a nicer default message.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIn" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIn"><code class="xref py py-obj docutils literal"><span class="pre">assertIn</span></code></a>(member,&nbsp;container[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a in b), but with a nicer default message.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIs" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIs"><code class="xref py py-obj docutils literal"><span class="pre">assertIs</span></code></a>(expr1,&nbsp;expr2[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a is b), but with a nicer default message.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsInstance" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsInstance"><code class="xref py py-obj docutils literal"><span class="pre">assertIsInstance</span></code></a>(obj,&nbsp;cls[,&nbsp;msg])</td>
<td>Same as self.assertTrue(isinstance(obj, cls)), with a nicer default message.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNone" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNone"><code class="xref py py-obj docutils literal"><span class="pre">assertIsNone</span></code></a>(obj[,&nbsp;msg])</td>
<td>Same as self.assertTrue(obj is None), with a nicer default message.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNot" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNot"><code class="xref py py-obj docutils literal"><span class="pre">assertIsNot</span></code></a>(expr1,&nbsp;expr2[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a is not b), but with a nicer default message.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNotNone" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNotNone"><code class="xref py py-obj docutils literal"><span class="pre">assertIsNotNone</span></code></a>(obj[,&nbsp;msg])</td>
<td>Included for symmetry with assertIsNone.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLess" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLess"><code class="xref py py-obj docutils literal"><span class="pre">assertLess</span></code></a>(a,&nbsp;b[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a &lt; b), but with a nicer default message.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLessEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLessEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertLessEqual</span></code></a>(a,&nbsp;b[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a &lt;= b), but with a nicer default message.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertListEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertListEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertListEqual</span></code></a>(list1,&nbsp;list2[,&nbsp;msg])</td>
<td>A list-specific equality assertion.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLogs" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLogs"><code class="xref py py-obj docutils literal"><span class="pre">assertLogs</span></code></a>([logger,&nbsp;level])</td>
<td>Fail unless a log message of level <em>level</em> or higher is emitted on <em>logger_name</em> or its children.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertMultiLineEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertMultiLineEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertMultiLineEqual</span></code></a>(first,&nbsp;second[,&nbsp;msg])</td>
<td>Assert that two multi-line strings are equal.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotAlmostEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotAlmostEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertNotAlmostEqual</span></code></a>(first,&nbsp;second[,&nbsp;...])</td>
<td>Fail if the two objects are equal as determined by their difference rounded to the given number of decimal places (default 7) and comparing to zero, or by comparing that the between the two objects is less than the given delta.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotAlmostEquals" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotAlmostEquals"><code class="xref py py-obj docutils literal"><span class="pre">assertNotAlmostEquals</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertNotEqual</span></code></a>(first,&nbsp;second[,&nbsp;msg])</td>
<td>Fail if the two objects are equal as determined by the &#8216;!=&#8217; operator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotEquals" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotEquals"><code class="xref py py-obj docutils literal"><span class="pre">assertNotEquals</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotIn" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotIn"><code class="xref py py-obj docutils literal"><span class="pre">assertNotIn</span></code></a>(member,&nbsp;container[,&nbsp;msg])</td>
<td>Just like self.assertTrue(a not in b), but with a nicer default message.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotIsInstance" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotIsInstance"><code class="xref py py-obj docutils literal"><span class="pre">assertNotIsInstance</span></code></a>(obj,&nbsp;cls[,&nbsp;msg])</td>
<td>Included for symmetry with assertIsInstance.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotRegex" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotRegex"><code class="xref py py-obj docutils literal"><span class="pre">assertNotRegex</span></code></a>(text,&nbsp;unexpected_regex[,&nbsp;msg])</td>
<td>Fail the test if the text matches the regular expression.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotRegexpMatches" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotRegexpMatches"><code class="xref py py-obj docutils literal"><span class="pre">assertNotRegexpMatches</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaises" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaises"><code class="xref py py-obj docutils literal"><span class="pre">assertRaises</span></code></a>(expected_exception,&nbsp;*args,&nbsp;**kwargs)</td>
<td>Fail unless an exception of class expected_exception is raised by the callable when invoked with specified positional and keyword arguments.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaisesRegex" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaisesRegex"><code class="xref py py-obj docutils literal"><span class="pre">assertRaisesRegex</span></code></a>(expected_exception,&nbsp;...)</td>
<td>Asserts that the message in a raised exception matches a regex.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaisesRegexp" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaisesRegexp"><code class="xref py py-obj docutils literal"><span class="pre">assertRaisesRegexp</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRegex" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRegex"><code class="xref py py-obj docutils literal"><span class="pre">assertRegex</span></code></a>(text,&nbsp;expected_regex[,&nbsp;msg])</td>
<td>Fail the test unless the text matches the regular expression.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRegexpMatches" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRegexpMatches"><code class="xref py py-obj docutils literal"><span class="pre">assertRegexpMatches</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertSequenceEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertSequenceEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertSequenceEqual</span></code></a>(seq1,&nbsp;seq2[,&nbsp;msg,&nbsp;seq_type])</td>
<td>An equality assertion for ordered sequences (like lists and tuples).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertSetEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertSetEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertSetEqual</span></code></a>(set1,&nbsp;set2[,&nbsp;msg])</td>
<td>A set-specific equality assertion.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertTrue" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertTrue"><code class="xref py py-obj docutils literal"><span class="pre">assertTrue</span></code></a>(expr[,&nbsp;msg])</td>
<td>Check that the expression is true.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertTupleEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertTupleEqual"><code class="xref py py-obj docutils literal"><span class="pre">assertTupleEqual</span></code></a>(tuple1,&nbsp;tuple2[,&nbsp;msg])</td>
<td>A tuple-specific equality assertion.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertWarns" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertWarns"><code class="xref py py-obj docutils literal"><span class="pre">assertWarns</span></code></a>(expected_warning,&nbsp;*args,&nbsp;**kwargs)</td>
<td>Fail unless a warning of class warnClass is triggered by the callable when invoked with specified positional and keyword arguments.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertWarnsRegex" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertWarnsRegex"><code class="xref py py-obj docutils literal"><span class="pre">assertWarnsRegex</span></code></a>(expected_warning,&nbsp;...)</td>
<td>Asserts that the message in a triggered warning matches a regexp.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assert_" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assert_"><code class="xref py py-obj docutils literal"><span class="pre">assert_</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.countTestCases" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.countTestCases"><code class="xref py py-obj docutils literal"><span class="pre">countTestCases</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.debug" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.debug"><code class="xref py py-obj docutils literal"><span class="pre">debug</span></code></a>()</td>
<td>Run the test without collecting errors in a TestResult</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.defaultTestResult" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.defaultTestResult"><code class="xref py py-obj docutils literal"><span class="pre">defaultTestResult</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.doCleanups" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.doCleanups"><code class="xref py py-obj docutils literal"><span class="pre">doCleanups</span></code></a>()</td>
<td>Execute all cleanup functions.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.fail" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.fail"><code class="xref py py-obj docutils literal"><span class="pre">fail</span></code></a>([msg])</td>
<td>Fail immediately, with the given message.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIf" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIf"><code class="xref py py-obj docutils literal"><span class="pre">failIf</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIfAlmostEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIfAlmostEqual"><code class="xref py py-obj docutils literal"><span class="pre">failIfAlmostEqual</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIfEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIfEqual"><code class="xref py py-obj docutils literal"><span class="pre">failIfEqual</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnless" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnless"><code class="xref py py-obj docutils literal"><span class="pre">failUnless</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessAlmostEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessAlmostEqual"><code class="xref py py-obj docutils literal"><span class="pre">failUnlessAlmostEqual</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessEqual" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessEqual"><code class="xref py py-obj docutils literal"><span class="pre">failUnlessEqual</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessRaises" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessRaises"><code class="xref py py-obj docutils literal"><span class="pre">failUnlessRaises</span></code></a>(*args,&nbsp;**kwargs)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failureException" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failureException"><code class="xref py py-obj docutils literal"><span class="pre">failureException</span></code></a></td>
<td>alias of <a class="reference external" href="https://docs.python.org/library/exceptions.html#AssertionError" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">AssertionError</span></code></a></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.id" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.id"><code class="xref py py-obj docutils literal"><span class="pre">id</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.run" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.run"><code class="xref py py-obj docutils literal"><span class="pre">run</span></code></a>([result])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.setUp" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.setUp"><code class="xref py py-obj docutils literal"><span class="pre">setUp</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.setUpClass" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.setUpClass"><code class="xref py py-obj docutils literal"><span class="pre">setUpClass</span></code></a>()</td>
<td>Hook method for setting up class fixture before running tests in the class.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.shortDescription" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.shortDescription"><code class="xref py py-obj docutils literal"><span class="pre">shortDescription</span></code></a>()</td>
<td>Returns a one-line description of the test, or None if no description has been provided.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.skipTest" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.skipTest"><code class="xref py py-obj docutils literal"><span class="pre">skipTest</span></code></a>(reason)</td>
<td>Skip this test.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.subTest" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.subTest"><code class="xref py py-obj docutils literal"><span class="pre">subTest</span></code></a>([msg])</td>
<td>Return a context manager that will return the enclosed block of code in a subtest identified by the optional message and keyword parameters.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.tearDown" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.tearDown"><code class="xref py py-obj docutils literal"><span class="pre">tearDown</span></code></a>()</td>
<td>Hook method for deconstructing the test fixture after testing it.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.tearDownClass" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.tearDownClass"><code class="xref py py-obj docutils literal"><span class="pre">tearDownClass</span></code></a>()</td>
<td>Hook method for deconstructing the class fixture after running all tests in the class.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.test_gradients" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.test_gradients"><code class="xref py py-obj docutils literal"><span class="pre">test_gradients</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.test_numpy_save_load" title="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.test_numpy_save_load"><code class="xref py py-obj docutils literal"><span class="pre">test_numpy_save_load</span></code></a>()</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.addCleanup">
<code class="descname">addCleanup</code><span class="sig-paren">(</span><em>function</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.addCleanup" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a function, with arguments, to be called when the test is
completed. Functions added are called on a LIFO basis and are
called after tearDown on test failure or success.</p>
<p>Cleanup items are called even if setUp fails (unlike tearDown).</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.addTypeEqualityFunc">
<code class="descname">addTypeEqualityFunc</code><span class="sig-paren">(</span><em>typeobj</em>, <em>function</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.addTypeEqualityFunc" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a type specific assertEqual style function to compare a type.</p>
<p>This method is for use by TestCase subclasses that need to register
their own type equality functions to provide nicer error messages.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first last docutils">
<dt>typeobj: The data type to call this function on when both values</dt>
<dd>are of the same type in assertEqual().</dd>
<dt>function: The callable taking two arguments and an optional</dt>
<dd>msg= argument that raises self.failureException with a
useful error message when the two arguments are not equal.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertAlmostEqual">
<code class="descname">assertAlmostEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>places=None</em>, <em>msg=None</em>, <em>delta=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are unequal as determined by their
difference rounded to the given number of decimal places
(default 7) and comparing to zero, or by comparing that the
between the two objects is more than the given delta.</p>
<p>Note that decimal places (from zero) are usually not the same
as significant digits (measured from the most significant digit).</p>
<p>If the two objects compare equal then they will automatically
compare almost equal.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertAlmostEquals">
<code class="descname">assertAlmostEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertAlmostEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertCountEqual">
<code class="descname">assertCountEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertCountEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>An unordered sequence comparison asserting that the same elements,
regardless of order.  If the same element occurs more than once,
it verifies that the elements occur the same number of times.</p>
<blockquote>
<div><blockquote>
<div><dl class="docutils">
<dt>self.assertEqual(Counter(list(first)),</dt>
<dd>Counter(list(second)))</dd>
</dl>
</div></blockquote>
<dl class="docutils">
<dt>Example:</dt>
<dd><ul class="first last simple">
<li>[0, 1, 1] and [1, 0, 1] compare equal.</li>
<li>[0, 0, 1] and [0, 1] compare unequal.</li>
</ul>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertDictContainsSubset">
<code class="descname">assertDictContainsSubset</code><span class="sig-paren">(</span><em>subset</em>, <em>dictionary</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertDictContainsSubset" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks whether dictionary is a superset of subset.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertDictEqual">
<code class="descname">assertDictEqual</code><span class="sig-paren">(</span><em>d1</em>, <em>d2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertDictEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertEqual">
<code class="descname">assertEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are unequal as determined by the &#8216;==&#8217;
operator.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertEquals">
<code class="descname">assertEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertFalse">
<code class="descname">assertFalse</code><span class="sig-paren">(</span><em>expr</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertFalse" title="Permalink to this definition">¶</a></dt>
<dd><p>Check that the expression is false.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertGreater">
<code class="descname">assertGreater</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertGreater" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &gt; b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertGreaterEqual">
<code class="descname">assertGreaterEqual</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertGreaterEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &gt;= b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIn">
<code class="descname">assertIn</code><span class="sig-paren">(</span><em>member</em>, <em>container</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIn" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a in b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIs">
<code class="descname">assertIs</code><span class="sig-paren">(</span><em>expr1</em>, <em>expr2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIs" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a is b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsInstance">
<code class="descname">assertIsInstance</code><span class="sig-paren">(</span><em>obj</em>, <em>cls</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsInstance" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as self.assertTrue(isinstance(obj, cls)), with a nicer
default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNone">
<code class="descname">assertIsNone</code><span class="sig-paren">(</span><em>obj</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNone" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as self.assertTrue(obj is None), with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNot">
<code class="descname">assertIsNot</code><span class="sig-paren">(</span><em>expr1</em>, <em>expr2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNot" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a is not b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNotNone">
<code class="descname">assertIsNotNone</code><span class="sig-paren">(</span><em>obj</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertIsNotNone" title="Permalink to this definition">¶</a></dt>
<dd><p>Included for symmetry with assertIsNone.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLess">
<code class="descname">assertLess</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLess" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &lt; b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLessEqual">
<code class="descname">assertLessEqual</code><span class="sig-paren">(</span><em>a</em>, <em>b</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLessEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a &lt;= b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertListEqual">
<code class="descname">assertListEqual</code><span class="sig-paren">(</span><em>list1</em>, <em>list2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertListEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>A list-specific equality assertion.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">list1: The first list to compare.
list2: The second list to compare.
msg: Optional message to use on failure instead of a list of</p>
<blockquote class="last">
<div>differences.</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLogs">
<code class="descname">assertLogs</code><span class="sig-paren">(</span><em>logger=None</em>, <em>level=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertLogs" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail unless a log message of level <em>level</em> or higher is emitted
on <em>logger_name</em> or its children.  If omitted, <em>level</em> defaults to
INFO and <em>logger</em> defaults to the root logger.</p>
<p>This method must be used as a context manager, and will yield
a recording object with two attributes: <cite>output</cite> and <cite>records</cite>.
At the end of the context manager, the <cite>output</cite> attribute will
be a list of the matching formatted log messages and the
<cite>records</cite> attribute will be a list of the corresponding LogRecord
objects.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertLogs</span><span class="p">(</span><span class="s1">&#39;foo&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="s1">&#39;INFO&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">cm</span><span class="p">:</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;foo&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;first message&#39;</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;foo.bar&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s1">&#39;second message&#39;</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;INFO:foo:first message&#39;</span><span class="p">,</span>
                             <span class="s1">&#39;ERROR:foo.bar:second message&#39;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertMultiLineEqual">
<code class="descname">assertMultiLineEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertMultiLineEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Assert that two multi-line strings are equal.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotAlmostEqual">
<code class="descname">assertNotAlmostEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>places=None</em>, <em>msg=None</em>, <em>delta=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are equal as determined by their
difference rounded to the given number of decimal places
(default 7) and comparing to zero, or by comparing that the
between the two objects is less than the given delta.</p>
<p>Note that decimal places (from zero) are usually not the same
as significant digits (measured from the most significant digit).</p>
<p>Objects that are equal automatically fail.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotAlmostEquals">
<code class="descname">assertNotAlmostEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotAlmostEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotEqual">
<code class="descname">assertNotEqual</code><span class="sig-paren">(</span><em>first</em>, <em>second</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail if the two objects are equal as determined by the &#8216;!=&#8217;
operator.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotEquals">
<code class="descname">assertNotEquals</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotEquals" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotIn">
<code class="descname">assertNotIn</code><span class="sig-paren">(</span><em>member</em>, <em>container</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotIn" title="Permalink to this definition">¶</a></dt>
<dd><p>Just like self.assertTrue(a not in b), but with a nicer default message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotIsInstance">
<code class="descname">assertNotIsInstance</code><span class="sig-paren">(</span><em>obj</em>, <em>cls</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotIsInstance" title="Permalink to this definition">¶</a></dt>
<dd><p>Included for symmetry with assertIsInstance.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotRegex">
<code class="descname">assertNotRegex</code><span class="sig-paren">(</span><em>text</em>, <em>unexpected_regex</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail the test if the text matches the regular expression.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotRegexpMatches">
<code class="descname">assertNotRegexpMatches</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertNotRegexpMatches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaises">
<code class="descname">assertRaises</code><span class="sig-paren">(</span><em>expected_exception</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaises" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail unless an exception of class expected_exception is raised
by the callable when invoked with specified positional and
keyword arguments. If a different type of exception is
raised, it will not be caught, and the test case will be
deemed to have suffered an error, exactly as for an
unexpected exception.</p>
<p>If called with the callable and arguments omitted, will return a
context object used like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertRaises</span><span class="p">(</span><span class="n">SomeException</span><span class="p">):</span>
    <span class="n">do_something</span><span class="p">()</span>
</pre></div>
</div>
<p>An optional keyword argument &#8216;msg&#8217; can be provided when assertRaises
is used as a context object.</p>
<p>The context manager keeps a reference to the exception as
the &#8216;exception&#8217; attribute. This allows you to inspect the
exception after the assertion:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertRaises</span><span class="p">(</span><span class="n">SomeException</span><span class="p">)</span> <span class="k">as</span> <span class="n">cm</span><span class="p">:</span>
    <span class="n">do_something</span><span class="p">()</span>
<span class="n">the_exception</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">exception</span>
<span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">the_exception</span><span class="o">.</span><span class="n">error_code</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaisesRegex">
<code class="descname">assertRaisesRegex</code><span class="sig-paren">(</span><em>expected_exception</em>, <em>expected_regex</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaisesRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Asserts that the message in a raised exception matches a regex.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">expected_exception: Exception class expected to be raised.
expected_regex: Regex (re pattern object or string) expected</p>
<blockquote>
<div>to be found in error message.</div></blockquote>
<p>args: Function to be called and extra positional args.
kwargs: Extra kwargs.
msg: Optional message used in case of failure. Can only be used</p>
<blockquote class="last">
<div>when assertRaisesRegex is used as a context manager.</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaisesRegexp">
<code class="descname">assertRaisesRegexp</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRaisesRegexp" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRegex">
<code class="descname">assertRegex</code><span class="sig-paren">(</span><em>text</em>, <em>expected_regex</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail the test unless the text matches the regular expression.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRegexpMatches">
<code class="descname">assertRegexpMatches</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertRegexpMatches" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertSequenceEqual">
<code class="descname">assertSequenceEqual</code><span class="sig-paren">(</span><em>seq1</em>, <em>seq2</em>, <em>msg=None</em>, <em>seq_type=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertSequenceEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>An equality assertion for ordered sequences (like lists and tuples).</p>
<p>For the purposes of this function, a valid ordered sequence type is one
which can be indexed, has a length, and has an equality operator.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">seq1: The first sequence to compare.
seq2: The second sequence to compare.
seq_type: The expected datatype of the sequences, or None if no</p>
<blockquote>
<div>datatype should be enforced.</div></blockquote>
<dl class="last docutils">
<dt>msg: Optional message to use on failure instead of a list of</dt>
<dd>differences.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertSetEqual">
<code class="descname">assertSetEqual</code><span class="sig-paren">(</span><em>set1</em>, <em>set2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertSetEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>A set-specific equality assertion.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">set1: The first set to compare.
set2: The second set to compare.
msg: Optional message to use on failure instead of a list of</p>
<blockquote class="last">
<div>differences.</div></blockquote>
</dd>
</dl>
<p>assertSetEqual uses ducktyping to support different types of sets, and
is optimized for sets specifically (parameters must support a
difference method).</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertTrue">
<code class="descname">assertTrue</code><span class="sig-paren">(</span><em>expr</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertTrue" title="Permalink to this definition">¶</a></dt>
<dd><p>Check that the expression is true.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertTupleEqual">
<code class="descname">assertTupleEqual</code><span class="sig-paren">(</span><em>tuple1</em>, <em>tuple2</em>, <em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertTupleEqual" title="Permalink to this definition">¶</a></dt>
<dd><p>A tuple-specific equality assertion.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">tuple1: The first tuple to compare.
tuple2: The second tuple to compare.
msg: Optional message to use on failure instead of a list of</p>
<blockquote class="last">
<div>differences.</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertWarns">
<code class="descname">assertWarns</code><span class="sig-paren">(</span><em>expected_warning</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertWarns" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail unless a warning of class warnClass is triggered
by the callable when invoked with specified positional and
keyword arguments.  If a different type of warning is
triggered, it will not be handled: depending on the other
warning filtering rules in effect, it might be silenced, printed
out, or raised as an exception.</p>
<p>If called with the callable and arguments omitted, will return a
context object used like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertWarns</span><span class="p">(</span><span class="n">SomeWarning</span><span class="p">):</span>
    <span class="n">do_something</span><span class="p">()</span>
</pre></div>
</div>
<p>An optional keyword argument &#8216;msg&#8217; can be provided when assertWarns
is used as a context object.</p>
<p>The context manager keeps a reference to the first matching
warning as the &#8216;warning&#8217; attribute; similarly, the &#8216;filename&#8217;
and &#8216;lineno&#8217; attributes give you information about the line
of Python code from which the warning was triggered.
This allows you to inspect the warning after the assertion:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertWarns</span><span class="p">(</span><span class="n">SomeWarning</span><span class="p">)</span> <span class="k">as</span> <span class="n">cm</span><span class="p">:</span>
    <span class="n">do_something</span><span class="p">()</span>
<span class="n">the_warning</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">warning</span>
<span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">the_warning</span><span class="o">.</span><span class="n">some_attribute</span><span class="p">,</span> <span class="mi">147</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertWarnsRegex">
<code class="descname">assertWarnsRegex</code><span class="sig-paren">(</span><em>expected_warning</em>, <em>expected_regex</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assertWarnsRegex" title="Permalink to this definition">¶</a></dt>
<dd><p>Asserts that the message in a triggered warning matches a regexp.
Basic functioning is similar to assertWarns() with the addition
that only warnings whose messages also match the regular expression
are considered successful matches.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">expected_warning: Warning class expected to be triggered.
expected_regex: Regex (re pattern object or string) expected</p>
<blockquote>
<div>to be found in error message.</div></blockquote>
<p>args: Function to be called and extra positional args.
kwargs: Extra kwargs.
msg: Optional message used in case of failure. Can only be used</p>
<blockquote class="last">
<div>when assertWarnsRegex is used as a context manager.</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assert_">
<code class="descname">assert_</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.assert_" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.countTestCases">
<code class="descname">countTestCases</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.countTestCases" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.debug">
<code class="descname">debug</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.debug" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the test without collecting errors in a TestResult</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.defaultTestResult">
<code class="descname">defaultTestResult</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.defaultTestResult" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.doCleanups">
<code class="descname">doCleanups</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.doCleanups" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute all cleanup functions. Normally called for you after
tearDown.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.fail">
<code class="descname">fail</code><span class="sig-paren">(</span><em>msg=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.fail" title="Permalink to this definition">¶</a></dt>
<dd><p>Fail immediately, with the given message.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIf">
<code class="descname">failIf</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIfAlmostEqual">
<code class="descname">failIfAlmostEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIfAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIfEqual">
<code class="descname">failIfEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failIfEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnless">
<code class="descname">failUnless</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnless" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessAlmostEqual">
<code class="descname">failUnlessAlmostEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessAlmostEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessEqual">
<code class="descname">failUnlessEqual</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessEqual" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessRaises">
<code class="descname">failUnlessRaises</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failUnlessRaises" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failureException">
<code class="descname">failureException</code><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.failureException" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference external" href="https://docs.python.org/library/exceptions.html#AssertionError" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">AssertionError</span></code></a></p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.id">
<code class="descname">id</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.id" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.longMessage">
<code class="descname">longMessage</code><em class="property"> = True</em><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.longMessage" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.maxDiff">
<code class="descname">maxDiff</code><em class="property"> = 640</em><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.maxDiff" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.run">
<code class="descname">run</code><span class="sig-paren">(</span><em>result=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.run" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.setUp">
<code class="descname">setUp</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_symmetry_functions.html#TestANIRegression.setUp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.setUp" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.setUpClass">
<code class="descname">setUpClass</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.setUpClass" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook method for setting up class fixture before running tests in the class.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.shortDescription">
<code class="descname">shortDescription</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.shortDescription" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a one-line description of the test, or None if no
description has been provided.</p>
<p>The default implementation of this method returns the first line of
the specified test method&#8217;s docstring.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.skipTest">
<code class="descname">skipTest</code><span class="sig-paren">(</span><em>reason</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.skipTest" title="Permalink to this definition">¶</a></dt>
<dd><p>Skip this test.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.subTest">
<code class="descname">subTest</code><span class="sig-paren">(</span><em>msg=&lt;object object&gt;</em>, <em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.subTest" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a context manager that will return the enclosed block
of code in a subtest identified by the optional message and
keyword parameters.  A failure in the subtest marks the test
case as failed but resumes execution at the end of the enclosed
block, allowing further test code to be executed.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.tearDown">
<code class="descname">tearDown</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.tearDown" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook method for deconstructing the test fixture after testing it.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.tearDownClass">
<code class="descname">tearDownClass</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.tearDownClass" title="Permalink to this definition">¶</a></dt>
<dd><p>Hook method for deconstructing the class fixture after running all tests in the class.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.test_gradients">
<code class="descname">test_gradients</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_symmetry_functions.html#TestANIRegression.test_gradients"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.test_gradients" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.test_numpy_save_load">
<code class="descname">test_numpy_save_load</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/test_symmetry_functions.html#TestANIRegression.test_numpy_save_load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.test_symmetry_functions.TestANIRegression.test_numpy_save_load" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models.text_cnn">
<span id="deepchem-models-tensorgraph-models-text-cnn-module"></span><h2>deepchem.models.tensorgraph.models.text_cnn module<a class="headerlink" href="#module-deepchem.models.tensorgraph.models.text_cnn" title="Permalink to this headline">¶</a></h2>
<p>Created on Thu Sep 28 15:17:50 2017</p>
<p>&#64;author: zqwu</p>
<dl class="class">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph">
<em class="property">class </em><code class="descclassname">deepchem.models.tensorgraph.models.text_cnn.</code><code class="descname">TextCNNTensorGraph</code><span class="sig-paren">(</span><em>n_tasks, char_dict, seq_length, n_embedding=75, filter_sizes=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20], num_filters=[100, 200, 200, 200, 200, 100, 100, 100, 100, 100, 160, 160], dropout=0.25, mode='classification', **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/text_cnn.html#TextCNNTensorGraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.tensor_graph.TensorGraph</span></code></a></p>
<p>A Convolutional neural network on smiles strings
Reimplementation of the discriminator module in ORGAN: <a class="reference external" href="https://arxiv.org/abs/1705.10843">https://arxiv.org/abs/1705.10843</a>
Originated from: <a class="reference external" href="http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf">http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf</a></p>
<p>This model applies multiple 1D convolutional filters to the padded strings,
then max-over-time pooling is applied on all filters, extracting one feature per filter.
All features are concatenated and transformed through several hidden layers to form predictions.</p>
<p>This model is initially developed for sentence-level classification tasks, with
words represented as vectors. In this implementation, SMILES strings are dissected
into characters and transformed to one-hot vectors in a similar way. The model can
be used for general molecular-level classification or regression tasks. It is also
used in the ORGAN model as discriminator.</p>
<p>Training of the model only requires SMILES strings input, all featurized datasets
that include SMILES in the <cite>ids</cite> attribute are accepted. PDBbind, QM7 and QM7b 
are not supported. To use the model, <cite>build_char_dict</cite> should be called first
before defining the model to build character dict of input dataset, example can
be found in examples/delaney/delaney_textcnn.py</p>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.add_output" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.add_output"><code class="xref py py-obj docutils literal"><span class="pre">add_output</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build"><code class="xref py py-obj docutils literal"><span class="pre">build</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build_char_dict" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build_char_dict"><code class="xref py py-obj docutils literal"><span class="pre">build_char_dict</span></code></a>(dataset[,&nbsp;default_dict])</td>
<td>Collect all unique characters(in smiles) from the dataset.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build_graph" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build_graph"><code class="xref py py-obj docutils literal"><span class="pre">build_graph</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.create_submodel" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.create_submodel"><code class="xref py py-obj docutils literal"><span class="pre">create_submodel</span></code></a>([layers,&nbsp;loss,&nbsp;optimizer])</td>
<td>Create an alternate objective for training one piece of a TensorGraph.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.default_generator" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.default_generator"><code class="xref py py-obj docutils literal"><span class="pre">default_generator</span></code></a>(dataset[,&nbsp;epochs,&nbsp;...])</td>
<td>Transfer smiles strings to fixed length integer vectors</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.evaluate" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.evaluate"><code class="xref py py-obj docutils literal"><span class="pre">evaluate</span></code></a>(dataset,&nbsp;metrics[,&nbsp;transformers,&nbsp;...])</td>
<td>Evaluates the performance of this model on specified dataset.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.evaluate_generator" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.evaluate_generator"><code class="xref py py-obj docutils literal"><span class="pre">evaluate_generator</span></code></a>(feed_dict_generator,&nbsp;metrics)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(dataset[,&nbsp;nb_epoch,&nbsp;...])</td>
<td>Train this model on a dataset.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit_generator" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit_generator"><code class="xref py py-obj docutils literal"><span class="pre">fit_generator</span></code></a>(feed_dict_generator[,&nbsp;...])</td>
<td>Train this model on data from a generator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit_on_batch" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">fit_on_batch</span></code></a>(X,&nbsp;y,&nbsp;w[,&nbsp;submodel])</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_global_step" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_global_step"><code class="xref py py-obj docutils literal"><span class="pre">get_global_step</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_layer_variables" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_layer_variables"><code class="xref py py-obj docutils literal"><span class="pre">get_layer_variables</span></code></a>(layer)</td>
<td>Get the list of trainable variables in a layer of the graph.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_model_filename" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_model_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_model_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_num_tasks" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_num_tasks"><code class="xref py py-obj docutils literal"><span class="pre">get_num_tasks</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_params" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_params"><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_params_filename" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_params_filename"><code class="xref py py-obj docutils literal"><span class="pre">get_params_filename</span></code></a>(model_dir)</td>
<td>Given model directory, obtain filename for the model itself.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_pickling_errors" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_pickling_errors"><code class="xref py py-obj docutils literal"><span class="pre">get_pickling_errors</span></code></a>(obj[,&nbsp;seen])</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_pre_q_input" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_pre_q_input"><code class="xref py py-obj docutils literal"><span class="pre">get_pre_q_input</span></code></a>(input_layer)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_task_type" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_task_type"><code class="xref py py-obj docutils literal"><span class="pre">get_task_type</span></code></a>()</td>
<td>Currently models can only be classifiers or regressors.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.load_from_dir" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.load_from_dir"><code class="xref py py-obj docutils literal"><span class="pre">load_from_dir</span></code></a>(model_dir)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Uses self to make predictions on provided Dataset object.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_on_batch" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;outputs])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_on_generator" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></code></a>(dataset[,&nbsp;transformers,&nbsp;outputs])</td>
<td><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba_on_batch" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba_on_batch"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_batch</span></code></a>(X[,&nbsp;transformers,&nbsp;...])</td>
<td>Generates predictions for input samples, processing samples in a batch.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba_on_generator" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba_on_generator"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba_on_generator</span></code></a>(generator[,&nbsp;...])</td>
<td>Returns:</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.reload" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.reload"><code class="xref py py-obj docutils literal"><span class="pre">reload</span></code></a>()</td>
<td>Reload trained model from disk.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.restore" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.restore"><code class="xref py py-obj docutils literal"><span class="pre">restore</span></code></a>()</td>
<td>Reload the values of all variables from the most recent checkpoint file.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.save" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.save"><code class="xref py py-obj docutils literal"><span class="pre">save</span></code></a>()</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.save_checkpoint" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.save_checkpoint"><code class="xref py py-obj docutils literal"><span class="pre">save_checkpoint</span></code></a>([max_checkpoints_to_keep])</td>
<td>Save a checkpoint to disk.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_loss" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_loss"><code class="xref py py-obj docutils literal"><span class="pre">set_loss</span></code></a>(layer)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_optimizer" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_optimizer"><code class="xref py py-obj docutils literal"><span class="pre">set_optimizer</span></code></a>(optimizer)</td>
<td>Set the optimizer to use for fitting.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_params" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_params"><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code></a>(**params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.smiles_to_seq" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.smiles_to_seq"><code class="xref py py-obj docutils literal"><span class="pre">smiles_to_seq</span></code></a>(smiles)</td>
<td>Tokenize characters in smiles to integers</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.topsort" title="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.topsort"><code class="xref py py-obj docutils literal"><span class="pre">topsort</span></code></a>()</td>
<td></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.add_output">
<code class="descname">add_output</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.add_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build">
<code class="descname">build</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build_char_dict">
<em class="property">static </em><code class="descname">build_char_dict</code><span class="sig-paren">(</span><em>dataset</em>, <em>default_dict={'3': 9</em>, <em>'5': 11</em>, <em>'2': 8</em>, <em>'N': 20</em>, <em>'S': 23</em>, <em>'Cl': 29</em>, <em>'n': 31</em>, <em>'1': 7</em>, <em>'c': 28</em>, <em>'s': 33</em>, <em>'+': 4</em>, <em>'8': 14</em>, <em>'-': 5</em>, <em>'\\': 25</em>, <em>'/': 6</em>, <em>']': 26</em>, <em>'Br': 30</em>, <em>'I': 19</em>, <em>'_': 27</em>, <em>'H': 18</em>, <em>'#': 1</em>, <em>'7': 13</em>, <em>'C': 16</em>, <em>'[': 24</em>, <em>'O': 21</em>, <em>')': 3</em>, <em>'=': 15</em>, <em>'6': 12</em>, <em>'F': 17</em>, <em>'P': 22</em>, <em>'o': 32</em>, <em>'4': 10</em>, <em>'(': 2}</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/text_cnn.html#TextCNNTensorGraph.build_char_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build_char_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect all unique characters(in smiles) from the dataset.
This method should be called before defining the model to build appropriate char_dict</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build_graph">
<code class="descname">build_graph</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/text_cnn.html#TextCNNTensorGraph.build_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.build_graph" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.create_submodel">
<code class="descname">create_submodel</code><span class="sig-paren">(</span><em>layers=None</em>, <em>loss=None</em>, <em>optimizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.create_submodel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an alternate objective for training one piece of a TensorGraph.</p>
<p>A TensorGraph consists of a set of layers, and specifies a loss function and
optimizer to use for training those layers.  Usually this is sufficient, but
there are cases where you want to train different parts of a model separately.
For example, a GAN consists of a generator and a discriminator.  They are
trained separately, and they use different loss functions.</p>
<p>A submodel defines an alternate objective to use in cases like this.  It may
optionally specify any of the following: a subset of layers in the model to
train; a different loss function; and a different optimizer to use.  This
method creates a submodel, which you can then pass to fit() to use it for
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>layers: list</strong></p>
<blockquote>
<div><p>the list of layers to train.  If None, all layers in the model will be
trained.</p>
</div></blockquote>
<p><strong>loss: Layer</strong></p>
<blockquote>
<div><p>the loss function to optimize.  If None, the model&#8217;s main loss function
will be used.</p>
</div></blockquote>
<p><strong>optimizer: Optimizer</strong></p>
<blockquote>
<div><p>the optimizer to use for training.  If None, the model&#8217;s main optimizer
will be used.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the newly created submodel, which can be passed to any of the fitting</p>
<p class="last">methods.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.default_generator">
<code class="descname">default_generator</code><span class="sig-paren">(</span><em>dataset</em>, <em>epochs=1</em>, <em>predict=False</em>, <em>deterministic=True</em>, <em>pad_batches=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/text_cnn.html#TextCNNTensorGraph.default_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.default_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Transfer smiles strings to fixed length integer vectors</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>dataset</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the performance of this model on specified dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset object.</p>
</div></blockquote>
<p><strong>metric: deepchem.metrics.Metric</strong></p>
<blockquote>
<div><p>Evaluation metric</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of deepchem.transformers.Transformer</p>
</div></blockquote>
<p><strong>per_task_metrics: bool</strong></p>
<blockquote>
<div><p>If True, return per-task scores.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">dict</p>
<blockquote class="last">
<div><p>Maps tasks to scores under metric.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.evaluate_generator">
<code class="descname">evaluate_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>metrics</em>, <em>transformers=[]</em>, <em>labels=None</em>, <em>outputs=None</em>, <em>weights=[]</em>, <em>per_task_metrics=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.evaluate_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>dataset</em>, <em>nb_epoch=10</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>deterministic=False</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on a dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: Dataset</strong></p>
<blockquote>
<div><p>the Dataset to train on</p>
</div></blockquote>
<p><strong>nb_epoch: int</strong></p>
<blockquote>
<div><p>the number of epochs to train for</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>deterministic: bool</strong></p>
<blockquote>
<div><p>if True, the samples are processed in order.  If False, a different random
order is used for each epoch.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote class="last">
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit_generator">
<code class="descname">fit_generator</code><span class="sig-paren">(</span><em>feed_dict_generator</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=1000</em>, <em>restore=False</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Train this model on data from a generator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>feed_dict_generator: generator</strong></p>
<blockquote>
<div><p>this should generate batches, each represented as a dict that maps
Layers to values.</p>
</div></blockquote>
<p><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote>
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
<p><strong>checkpoint_interval: int</strong></p>
<blockquote>
<div><p>the frequency at which to write checkpoints, measured in training steps.
Set this to 0 to disable automatic checkpointing.</p>
</div></blockquote>
<p><strong>restore: bool</strong></p>
<blockquote>
<div><p>if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</p>
</div></blockquote>
<p><strong>submodel: Submodel</strong></p>
<blockquote>
<div><p>an alternate training objective to use.  This should have been created by
calling create_submodel().</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">the average loss over the most recent checkpoint interval</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit_on_batch">
<code class="descname">fit_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>w</em>, <em>submodel=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.fit_on_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_global_step">
<code class="descname">get_global_step</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_global_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_layer_variables">
<code class="descname">get_layer_variables</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_layer_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of trainable variables in a layer of the graph.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_model_filename">
<code class="descname">get_model_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_model_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_num_tasks">
<code class="descname">get_num_tasks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_num_tasks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_params_filename">
<code class="descname">get_params_filename</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_params_filename" title="Permalink to this definition">¶</a></dt>
<dd><p>Given model directory, obtain filename for the model itself.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_pickling_errors">
<code class="descname">get_pickling_errors</code><span class="sig-paren">(</span><em>obj</em>, <em>seen=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_pickling_errors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_pre_q_input">
<code class="descname">get_pre_q_input</code><span class="sig-paren">(</span><em>input_layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_pre_q_input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_task_type">
<code class="descname">get_task_type</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.get_task_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Currently models can only be classifiers or regressors.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.load_from_dir">
<code class="descname">load_from_dir</code><span class="sig-paren">(</span><em>model_dir</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.load_from_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses self to make predictions on provided Dataset object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">results: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_on_batch">
<code class="descname">predict_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_on_generator">
<code class="descname">predict_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>generator: Generator</strong></p>
<blockquote>
<div><p>Generator that constructs feed dictionaries for TensorGraph.</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs.
If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
<p><strong>Returns:</strong></p>
<blockquote class="last">
<div><p>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>dataset</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>dataset: dc.data.Dataset</strong></p>
<blockquote>
<div><p>Dataset to make prediction on</p>
</div></blockquote>
<p><strong>transformers: list</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers.</p>
</div></blockquote>
<p><strong>outputs: object</strong></p>
<blockquote>
<div><p>If outputs is None, then will assume outputs = self.outputs[0] (single
output). If outputs is a Layer/Tensor, then will evaluate and return as a
single ndarray. If outputs is a list of Layers/Tensors, will return a list
of ndarrays.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">y_pred: numpy ndarray or list of numpy ndarrays</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba_on_batch">
<code class="descname">predict_proba_on_batch</code><span class="sig-paren">(</span><em>X</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba_on_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates predictions for input samples, processing samples in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>the input data, as a Numpy array.</p>
</div></blockquote>
<p><strong>transformers: List</strong></p>
<blockquote>
<div><p>List of dc.trans.Transformers</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Numpy array of predictions.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba_on_generator">
<code class="descname">predict_proba_on_generator</code><span class="sig-paren">(</span><em>generator</em>, <em>transformers=[]</em>, <em>outputs=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.predict_proba_on_generator" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Returns:</dt>
<dd>y_pred: numpy ndarray of shape (n_samples, n_classes*n_tasks)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.reload">
<code class="descname">reload</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.reload" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload trained model from disk.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the values of all variables from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.save">
<code class="descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.save_checkpoint">
<code class="descname">save_checkpoint</code><span class="sig-paren">(</span><em>max_checkpoints_to_keep=5</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.save_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Save a checkpoint to disk.</p>
<p>Usually you do not need to call this method, since fit() saves checkpoints
automatically.  If you have disabled automatic checkpointing during fitting,
this can be called to manually write checkpoints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>max_checkpoints_to_keep: int</strong></p>
<blockquote class="last">
<div><p>the maximum number of checkpoints to keep.  Older checkpoints are discarded.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_loss">
<code class="descname">set_loss</code><span class="sig-paren">(</span><em>layer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_optimizer">
<code class="descname">set_optimizer</code><span class="sig-paren">(</span><em>optimizer</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the optimizer to use for fitting.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.smiles_to_seq">
<code class="descname">smiles_to_seq</code><span class="sig-paren">(</span><em>smiles</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/models/tensorgraph/models/text_cnn.html#TextCNNTensorGraph.smiles_to_seq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.smiles_to_seq" title="Permalink to this definition">¶</a></dt>
<dd><p>Tokenize characters in smiles to integers</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.topsort">
<code class="descname">topsort</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.models.tensorgraph.models.text_cnn.TextCNNTensorGraph.topsort" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.models.tensorgraph.models">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-deepchem.models.tensorgraph.models" title="Permalink to this headline">¶</a></h2>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="_sources/deepchem.models.tensorgraph.models.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2016, Stanford University and the Authors.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>