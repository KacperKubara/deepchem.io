<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>deepchem.rl package &mdash; deepchem 1.3.1 documentation</title>
    
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.3.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="deepchem 1.3.1 documentation" href="index.html" />
    <link rel="up" title="deepchem package" href="deepchem.html" />
    <link rel="next" title="deepchem.rl.envs package" href="deepchem.rl.envs.html" />
    <link rel="prev" title="deepchem.molnet.load_function package" href="deepchem.molnet.load_function.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-inverse navbar-default ">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html"><span><img src="_static/logo.png"></span>
          deepchem</a>
        <span class="navbar-text navbar-version pull-left"><b>1.3</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="notebooks/index.html">Notebooks</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="deepchem.html">deepchem package</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">deepchem.rl package</a><ul>
<li><a class="reference internal" href="#subpackages">Subpackages</a></li>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-deepchem.rl.a3c">deepchem.rl.a3c module</a></li>
<li><a class="reference internal" href="#module-deepchem.rl.mcts">deepchem.rl.mcts module</a></li>
<li><a class="reference internal" href="#module-deepchem.rl.ppo">deepchem.rl.ppo module</a></li>
<li><a class="reference internal" href="#module-deepchem.rl">Module contents</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="deepchem-rl-package">
<h1>deepchem.rl package<a class="headerlink" href="#deepchem-rl-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="deepchem.rl.envs.html">deepchem.rl.envs package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="deepchem.rl.envs.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="deepchem.rl.envs.html#module-deepchem.rl.envs.test_tictactoe">deepchem.rl.envs.test_tictactoe module</a></li>
<li class="toctree-l2"><a class="reference internal" href="deepchem.rl.envs.html#module-deepchem.rl.envs.tictactoe">deepchem.rl.envs.tictactoe module</a></li>
<li class="toctree-l2"><a class="reference internal" href="deepchem.rl.envs.html#module-deepchem.rl.envs">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-deepchem.rl.a3c">
<span id="deepchem-rl-a3c-module"></span><h2>deepchem.rl.a3c module<a class="headerlink" href="#module-deepchem.rl.a3c" title="Permalink to this headline">¶</a></h2>
<p>Asynchronous Advantage Actor-Critic (A3C) algorithm for reinforcement learning.</p>
<dl class="class">
<dt id="deepchem.rl.a3c.A3C">
<em class="property">class </em><code class="descclassname">deepchem.rl.a3c.</code><code class="descname">A3C</code><span class="sig-paren">(</span><em>env</em>, <em>policy</em>, <em>max_rollout_length=20</em>, <em>discount_factor=0.99</em>, <em>advantage_lambda=0.98</em>, <em>value_weight=1.0</em>, <em>entropy_weight=0.01</em>, <em>optimizer=None</em>, <em>model_dir=None</em>, <em>use_hindsight=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/a3c.html#A3C"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.a3c.A3C" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
<p>Implements the Asynchronous Advantage Actor-Critic (A3C) algorithm for reinforcement learning.</p>
<p>The algorithm is described in Mnih et al, &#8220;Asynchronous Methods for Deep Reinforcement Learning&#8221;
(<a class="reference external" href="https://arxiv.org/abs/1602.01783">https://arxiv.org/abs/1602.01783</a>).  This class requires the policy to output two quantities:
a vector giving the probability of taking each action, and an estimate of the value function for
the current state.  It optimizes both outputs at once using a loss that is the sum of three terms:</p>
<ol class="arabic simple">
<li>The policy loss, which seeks to maximize the discounted reward for each action.</li>
<li>The value loss, which tries to make the value estimate match the actual discounted reward
that was attained at each step.</li>
<li>An entropy term to encourage exploration.</li>
</ol>
<p>This class only supports environments with discrete action spaces, not continuous ones.  The
&#8220;action&#8221; argument passed to the environment is an integer, giving the index of the action to perform.</p>
<p>This class supports Generalized Advantage Estimation as described in Schulman et al., &#8220;High-Dimensional
Continuous Control Using Generalized Advantage Estimation&#8221; (<a class="reference external" href="https://arxiv.org/abs/1506.02438">https://arxiv.org/abs/1506.02438</a>).
This is a method of trading off bias and variance in the advantage estimate, which can sometimes
improve the rate of convergance.  Use the advantage_lambda parameter to adjust the tradeoff.</p>
<p>This class supports Hindsight Experience Replay as described in Andrychowicz et al., &#8220;Hindsight
Experience Replay&#8221; (<a class="reference external" href="https://arxiv.org/abs/1707.01495">https://arxiv.org/abs/1707.01495</a>).  This is a method that can enormously
accelerate learning when rewards are very rare.  It requires that the environment state contains
information about the goal the agent is trying to achieve.  Each time it generates a rollout, it
processes that rollout twice: once using the actual goal the agent was pursuing while generating
it, and again using the final state of that rollout as the goal.  This guarantees that half of
all rollouts processed will be ones that achieved their goals, and hence received a reward.</p>
<p>To use this feature, specify use_hindsight=True to the constructor.  The environment must have
a method defined as follows:</p>
<dl class="docutils">
<dt>def apply_hindsight(self, states, actions, goal):</dt>
<dd>...
return new_states, rewards</dd>
</dl>
<p>The method receives the list of states generated during the rollout, the action taken for each one,
and a new goal state.  It should generate a new list of states that are identical to the input ones,
except specifying the new goal.  It should return that list of states, and the rewards that would
have been received for taking the specified actions from those states.</p>
<dl class="method">
<dt id="deepchem.rl.a3c.A3C.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>total_steps</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=600</em>, <em>restore=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/a3c.html#A3C.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.a3c.A3C.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train the policy.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>total_steps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the total number of time steps to perform on the environment, across all rollouts
on all threads</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoint files to keep.  When this number is reached, older
files are deleted.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) &#8211; the time interval at which to save checkpoints, measured in seconds</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.a3c.A3C.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>state</em>, <em>use_saved_states=True</em>, <em>save_states=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/a3c.html#A3C.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.a3c.A3C.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the policy&#8217;s output predictions for a state.</p>
<p>If the policy involves recurrent layers, this method can preserve their internal
states between calls.  Use the use_saved_states and save_states arguments to specify
how it should behave.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>state</strong> (<a class="reference external" href="https://docs.python.org/library/array.html#module-array" title="(in Python v3.6)"><em>array</em></a>) &#8211; the state of the environment for which to generate predictions</li>
<li><strong>use_saved_states</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the states most recently saved by a previous call to predict() or select_action()
will be used as the initial states.  If False, the internal states of all recurrent layers
will be set to all zeros before computing the predictions.</li>
<li><strong>save_states</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the internal states of all recurrent layers at the end of the calculation
will be saved, and any previously saved states will be discarded.  If False, the
states at the end of the calculation will be discarded, and any previously saved
states will be kept.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the array of action probabilities, and the estimated value function</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.a3c.A3C.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/a3c.html#A3C.restore"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.a3c.A3C.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the model parameters from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.a3c.A3C.select_action">
<code class="descname">select_action</code><span class="sig-paren">(</span><em>state</em>, <em>deterministic=False</em>, <em>use_saved_states=True</em>, <em>save_states=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/a3c.html#A3C.select_action"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.a3c.A3C.select_action" title="Permalink to this definition">¶</a></dt>
<dd><p>Select an action to perform based on the environment&#8217;s state.</p>
<p>If the policy involves recurrent layers, this method can preserve their internal
states between calls.  Use the use_saved_states and save_states arguments to specify
how it should behave.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>state</strong> (<a class="reference external" href="https://docs.python.org/library/array.html#module-array" title="(in Python v3.6)"><em>array</em></a>) &#8211; the state of the environment for which to select an action</li>
<li><strong>deterministic</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, always return the best action (that is, the one with highest probability).
If False, randomly select an action based on the computed probabilities.</li>
<li><strong>use_saved_states</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the states most recently saved by a previous call to predict() or select_action()
will be used as the initial states.  If False, the internal states of all recurrent layers
will be set to all zeros before computing the predictions.</li>
<li><strong>save_states</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the internal states of all recurrent layers at the end of the calculation
will be saved, and any previously saved states will be discarded.  If False, the
states at the end of the calculation will be discarded, and any previously saved
states will be kept.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the index of the selected action</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.rl.a3c.A3CLoss">
<em class="property">class </em><code class="descclassname">deepchem.rl.a3c.</code><code class="descname">A3CLoss</code><span class="sig-paren">(</span><em>value_weight</em>, <em>entropy_weight</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/a3c.html#A3CLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.a3c.A3CLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.layers.Layer" title="deepchem.models.tensorgraph.layers.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.layers.Layer</span></code></a></p>
<p>This layer computes the loss function for A3C.</p>
<dl class="method">
<dt id="deepchem.rl.a3c.A3CLoss.add_summary_to_tg">
<code class="descname">add_summary_to_tg</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.a3c.A3CLoss.add_summary_to_tg" title="Permalink to this definition">¶</a></dt>
<dd><p>Can only be called after self.create_layer to gaurentee that name is not none</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.a3c.A3CLoss.clone">
<code class="descname">clone</code><span class="sig-paren">(</span><em>in_layers</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.a3c.A3CLoss.clone" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of this layer with different inputs.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.a3c.A3CLoss.copy">
<code class="descname">copy</code><span class="sig-paren">(</span><em>replacements={}</em>, <em>variables_graph=None</em>, <em>shared=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.a3c.A3CLoss.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Duplicate this Layer and all its inputs.</p>
<p>This is similar to clone(), but instead of only cloning one layer, it also
recursively calls copy() on all of this layer&#8217;s inputs to clone the entire
hierarchy of layers.  In the process, you can optionally tell it to replace
particular layers with specific existing ones.  For example, you can clone a
stack of layers, while connecting the topmost ones to different inputs.</p>
<p>For example, consider a stack of dense layers that depend on an input:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense3</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense2</span><span class="p">)</span>
</pre></div>
</div>
<p>The following will clone all three dense layers, but not the input layer.
Instead, the input to the first dense layer will be a different layer
specified in the replacements map.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">replacements</span> <span class="o">=</span> <span class="p">{</span><span class="nb">input</span><span class="p">:</span> <span class="n">new_input</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense3_copy</span> <span class="o">=</span> <span class="n">dense3</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">replacements</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>replacements</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#map" title="(in Python v3.6)"><em>map</em></a>) &#8211; specifies existing layers, and the layers to replace them with (instead of
cloning them).  This argument serves two purposes.  First, you can pass in
a list of replacements to control which layers get cloned.  In addition,
as each layer is cloned, it is added to this map.  On exit, it therefore
contains a complete record of all layers that were copied, and a reference
to the copy of each one.</li>
<li><strong>variables_graph</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><em>TensorGraph</em></a>) &#8211; an optional TensorGraph from which to take variables.  If this is specified,
the current value of each variable in each layer is recorded, and the copy
has that value specified as its initial value.  This allows a piece of a
pre-trained model to be copied to another model.</li>
<li><strong>shared</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, create new layers by calling shared() on the input layers.
This means the newly created layers will share variables with the original
ones.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.a3c.A3CLoss.create_tensor">
<code class="descname">create_tensor</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/a3c.html#A3CLoss.create_tensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.a3c.A3CLoss.create_tensor" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.rl.a3c.A3CLoss.layer_number_dict">
<code class="descname">layer_number_dict</code><em class="property"> = {}</em><a class="headerlink" href="#deepchem.rl.a3c.A3CLoss.layer_number_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.rl.a3c.A3CLoss.none_tensors">
<code class="descname">none_tensors</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.a3c.A3CLoss.none_tensors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.rl.a3c.A3CLoss.set_summary">
<code class="descname">set_summary</code><span class="sig-paren">(</span><em>summary_op</em>, <em>summary_description=None</em>, <em>collections=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.a3c.A3CLoss.set_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Annotates a tensor with a tf.summary operation
Collects data from self.out_tensor by default but can be changed by setting
self.tb_input to another tensor in create_tensor</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>summary_op</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) &#8211; summary operation to annotate node</li>
<li><strong>summary_description</strong> (<em>object, optional</em>) &#8211; Optional summary_pb2.SummaryDescription()</li>
<li><strong>collections</strong> (<em>list of graph collections keys, optional</em>) &#8211; New summary op is added to these collections. Defaults to [GraphKeys.SUMMARIES]</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.a3c.A3CLoss.set_tensors">
<code class="descname">set_tensors</code><span class="sig-paren">(</span><em>tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.a3c.A3CLoss.set_tensors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.rl.a3c.A3CLoss.set_variable_initial_values">
<code class="descname">set_variable_initial_values</code><span class="sig-paren">(</span><em>values</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.a3c.A3CLoss.set_variable_initial_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the initial values of all variables.</p>
<p>This takes a list, which contains the initial values to use for all of
this layer&#8217;s values (in the same order retured by
TensorGraph.get_layer_variables()).  When this layer is used in a
TensorGraph, it will automatically initialize each variable to the value
specified in the list.  Note that some layers also have separate mechanisms
for specifying variable initializers; this method overrides them. The
purpose of this method is to let a Layer object represent a pre-trained
layer, complete with trained values for its variables.</p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.rl.a3c.A3CLoss.shape">
<code class="descname">shape</code><a class="headerlink" href="#deepchem.rl.a3c.A3CLoss.shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shape of this Layer&#8217;s output.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.a3c.A3CLoss.shared">
<code class="descname">shared</code><span class="sig-paren">(</span><em>in_layers</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.a3c.A3CLoss.shared" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of this layer that shares variables with it.</p>
<p>This is similar to clone(), but where clone() creates two independent layers,
this causes the layers to share variables with each other.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>in_layers</strong> (<em>list tensor</em>) &#8211; </li>
<li><strong>in tensors for the shared layer</strong> (<em>List</em>) &#8211; </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer">Layer</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.rl.mcts">
<span id="deepchem-rl-mcts-module"></span><h2>deepchem.rl.mcts module<a class="headerlink" href="#module-deepchem.rl.mcts" title="Permalink to this headline">¶</a></h2>
<p>Monte Carlo tree search algorithm for reinforcement learning.</p>
<dl class="class">
<dt id="deepchem.rl.mcts.MCTS">
<em class="property">class </em><code class="descclassname">deepchem.rl.mcts.</code><code class="descname">MCTS</code><span class="sig-paren">(</span><em>env</em>, <em>policy</em>, <em>max_search_depth=100</em>, <em>n_search_episodes=1000</em>, <em>discount_factor=0.99</em>, <em>value_weight=1.0</em>, <em>optimizer=&lt;deepchem.models.tensorgraph.optimizers.Adam object&gt;</em>, <em>model_dir=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/mcts.html#MCTS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.mcts.MCTS" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
<p>Implements a Monte Carlo tree search algorithm for reinforcement learning.</p>
<p>This is adapted from Silver et al, &#8220;Mastering the game of Go without human
knowledge&#8221; (<a class="reference external" href="https://www.nature.com/articles/nature24270">https://www.nature.com/articles/nature24270</a>).  The methods
described in that paper rely on features of Go that are not generally true of
all reinforcement learning problems.  To transform it into a more generally
useful RL algorithm, it has been necessary to change some aspects of the
method.  The overall approach used in this implementation is still the same,
although some of the details differ.</p>
<p>This class requires the policy to output two quantities: a vector giving the
probability of taking each action, and an estimate of the value function for
the current state.  At every step of simulating an episode, it performs an
expensive tree search to explore the consequences of many possible actions.
Based on that search, it computes much better estimates for the value function
of the current state and the desired action probabilities.  In then tries to
optimize the policy to make its outputs match the result of the tree search.</p>
<p>Optimization proceeds through a series of iterations.  Each iteration consists
of two stages:</p>
<ol class="arabic simple">
<li>Simulate many episodes.  At every step perform a tree search to determine
targets for the probabilities and value function, and store them into a
buffer.</li>
<li>Optimize the policy using batches drawn from the buffer generated in step 1.</li>
</ol>
<p>The tree search involves repeatedly selecting actions starting from the
current state.  This is done by using deepcopy() to clone the environment.  It
is essential that this produce a deterministic sequence of states: performing
an action on the cloned environment must always lead to the same state as
performing that action on the original environment.  For environments whose
state transitions are deterministic, this is not a problem.  For ones whose
state transitions are stochastic, it is essential that the random number
generator used to select new states be stored as part of the environment and
be properly cloned by deepcopy().</p>
<p>This class does not support policies that include recurrent layers.</p>
<dl class="method">
<dt id="deepchem.rl.mcts.MCTS.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>iterations</em>, <em>steps_per_iteration=10000</em>, <em>epochs_per_iteration=10</em>, <em>temperature=0.5</em>, <em>puct_scale=None</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=600</em>, <em>restore=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/mcts.html#MCTS.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.mcts.MCTS.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train the policy.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>iterations</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the total number of iterations (simulation followed by optimization) to perform</li>
<li><strong>steps_per_iteration</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the total number of steps to simulate in each iteration.  Every step consists
of a tree search, followed by selecting an action based on the results of
the search.</li>
<li><strong>epochs_per_iteration</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of epochs of optimization to perform for each iteration.  Each
epoch involves randomly ordering all the steps that were just simulated in
the current iteration, splitting them into batches, and looping over the
batches.</li>
<li><strong>temperature</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) &#8211; the temperature factor to use when selecting a move for each step of
simulation.  Larger values produce a broader probability distribution and
hence more exploration.  Smaller values produce a stronger preference for
whatever action did best in the tree search.</li>
<li><strong>puct_scale</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) &#8211; the scale of the PUCT term in the expression for selecting actions during
tree search.  This should be roughly similar in magnitude to the rewards
given by the environment, since the PUCT term is added to the mean
discounted reward.  This may be None, in which case a value is adaptively
selected that tries to match the mean absolute value of the discounted
reward.</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoint files to keep.  When this number is reached, older
files are deleted.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) &#8211; the time interval at which to save checkpoints, measured in seconds</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.mcts.MCTS.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/mcts.html#MCTS.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.mcts.MCTS.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the policy&#8217;s output predictions for a state.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>state</strong> (<a class="reference external" href="https://docs.python.org/library/array.html#module-array" title="(in Python v3.6)"><em>array</em></a>) &#8211; the state of the environment for which to generate predictions</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">the array of action probabilities, and the estimated value function</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.mcts.MCTS.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/mcts.html#MCTS.restore"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.mcts.MCTS.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the model parameters from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.mcts.MCTS.select_action">
<code class="descname">select_action</code><span class="sig-paren">(</span><em>state</em>, <em>deterministic=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/mcts.html#MCTS.select_action"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.mcts.MCTS.select_action" title="Permalink to this definition">¶</a></dt>
<dd><p>Select an action to perform based on the environment&#8217;s state.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>state</strong> (<a class="reference external" href="https://docs.python.org/library/array.html#module-array" title="(in Python v3.6)"><em>array</em></a>) &#8211; the state of the environment for which to select an action</li>
<li><strong>deterministic</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, always return the best action (that is, the one with highest probability).
If False, randomly select an action based on the computed probabilities.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the index of the selected action</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.rl.mcts.MCTSLoss">
<em class="property">class </em><code class="descclassname">deepchem.rl.mcts.</code><code class="descname">MCTSLoss</code><span class="sig-paren">(</span><em>value_weight</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/mcts.html#MCTSLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.mcts.MCTSLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.layers.Layer" title="deepchem.models.tensorgraph.layers.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.layers.Layer</span></code></a></p>
<p>This layer computes the loss function for MCTS.</p>
<dl class="method">
<dt id="deepchem.rl.mcts.MCTSLoss.add_summary_to_tg">
<code class="descname">add_summary_to_tg</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.mcts.MCTSLoss.add_summary_to_tg" title="Permalink to this definition">¶</a></dt>
<dd><p>Can only be called after self.create_layer to gaurentee that name is not none</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.mcts.MCTSLoss.clone">
<code class="descname">clone</code><span class="sig-paren">(</span><em>in_layers</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.mcts.MCTSLoss.clone" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of this layer with different inputs.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.mcts.MCTSLoss.copy">
<code class="descname">copy</code><span class="sig-paren">(</span><em>replacements={}</em>, <em>variables_graph=None</em>, <em>shared=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.mcts.MCTSLoss.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Duplicate this Layer and all its inputs.</p>
<p>This is similar to clone(), but instead of only cloning one layer, it also
recursively calls copy() on all of this layer&#8217;s inputs to clone the entire
hierarchy of layers.  In the process, you can optionally tell it to replace
particular layers with specific existing ones.  For example, you can clone a
stack of layers, while connecting the topmost ones to different inputs.</p>
<p>For example, consider a stack of dense layers that depend on an input:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense3</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense2</span><span class="p">)</span>
</pre></div>
</div>
<p>The following will clone all three dense layers, but not the input layer.
Instead, the input to the first dense layer will be a different layer
specified in the replacements map.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">replacements</span> <span class="o">=</span> <span class="p">{</span><span class="nb">input</span><span class="p">:</span> <span class="n">new_input</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense3_copy</span> <span class="o">=</span> <span class="n">dense3</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">replacements</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>replacements</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#map" title="(in Python v3.6)"><em>map</em></a>) &#8211; specifies existing layers, and the layers to replace them with (instead of
cloning them).  This argument serves two purposes.  First, you can pass in
a list of replacements to control which layers get cloned.  In addition,
as each layer is cloned, it is added to this map.  On exit, it therefore
contains a complete record of all layers that were copied, and a reference
to the copy of each one.</li>
<li><strong>variables_graph</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><em>TensorGraph</em></a>) &#8211; an optional TensorGraph from which to take variables.  If this is specified,
the current value of each variable in each layer is recorded, and the copy
has that value specified as its initial value.  This allows a piece of a
pre-trained model to be copied to another model.</li>
<li><strong>shared</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, create new layers by calling shared() on the input layers.
This means the newly created layers will share variables with the original
ones.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.mcts.MCTSLoss.create_tensor">
<code class="descname">create_tensor</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/mcts.html#MCTSLoss.create_tensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.mcts.MCTSLoss.create_tensor" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.rl.mcts.MCTSLoss.layer_number_dict">
<code class="descname">layer_number_dict</code><em class="property"> = {}</em><a class="headerlink" href="#deepchem.rl.mcts.MCTSLoss.layer_number_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.rl.mcts.MCTSLoss.none_tensors">
<code class="descname">none_tensors</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.mcts.MCTSLoss.none_tensors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.rl.mcts.MCTSLoss.set_summary">
<code class="descname">set_summary</code><span class="sig-paren">(</span><em>summary_op</em>, <em>summary_description=None</em>, <em>collections=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.mcts.MCTSLoss.set_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Annotates a tensor with a tf.summary operation
Collects data from self.out_tensor by default but can be changed by setting
self.tb_input to another tensor in create_tensor</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>summary_op</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) &#8211; summary operation to annotate node</li>
<li><strong>summary_description</strong> (<em>object, optional</em>) &#8211; Optional summary_pb2.SummaryDescription()</li>
<li><strong>collections</strong> (<em>list of graph collections keys, optional</em>) &#8211; New summary op is added to these collections. Defaults to [GraphKeys.SUMMARIES]</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.mcts.MCTSLoss.set_tensors">
<code class="descname">set_tensors</code><span class="sig-paren">(</span><em>tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.mcts.MCTSLoss.set_tensors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.rl.mcts.MCTSLoss.set_variable_initial_values">
<code class="descname">set_variable_initial_values</code><span class="sig-paren">(</span><em>values</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.mcts.MCTSLoss.set_variable_initial_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the initial values of all variables.</p>
<p>This takes a list, which contains the initial values to use for all of
this layer&#8217;s values (in the same order retured by
TensorGraph.get_layer_variables()).  When this layer is used in a
TensorGraph, it will automatically initialize each variable to the value
specified in the list.  Note that some layers also have separate mechanisms
for specifying variable initializers; this method overrides them. The
purpose of this method is to let a Layer object represent a pre-trained
layer, complete with trained values for its variables.</p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.rl.mcts.MCTSLoss.shape">
<code class="descname">shape</code><a class="headerlink" href="#deepchem.rl.mcts.MCTSLoss.shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shape of this Layer&#8217;s output.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.mcts.MCTSLoss.shared">
<code class="descname">shared</code><span class="sig-paren">(</span><em>in_layers</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.mcts.MCTSLoss.shared" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of this layer that shares variables with it.</p>
<p>This is similar to clone(), but where clone() creates two independent layers,
this causes the layers to share variables with each other.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>in_layers</strong> (<em>list tensor</em>) &#8211; </li>
<li><strong>in tensors for the shared layer</strong> (<em>List</em>) &#8211; </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer">Layer</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.rl.mcts.TreeSearchNode">
<em class="property">class </em><code class="descclassname">deepchem.rl.mcts.</code><code class="descname">TreeSearchNode</code><span class="sig-paren">(</span><em>prior_prob</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/mcts.html#TreeSearchNode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.mcts.TreeSearchNode" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
<p>Represents a node in the Monte Carlo tree search.</p>
</dd></dl>

</div>
<div class="section" id="module-deepchem.rl.ppo">
<span id="deepchem-rl-ppo-module"></span><h2>deepchem.rl.ppo module<a class="headerlink" href="#module-deepchem.rl.ppo" title="Permalink to this headline">¶</a></h2>
<p>Proximal Policy Optimization (PPO) algorithm for reinforcement learning.</p>
<dl class="class">
<dt id="deepchem.rl.ppo.PPO">
<em class="property">class </em><code class="descclassname">deepchem.rl.ppo.</code><code class="descname">PPO</code><span class="sig-paren">(</span><em>env</em>, <em>policy</em>, <em>max_rollout_length=20</em>, <em>optimization_rollouts=8</em>, <em>optimization_epochs=4</em>, <em>batch_size=64</em>, <em>clipping_width=0.2</em>, <em>discount_factor=0.99</em>, <em>advantage_lambda=0.98</em>, <em>value_weight=1.0</em>, <em>entropy_weight=0.01</em>, <em>optimizer=None</em>, <em>model_dir=None</em>, <em>use_hindsight=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/ppo.html#PPO"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.ppo.PPO" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
<p>Implements the Proximal Policy Optimization (PPO) algorithm for reinforcement learning.</p>
<p>The algorithm is described in Schulman et al, &#8220;Proximal Policy Optimization Algorithms&#8221;
(<a class="reference external" href="https://openai-public.s3-us-west-2.amazonaws.com/blog/2017-07/ppo/ppo-arxiv.pdf">https://openai-public.s3-us-west-2.amazonaws.com/blog/2017-07/ppo/ppo-arxiv.pdf</a>).
This class requires the policy to output two quantities: a vector giving the probability of
taking each action, and an estimate of the value function for the current state.  It
optimizes both outputs at once using a loss that is the sum of three terms:</p>
<ol class="arabic simple">
<li>The policy loss, which seeks to maximize the discounted reward for each action.</li>
<li>The value loss, which tries to make the value estimate match the actual discounted reward
that was attained at each step.</li>
<li>An entropy term to encourage exploration.</li>
</ol>
<p>This class only supports environments with discrete action spaces, not continuous ones.  The
&#8220;action&#8221; argument passed to the environment is an integer, giving the index of the action to perform.</p>
<p>This class supports Generalized Advantage Estimation as described in Schulman et al., &#8220;High-Dimensional
Continuous Control Using Generalized Advantage Estimation&#8221; (<a class="reference external" href="https://arxiv.org/abs/1506.02438">https://arxiv.org/abs/1506.02438</a>).
This is a method of trading off bias and variance in the advantage estimate, which can sometimes
improve the rate of convergance.  Use the advantage_lambda parameter to adjust the tradeoff.</p>
<p>This class supports Hindsight Experience Replay as described in Andrychowicz et al., &#8220;Hindsight
Experience Replay&#8221; (<a class="reference external" href="https://arxiv.org/abs/1707.01495">https://arxiv.org/abs/1707.01495</a>).  This is a method that can enormously
accelerate learning when rewards are very rare.  It requires that the environment state contains
information about the goal the agent is trying to achieve.  Each time it generates a rollout, it
processes that rollout twice: once using the actual goal the agent was pursuing while generating
it, and again using the final state of that rollout as the goal.  This guarantees that half of
all rollouts processed will be ones that achieved their goals, and hence received a reward.</p>
<p>To use this feature, specify use_hindsight=True to the constructor.  The environment must have
a method defined as follows:</p>
<dl class="docutils">
<dt>def apply_hindsight(self, states, actions, goal):</dt>
<dd>...
return new_states, rewards</dd>
</dl>
<p>The method receives the list of states generated during the rollout, the action taken for each one,
and a new goal state.  It should generate a new list of states that are identical to the input ones,
except specifying the new goal.  It should return that list of states, and the rewards that would
have been received for taking the specified actions from those states.</p>
<dl class="method">
<dt id="deepchem.rl.ppo.PPO.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>total_steps</em>, <em>max_checkpoints_to_keep=5</em>, <em>checkpoint_interval=600</em>, <em>restore=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/ppo.html#PPO.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.ppo.PPO.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train the policy.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>total_steps</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the total number of time steps to perform on the environment, across all rollouts
on all threads</li>
<li><strong>max_checkpoints_to_keep</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the maximum number of checkpoint files to keep.  When this number is reached, older
files are deleted.</li>
<li><strong>checkpoint_interval</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) &#8211; the time interval at which to save checkpoints, measured in seconds</li>
<li><strong>restore</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, restore the model from the most recent checkpoint and continue training
from there.  If False, retrain the model from scratch.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.ppo.PPO.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>state</em>, <em>use_saved_states=True</em>, <em>save_states=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/ppo.html#PPO.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.ppo.PPO.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the policy&#8217;s output predictions for a state.</p>
<p>If the policy involves recurrent layers, this method can preserve their internal
states between calls.  Use the use_saved_states and save_states arguments to specify
how it should behave.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>state</strong> (<a class="reference external" href="https://docs.python.org/library/array.html#module-array" title="(in Python v3.6)"><em>array</em></a>) &#8211; the state of the environment for which to generate predictions</li>
<li><strong>use_saved_states</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the states most recently saved by a previous call to predict() or select_action()
will be used as the initial states.  If False, the internal states of all recurrent layers
will be set to all zeros before computing the predictions.</li>
<li><strong>save_states</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the internal states of all recurrent layers at the end of the calculation
will be saved, and any previously saved states will be discarded.  If False, the
states at the end of the calculation will be discarded, and any previously saved
states will be kept.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the array of action probabilities, and the estimated value function</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.ppo.PPO.restore">
<code class="descname">restore</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/ppo.html#PPO.restore"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.ppo.PPO.restore" title="Permalink to this definition">¶</a></dt>
<dd><p>Reload the model parameters from the most recent checkpoint file.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.ppo.PPO.select_action">
<code class="descname">select_action</code><span class="sig-paren">(</span><em>state</em>, <em>deterministic=False</em>, <em>use_saved_states=True</em>, <em>save_states=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/ppo.html#PPO.select_action"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.ppo.PPO.select_action" title="Permalink to this definition">¶</a></dt>
<dd><p>Select an action to perform based on the environment&#8217;s state.</p>
<p>If the policy involves recurrent layers, this method can preserve their internal
states between calls.  Use the use_saved_states and save_states arguments to specify
how it should behave.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>state</strong> (<a class="reference external" href="https://docs.python.org/library/array.html#module-array" title="(in Python v3.6)"><em>array</em></a>) &#8211; the state of the environment for which to select an action</li>
<li><strong>deterministic</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, always return the best action (that is, the one with highest probability).
If False, randomly select an action based on the computed probabilities.</li>
<li><strong>use_saved_states</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the states most recently saved by a previous call to predict() or select_action()
will be used as the initial states.  If False, the internal states of all recurrent layers
will be set to all zeros before computing the predictions.</li>
<li><strong>save_states</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, the internal states of all recurrent layers at the end of the calculation
will be saved, and any previously saved states will be discarded.  If False, the
states at the end of the calculation will be discarded, and any previously saved
states will be kept.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">the index of the selected action</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.rl.ppo.PPOLoss">
<em class="property">class </em><code class="descclassname">deepchem.rl.ppo.</code><code class="descname">PPOLoss</code><span class="sig-paren">(</span><em>value_weight</em>, <em>entropy_weight</em>, <em>clipping_width</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/ppo.html#PPOLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.ppo.PPOLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.layers.Layer" title="deepchem.models.tensorgraph.layers.Layer"><code class="xref py py-class docutils literal"><span class="pre">deepchem.models.tensorgraph.layers.Layer</span></code></a></p>
<p>This layer computes the loss function for PPO.</p>
<dl class="method">
<dt id="deepchem.rl.ppo.PPOLoss.add_summary_to_tg">
<code class="descname">add_summary_to_tg</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.ppo.PPOLoss.add_summary_to_tg" title="Permalink to this definition">¶</a></dt>
<dd><p>Can only be called after self.create_layer to gaurentee that name is not none</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.ppo.PPOLoss.clone">
<code class="descname">clone</code><span class="sig-paren">(</span><em>in_layers</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.ppo.PPOLoss.clone" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of this layer with different inputs.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.ppo.PPOLoss.copy">
<code class="descname">copy</code><span class="sig-paren">(</span><em>replacements={}</em>, <em>variables_graph=None</em>, <em>shared=False</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.ppo.PPOLoss.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Duplicate this Layer and all its inputs.</p>
<p>This is similar to clone(), but instead of only cloning one layer, it also
recursively calls copy() on all of this layer&#8217;s inputs to clone the entire
hierarchy of layers.  In the process, you can optionally tell it to replace
particular layers with specific existing ones.  For example, you can clone a
stack of layers, while connecting the topmost ones to different inputs.</p>
<p>For example, consider a stack of dense layers that depend on an input:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense3</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense2</span><span class="p">)</span>
</pre></div>
</div>
<p>The following will clone all three dense layers, but not the input layer.
Instead, the input to the first dense layer will be a different layer
specified in the replacements map.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">replacements</span> <span class="o">=</span> <span class="p">{</span><span class="nb">input</span><span class="p">:</span> <span class="n">new_input</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dense3_copy</span> <span class="o">=</span> <span class="n">dense3</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">replacements</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>replacements</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#map" title="(in Python v3.6)"><em>map</em></a>) &#8211; specifies existing layers, and the layers to replace them with (instead of
cloning them).  This argument serves two purposes.  First, you can pass in
a list of replacements to control which layers get cloned.  In addition,
as each layer is cloned, it is added to this map.  On exit, it therefore
contains a complete record of all layers that were copied, and a reference
to the copy of each one.</li>
<li><strong>variables_graph</strong> (<a class="reference internal" href="deepchem.models.tensorgraph.html#deepchem.models.tensorgraph.tensor_graph.TensorGraph" title="deepchem.models.tensorgraph.tensor_graph.TensorGraph"><em>TensorGraph</em></a>) &#8211; an optional TensorGraph from which to take variables.  If this is specified,
the current value of each variable in each layer is recorded, and the copy
has that value specified as its initial value.  This allows a piece of a
pre-trained model to be copied to another model.</li>
<li><strong>shared</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; if True, create new layers by calling shared() on the input layers.
This means the newly created layers will share variables with the original
ones.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.ppo.PPOLoss.create_tensor">
<code class="descname">create_tensor</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl/ppo.html#PPOLoss.create_tensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.ppo.PPOLoss.create_tensor" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.rl.ppo.PPOLoss.layer_number_dict">
<code class="descname">layer_number_dict</code><em class="property"> = {}</em><a class="headerlink" href="#deepchem.rl.ppo.PPOLoss.layer_number_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.rl.ppo.PPOLoss.none_tensors">
<code class="descname">none_tensors</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.ppo.PPOLoss.none_tensors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.rl.ppo.PPOLoss.set_summary">
<code class="descname">set_summary</code><span class="sig-paren">(</span><em>summary_op</em>, <em>summary_description=None</em>, <em>collections=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.ppo.PPOLoss.set_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Annotates a tensor with a tf.summary operation
Collects data from self.out_tensor by default but can be changed by setting
self.tb_input to another tensor in create_tensor</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>summary_op</strong> (<a class="reference external" href="https://docs.python.org/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) &#8211; summary operation to annotate node</li>
<li><strong>summary_description</strong> (<em>object, optional</em>) &#8211; Optional summary_pb2.SummaryDescription()</li>
<li><strong>collections</strong> (<em>list of graph collections keys, optional</em>) &#8211; New summary op is added to these collections. Defaults to [GraphKeys.SUMMARIES]</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.ppo.PPOLoss.set_tensors">
<code class="descname">set_tensors</code><span class="sig-paren">(</span><em>tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.ppo.PPOLoss.set_tensors" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deepchem.rl.ppo.PPOLoss.set_variable_initial_values">
<code class="descname">set_variable_initial_values</code><span class="sig-paren">(</span><em>values</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.ppo.PPOLoss.set_variable_initial_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the initial values of all variables.</p>
<p>This takes a list, which contains the initial values to use for all of
this layer&#8217;s values (in the same order retured by
TensorGraph.get_layer_variables()).  When this layer is used in a
TensorGraph, it will automatically initialize each variable to the value
specified in the list.  Note that some layers also have separate mechanisms
for specifying variable initializers; this method overrides them. The
purpose of this method is to let a Layer object represent a pre-trained
layer, complete with trained values for its variables.</p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.rl.ppo.PPOLoss.shape">
<code class="descname">shape</code><a class="headerlink" href="#deepchem.rl.ppo.PPOLoss.shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shape of this Layer&#8217;s output.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.ppo.PPOLoss.shared">
<code class="descname">shared</code><span class="sig-paren">(</span><em>in_layers</em><span class="sig-paren">)</span><a class="headerlink" href="#deepchem.rl.ppo.PPOLoss.shared" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of this layer that shares variables with it.</p>
<p>This is similar to clone(), but where clone() creates two independent layers,
this causes the layers to share variables with each other.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>in_layers</strong> (<em>list tensor</em>) &#8211; </li>
<li><strong>in tensors for the shared layer</strong> (<em>List</em>) &#8211; </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="deepchem.nn.html#deepchem.nn.copy.Layer" title="deepchem.nn.copy.Layer">Layer</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-deepchem.rl">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-deepchem.rl" title="Permalink to this headline">¶</a></h2>
<p>Interface for reinforcement learning.</p>
<dl class="class">
<dt id="deepchem.rl.Environment">
<em class="property">class </em><code class="descclassname">deepchem.rl.</code><code class="descname">Environment</code><span class="sig-paren">(</span><em>state_shape</em>, <em>n_actions</em>, <em>state_dtype=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl.html#Environment"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.Environment" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
<p>An environment in which an actor performs actions to accomplish a task.</p>
<p>An environment has a current state, which is represented as either a single NumPy
array, or optionally a list of NumPy arrays.  When an action is taken, that causes
the state to be updated.  Exactly what is meant by an &#8220;action&#8221; is defined by each
subclass.  As far as this interface is concerned, it is simply an arbitrary object.
The environment also computes a reward for each action, and reports when the task
has been terminated (meaning that no more actions may be taken).</p>
<p>Environment objects should be written to support pickle and deepcopy operations.
Many algorithms involve creating multiple copies of the Environment, possibly
running in different processes or even on different computers.</p>
<dl class="attribute">
<dt id="deepchem.rl.Environment.n_actions">
<code class="descname">n_actions</code><a class="headerlink" href="#deepchem.rl.Environment.n_actions" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of possible actions that can be performed in this Environment.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.Environment.reset">
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl.html#Environment.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.Environment.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize the environment in preparation for doing calculations with it.</p>
<p>This must be called before calling step() or querying the state.  You can call it
again later to reset the environment back to its original state.</p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.rl.Environment.state">
<code class="descname">state</code><a class="headerlink" href="#deepchem.rl.Environment.state" title="Permalink to this definition">¶</a></dt>
<dd><p>The current state of the environment, represented as either a NumPy array or list of arrays.</p>
<p>If reset() has not yet been called at least once, this is undefined.</p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.rl.Environment.state_dtype">
<code class="descname">state_dtype</code><a class="headerlink" href="#deepchem.rl.Environment.state_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>The dtypes of the arrays that describe a state.</p>
<p>If the state is a single array, this returns the dtype of that array.  If the state
is a list of arrays, this returns a list containing the dtypes of the arrays.</p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.rl.Environment.state_shape">
<code class="descname">state_shape</code><a class="headerlink" href="#deepchem.rl.Environment.state_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>The shape of the arrays that describe a state.</p>
<p>If the state is a single array, this returns a tuple giving the shape of that array.
If the state is a list of arrays, this returns a list of tuples where each tuple is
the shape of one array.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.Environment.step">
<code class="descname">step</code><span class="sig-paren">(</span><em>action</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl.html#Environment.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.Environment.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Take a time step by performing an action.</p>
<p>This causes the &#8220;state&#8221; and &#8220;terminated&#8221; properties to be updated.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>action</strong> (<a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><em>object</em></a>) &#8211; an object describing the action to take</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><em>the reward earned by taking the action, represented as a floating point number</em></li>
<li><em>(higher values are better)</em></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.rl.Environment.terminated">
<code class="descname">terminated</code><a class="headerlink" href="#deepchem.rl.Environment.terminated" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether the task has reached its end.</p>
<p>If reset() has not yet been called at least once, this is undefined.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.rl.GymEnvironment">
<em class="property">class </em><code class="descclassname">deepchem.rl.</code><code class="descname">GymEnvironment</code><span class="sig-paren">(</span><em>name</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl.html#GymEnvironment"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.GymEnvironment" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#deepchem.rl.Environment" title="deepchem.rl.Environment"><code class="xref py py-class docutils literal"><span class="pre">deepchem.rl.Environment</span></code></a></p>
<p>This is a convenience class for working with environments from OpenAI Gym.</p>
<dl class="attribute">
<dt id="deepchem.rl.GymEnvironment.n_actions">
<code class="descname">n_actions</code><a class="headerlink" href="#deepchem.rl.GymEnvironment.n_actions" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of possible actions that can be performed in this Environment.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.GymEnvironment.reset">
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl.html#GymEnvironment.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.GymEnvironment.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.rl.GymEnvironment.state">
<code class="descname">state</code><a class="headerlink" href="#deepchem.rl.GymEnvironment.state" title="Permalink to this definition">¶</a></dt>
<dd><p>The current state of the environment, represented as either a NumPy array or list of arrays.</p>
<p>If reset() has not yet been called at least once, this is undefined.</p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.rl.GymEnvironment.state_dtype">
<code class="descname">state_dtype</code><a class="headerlink" href="#deepchem.rl.GymEnvironment.state_dtype" title="Permalink to this definition">¶</a></dt>
<dd><p>The dtypes of the arrays that describe a state.</p>
<p>If the state is a single array, this returns the dtype of that array.  If the state
is a list of arrays, this returns a list containing the dtypes of the arrays.</p>
</dd></dl>

<dl class="attribute">
<dt id="deepchem.rl.GymEnvironment.state_shape">
<code class="descname">state_shape</code><a class="headerlink" href="#deepchem.rl.GymEnvironment.state_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>The shape of the arrays that describe a state.</p>
<p>If the state is a single array, this returns a tuple giving the shape of that array.
If the state is a list of arrays, this returns a list of tuples where each tuple is
the shape of one array.</p>
</dd></dl>

<dl class="method">
<dt id="deepchem.rl.GymEnvironment.step">
<code class="descname">step</code><span class="sig-paren">(</span><em>action</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl.html#GymEnvironment.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.GymEnvironment.step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="deepchem.rl.GymEnvironment.terminated">
<code class="descname">terminated</code><a class="headerlink" href="#deepchem.rl.GymEnvironment.terminated" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether the task has reached its end.</p>
<p>If reset() has not yet been called at least once, this is undefined.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepchem.rl.Policy">
<em class="property">class </em><code class="descclassname">deepchem.rl.</code><code class="descname">Policy</code><a class="reference internal" href="_modules/deepchem/rl.html#Policy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.Policy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
<p>A policy for taking actions within an environment.</p>
<p>A policy is defined by a set of TensorGraph Layer objects that perform the
necessary calculations.  There are many algorithms for reinforcement learning,
and they differ in what values they require a policy to compute.  That makes
it impossible to define a single interface allowing any policy to be optimized
with any algorithm.  Instead, this interface just tries to be as flexible and
generic as possible.  Each algorithm must document what values it expects
create_layers() to return.</p>
<p>Policy objects should be written to support pickling.  Many algorithms involve
creating multiple copies of the Policy, possibly running in different processes
or even on different computers.</p>
<dl class="method">
<dt id="deepchem.rl.Policy.create_layers">
<code class="descname">create_layers</code><span class="sig-paren">(</span><em>state</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deepchem/rl.html#Policy.create_layers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#deepchem.rl.Policy.create_layers" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the TensorGraph Layers that define the policy.</p>
<p>The arguments always include a list of Feature layers representing the current
state of the environment (one layer for each array in the state).  Depending on
the algorithm being used, other arguments might get passed as well.  It is up
to each algorithm to document that.</p>
<p>This method should construct and return a dict that maps strings to Layer
objects.  Each algorithm must document what Layers it expects the policy to
create.  If this method is called multiple times, it should create a new set
of Layers every time.</p>
</dd></dl>

</dd></dl>

</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="_sources/deepchem.rl.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2016, Stanford University and the Authors.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>