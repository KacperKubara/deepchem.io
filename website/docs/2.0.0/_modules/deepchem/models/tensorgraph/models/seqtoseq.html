<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>deepchem.models.tensorgraph.models.seqtoseq &mdash; deepchem 1.2 documentation</title>
    
    <link rel="stylesheet" href="../../../../../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../../../',
        VERSION:     '1.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../../../../../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../../../../../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../../../../../_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../../../../../_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="deepchem 1.2 documentation" href="../../../../../index.html" />
    <link rel="up" title="Module code" href="../../../../index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-inverse navbar-default ">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../../../index.html"><span><img src="../../../../../_static/logo.png"></span>
          deepchem</a>
        <span class="navbar-text navbar-version pull-left"><b>1.2</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../../../../../notebooks/index.html">Notebooks</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../../../../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../deepchem.html">deepchem package</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"></ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../../../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <h1>Source code for deepchem.models.tensorgraph.models.seqtoseq</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Sequence to sequence translation models.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">deepchem.models</span> <span class="kn">import</span> <span class="n">TensorGraph</span>
<span class="kn">from</span> <span class="nn">deepchem.models.tensorgraph</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">heapq</span> <span class="kn">import</span> <span class="n">heappush</span><span class="p">,</span> <span class="n">heappushpop</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>


<div class="viewcode-block" id="SeqToSeq"><a class="viewcode-back" href="../../../../../deepchem.models.tensorgraph.models.html#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq">[docs]</a><span class="k">class</span> <span class="nc">SeqToSeq</span><span class="p">(</span><span class="n">TensorGraph</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Implements sequence to sequence translation models.</span>

<span class="sd">  The model is based on the description in Sutskever et al., &quot;Sequence to</span>
<span class="sd">  Sequence Learning with Neural Networks&quot; (https://arxiv.org/abs/1409.3215),</span>
<span class="sd">  although this implementation uses GRUs instead of LSTMs.  The goal is to</span>
<span class="sd">  take sequences of tokens as input, and translate each one into a different</span>
<span class="sd">  output sequence.  The input and output sequences can both be of variable</span>
<span class="sd">  length, and an output sequence need not have the same length as the input</span>
<span class="sd">  sequence it was generated from.  For example, these models were originally</span>
<span class="sd">  developed for use in natural language processing.  In that context, the</span>
<span class="sd">  input might be a sequence of English words, and the output might be a</span>
<span class="sd">  sequence of French words.  The goal would be to train the model to translate</span>
<span class="sd">  sentences from English to French.</span>

<span class="sd">  The model consists of two parts called the &quot;encoder&quot; and &quot;decoder&quot;.  Each one</span>
<span class="sd">  consists of a stack of recurrent layers.  The job of the encoder is to</span>
<span class="sd">  transform the input sequence into a single, fixed length vector called the</span>
<span class="sd">  &quot;embedding&quot;.  That vector contains all relevant information from the input</span>
<span class="sd">  sequence.  The decoder then transforms the embedding vector into the output</span>
<span class="sd">  sequence.</span>

<span class="sd">  These models can be used for various purposes.  First and most obviously,</span>
<span class="sd">  they can be used for sequence to sequence translation.  In any case where you</span>
<span class="sd">  have sequences of tokens, and you want to translate each one into a different</span>
<span class="sd">  sequence, a SeqToSeq model can be trained to perform the translation.</span>

<span class="sd">  Another possible use case is transforming variable length sequences into</span>
<span class="sd">  fixed length vectors.  Many types of models require their inputs to have a</span>
<span class="sd">  fixed shape, which makes it difficult to use them with variable sized inputs</span>
<span class="sd">  (for example, when the input is a molecule, and different molecules have</span>
<span class="sd">  different numbers of atoms).  In that case, you can train a SeqToSeq model as</span>
<span class="sd">  an autoencoder, so that it tries to make the output sequence identical to the</span>
<span class="sd">  input one.  That forces the embedding vector to contain all information from</span>
<span class="sd">  the original sequence.  You can then use the encoder for transforming</span>
<span class="sd">  sequences into fixed length embedding vectors, suitable to use as inputs to</span>
<span class="sd">  other types of models.</span>

<span class="sd">  Another use case is to train the decoder for use as a generative model.  Here</span>
<span class="sd">  again you begin by training the SeqToSeq model as an autoencoder.  Once</span>
<span class="sd">  training is complete, you can supply arbitrary embedding vectors, and</span>
<span class="sd">  transform each one into an output sequence.  When used in this way, you</span>
<span class="sd">  typically train it as a variational autoencoder.  This adds random noise to</span>
<span class="sd">  the encoder, and also adds a constraint term to the loss that forces the</span>
<span class="sd">  embedding vector to have a unit Gaussian distribution.  You can then pick</span>
<span class="sd">  random vectors from a Gaussian distribution, and the output sequences should</span>
<span class="sd">  follow the same distribution as the training data.</span>

<span class="sd">  When training as a variational autoencoder, it is best to use KL cost</span>
<span class="sd">  annealing, as described in https://arxiv.org/abs/1511.06349.  The constraint</span>
<span class="sd">  term in the loss is initially set to 0, so the optimizer just tries to</span>
<span class="sd">  minimize the reconstruction loss.  Once it has made reasonable progress</span>
<span class="sd">  toward that, the constraint term can be gradually turned back on.  The range</span>
<span class="sd">  of steps over which this happens is configurable.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="n">sequence_end</span> <span class="o">=</span> <span class="nb">object</span><span class="p">()</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">input_tokens</span><span class="p">,</span>
               <span class="n">output_tokens</span><span class="p">,</span>
               <span class="n">max_output_length</span><span class="p">,</span>
               <span class="n">encoder_layers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
               <span class="n">decoder_layers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
               <span class="n">embedding_dimension</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
               <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
               <span class="n">reverse_input</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
               <span class="n">variational</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
               <span class="n">annealing_start_step</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
               <span class="n">annealing_final_step</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Construct a SeqToSeq model.</span>

<span class="sd">    In addition to the following arguments, this class also accepts all the keyword arguments</span>
<span class="sd">    from TensorGraph.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    input_tokens: list</span>
<span class="sd">      a list of all tokens that may appear in input sequences</span>
<span class="sd">    output_tokens: list</span>
<span class="sd">      a list of all tokens that may appear in output sequences</span>
<span class="sd">    max_output_length: int</span>
<span class="sd">      the maximum length of output sequence that may be generated</span>
<span class="sd">    encoder_layers: int</span>
<span class="sd">      the number of recurrent layers in the encoder</span>
<span class="sd">    decoder_layers: int</span>
<span class="sd">      the number of recurrent layers in the decoder</span>
<span class="sd">    embedding_dimension: int</span>
<span class="sd">      the width of the embedding vector.  This also is the width of all</span>
<span class="sd">      recurrent layers.</span>
<span class="sd">    dropout: float</span>
<span class="sd">      the dropout probability to use during training</span>
<span class="sd">    reverse_input: bool</span>
<span class="sd">      if True, reverse the order of input sequences before sending them into</span>
<span class="sd">      the encoder.  This can improve performance when working with long sequences.</span>
<span class="sd">    variational: bool</span>
<span class="sd">      if True, train the model as a variational autoencoder.  This adds random</span>
<span class="sd">      noise to the encoder, and also constrains the embedding to follow a unit</span>
<span class="sd">      Gaussian distribution.</span>
<span class="sd">    annealing_start_step: int</span>
<span class="sd">      the step (that is, batch) at which to begin turning on the constraint term</span>
<span class="sd">      for KL cost annealing</span>
<span class="sd">    annealing_final_step: int</span>
<span class="sd">      the step (that is, batch) at which to finish turning on the constraint term</span>
<span class="sd">      for KL cost annealing</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">SeqToSeq</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">use_queue</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># TODO can we make it work with the queue?</span>
    <span class="k">if</span> <span class="n">SeqToSeq</span><span class="o">.</span><span class="n">sequence_end</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">input_tokens</span><span class="p">:</span>
      <span class="n">input_tokens</span> <span class="o">=</span> <span class="n">input_tokens</span> <span class="o">+</span> <span class="p">[</span><span class="n">SeqToSeq</span><span class="o">.</span><span class="n">sequence_end</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">SeqToSeq</span><span class="o">.</span><span class="n">sequence_end</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">output_tokens</span><span class="p">:</span>
      <span class="n">output_tokens</span> <span class="o">=</span> <span class="n">output_tokens</span> <span class="o">+</span> <span class="p">[</span><span class="n">SeqToSeq</span><span class="o">.</span><span class="n">sequence_end</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_input_tokens</span> <span class="o">=</span> <span class="n">input_tokens</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_output_tokens</span> <span class="o">=</span> <span class="n">output_tokens</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_input_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_output_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">output_tokens</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_max_output_length</span> <span class="o">=</span> <span class="n">max_output_length</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_dimension</span> <span class="o">=</span> <span class="n">embedding_dimension</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_annealing_final_step</span> <span class="o">=</span> <span class="n">annealing_final_step</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_annealing_start_step</span> <span class="o">=</span> <span class="n">annealing_start_step</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_features</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_tokens</span><span class="p">)))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_labels</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Label</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_tokens</span><span class="p">)))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_gather_indices</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Feature</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reverse_input</span> <span class="o">=</span> <span class="n">reverse_input</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_variational</span> <span class="o">=</span> <span class="n">variational</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_encoder</span><span class="p">(</span><span class="n">encoder_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_decoder</span><span class="p">(</span><span class="n">decoder_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">set_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_create_loss</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_output</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_create_encoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create the encoder layers.&quot;&quot;&quot;</span>
    <span class="n">prev_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_features</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">dropout</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="n">prev_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">prev_layer</span><span class="p">)</span>
      <span class="n">prev_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_dimension</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">prev_layer</span><span class="p">)</span>
    <span class="n">prev_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Gather</span><span class="p">(</span><span class="n">in_layers</span><span class="o">=</span><span class="p">[</span><span class="n">prev_layer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gather_indices</span><span class="p">])</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_variational</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_mean</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_dimension</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">prev_layer</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_stddev</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_dimension</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">prev_layer</span><span class="p">)</span>
      <span class="n">prev_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">CombineMeanStd</span><span class="p">(</span>
          <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_embedding_mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_stddev</span><span class="p">],</span> <span class="n">training_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">prev_layer</span>

  <span class="k">def</span> <span class="nf">_create_decoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create the decoder layers.&quot;&quot;&quot;</span>
    <span class="n">prev_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Repeat</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_max_output_length</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">dropout</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="n">prev_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">prev_layer</span><span class="p">)</span>
      <span class="n">prev_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_dimension</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">prev_layer</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_tokens</span><span class="p">),</span>
        <span class="n">in_layers</span><span class="o">=</span><span class="n">prev_layer</span><span class="p">,</span>
        <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_create_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create the loss function.&quot;&quot;&quot;</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">log_prob</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Log</span><span class="p">(</span><span class="n">prob</span> <span class="o">+</span> <span class="mf">1e-20</span><span class="p">)</span> <span class="o">*</span> <span class="n">mask</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">layers</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">(</span><span class="n">log_prob</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_variational</span><span class="p">:</span>
      <span class="n">mean_sq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_mean</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_mean</span>
      <span class="n">stddev_sq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_stddev</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_stddev</span>
      <span class="n">kl</span> <span class="o">=</span> <span class="n">mean_sq</span> <span class="o">+</span> <span class="n">stddev_sq</span> <span class="o">-</span> <span class="n">layers</span><span class="o">.</span><span class="n">Log</span><span class="p">(</span><span class="n">stddev_sq</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
      <span class="n">anneal_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_annealing_final_step</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_annealing_start_step</span>
      <span class="k">if</span> <span class="n">anneal_steps</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">current_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">get_global_step</span><span class="p">())</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_annealing_start_step</span>
        <span class="n">anneal_frac</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">current_step</span><span class="p">)</span> <span class="o">/</span> <span class="n">anneal_steps</span>
        <span class="n">kl_scale</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">TensorWrapper</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">anneal_frac</span> <span class="o">*</span> <span class="n">anneal_frac</span><span class="p">))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">kl_scale</span> <span class="o">=</span> <span class="mf">1.0</span>
      <span class="n">loss</span> <span class="o">+=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">kl_scale</span> <span class="o">*</span> <span class="n">layers</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">(</span><span class="n">kl</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">loss</span>

<div class="viewcode-block" id="SeqToSeq.fit_sequences"><a class="viewcode-back" href="../../../../../deepchem.models.tensorgraph.models.html#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.fit_sequences">[docs]</a>  <span class="k">def</span> <span class="nf">fit_sequences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                    <span class="n">sequences</span><span class="p">,</span>
                    <span class="n">max_checkpoints_to_keep</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                    <span class="n">checkpoint_interval</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                    <span class="n">restore</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Train this model on a set of sequences</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sequences: iterable</span>
<span class="sd">      the training samples to fit to.  Each sample should be</span>
<span class="sd">      represented as a tuple of the form (input_sequence, output_sequence).</span>
<span class="sd">    max_checkpoints_to_keep: int</span>
<span class="sd">      the maximum number of checkpoints to keep.  Older checkpoints are discarded.</span>
<span class="sd">    checkpoint_interval: int</span>
<span class="sd">      the frequency at which to write checkpoints, measured in training steps.</span>
<span class="sd">    restore: bool</span>
<span class="sd">      if True, restore the model from the most recent checkpoint and continue training</span>
<span class="sd">      from there.  If False, retrain the model from scratch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_generate_batches</span><span class="p">(</span><span class="n">sequences</span><span class="p">),</span>
        <span class="n">max_checkpoints_to_keep</span><span class="o">=</span><span class="n">max_checkpoints_to_keep</span><span class="p">,</span>
        <span class="n">checkpoint_interval</span><span class="o">=</span><span class="n">checkpoint_interval</span><span class="p">,</span>
        <span class="n">restore</span><span class="o">=</span><span class="n">restore</span><span class="p">)</span></div>

<div class="viewcode-block" id="SeqToSeq.predict_from_sequences"><a class="viewcode-back" href="../../../../../deepchem.models.tensorgraph.models.html#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_from_sequences">[docs]</a>  <span class="k">def</span> <span class="nf">predict_from_sequences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequences</span><span class="p">,</span> <span class="n">beam_width</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Given a set of input sequences, predict the output sequences.</span>

<span class="sd">    The prediction is done using a beam search with length normalization.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sequences: iterable</span>
<span class="sd">      the input sequences to generate a prediction for</span>
<span class="sd">    beam_width: int</span>
<span class="sd">      the beam width to use for searching.  Set to 1 to use a simple greedy search.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_tf</span><span class="p">(</span><span class="s2">&quot;Graph&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_elements</span><span class="p">(</span><span class="n">sequences</span><span class="p">):</span>
        <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_features</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_input_array</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_gather_indices</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                                            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
                                           <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)]</span>
        <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_training_placeholder</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">initial</span><span class="p">,</span> <span class="n">zero</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_initial_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_zero_states</span><span class="p">):</span>
          <span class="n">feed_dict</span><span class="p">[</span><span class="n">initial</span><span class="p">]</span> <span class="o">=</span> <span class="n">zero</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)):</span>
          <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_beam_search</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">beam_width</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="SeqToSeq.predict_from_embeddings"><a class="viewcode-back" href="../../../../../deepchem.models.tensorgraph.models.html#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_from_embeddings">[docs]</a>  <span class="k">def</span> <span class="nf">predict_from_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">beam_width</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Given a set of embedding vectors, predict the output sequences.</span>

<span class="sd">    The prediction is done using a beam search with length normalization.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    embeddings: iterable</span>
<span class="sd">      the embedding vectors to generate predictions for</span>
<span class="sd">    beam_width: int</span>
<span class="sd">      the beam width to use for searching.  Set to 1 to use a simple greedy search.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_tf</span><span class="p">(</span><span class="s2">&quot;Graph&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_elements</span><span class="p">(</span><span class="n">embeddings</span><span class="p">):</span>
        <span class="n">embedding_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_dimension</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
          <span class="n">embedding_array</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">e</span>
        <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">]</span> <span class="o">=</span> <span class="n">embedding_array</span>
        <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_training_placeholder</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">initial</span><span class="p">,</span> <span class="n">zero</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_initial_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_zero_states</span><span class="p">):</span>
          <span class="n">feed_dict</span><span class="p">[</span><span class="n">initial</span><span class="p">]</span> <span class="o">=</span> <span class="n">zero</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)):</span>
          <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_beam_search</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">beam_width</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="SeqToSeq.predict_embeddings"><a class="viewcode-back" href="../../../../../deepchem.models.tensorgraph.models.html#deepchem.models.tensorgraph.models.seqtoseq.SeqToSeq.predict_embeddings">[docs]</a>  <span class="k">def</span> <span class="nf">predict_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequences</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Given a set of input sequences, compute the embedding vectors.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sequences: iterable</span>
<span class="sd">      the input sequences to generate an embedding vector for</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_tf</span><span class="p">(</span><span class="s2">&quot;Graph&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_elements</span><span class="p">(</span><span class="n">sequences</span><span class="p">):</span>
        <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_features</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_input_array</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_gather_indices</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                                            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
                                           <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)]</span>
        <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_training_placeholder</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">initial</span><span class="p">,</span> <span class="n">zero</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_initial_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_zero_states</span><span class="p">):</span>
          <span class="n">feed_dict</span><span class="p">[</span><span class="n">initial</span><span class="p">]</span> <span class="o">=</span> <span class="n">zero</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)):</span>
          <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">embeddings</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="nf">_beam_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">beam_width</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Perform a beam search for the most likely output sequence.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">beam_width</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="c1"># Do a simple greedy search.</span>

      <span class="n">s</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">probs</span><span class="p">)):</span>
        <span class="n">token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_tokens</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs</span><span class="p">[</span><span class="n">i</span><span class="p">])]</span>
        <span class="k">if</span> <span class="n">token</span> <span class="o">==</span> <span class="n">SeqToSeq</span><span class="o">.</span><span class="n">sequence_end</span><span class="p">:</span>
          <span class="k">break</span>
        <span class="n">s</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">s</span>

    <span class="c1"># Do a beam search with length normalization.</span>

    <span class="n">logprobs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
    <span class="c1"># Represent each candidate as (normalized prob, raw prob, sequence)</span>
    <span class="n">candidates</span> <span class="o">=</span> <span class="p">[(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="p">[])]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">logprobs</span><span class="p">)):</span>
      <span class="n">new_candidates</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">candidates</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">c</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">SeqToSeq</span><span class="o">.</span><span class="n">sequence_end</span><span class="p">:</span>
          <span class="c1"># This candidate sequence has already been terminated</span>
          <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_candidates</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">beam_width</span><span class="p">:</span>
            <span class="n">heappush</span><span class="p">(</span><span class="n">new_candidates</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">heappushpop</span><span class="p">(</span><span class="n">new_candidates</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="c1"># Consider all possible tokens we could add to this candidate sequence.</span>
          <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">logprob</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">logprobs</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span>
            <span class="n">new_logprob</span> <span class="o">=</span> <span class="n">logprob</span> <span class="o">+</span> <span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">newc</span> <span class="o">=</span> <span class="p">(</span><span class="n">new_logprob</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">new_logprob</span><span class="p">,</span>
                    <span class="n">c</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_tokens</span><span class="p">[</span><span class="n">j</span><span class="p">]])</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_candidates</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">beam_width</span><span class="p">:</span>
              <span class="n">heappush</span><span class="p">(</span><span class="n">new_candidates</span><span class="p">,</span> <span class="n">newc</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
              <span class="n">heappushpop</span><span class="p">(</span><span class="n">new_candidates</span><span class="p">,</span> <span class="n">newc</span><span class="p">)</span>
      <span class="n">candidates</span> <span class="o">=</span> <span class="n">new_candidates</span>
    <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">candidates</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">_create_input_array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequences</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create the array describing the input sequences for a batch.&quot;&quot;&quot;</span>
    <span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sequences</span><span class="p">]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reverse_input</span><span class="p">:</span>
      <span class="n">sequences</span> <span class="o">=</span> <span class="p">[</span><span class="nb">reversed</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sequences</span><span class="p">]</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_tokens</span><span class="p">)),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sequences</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sequence</span><span class="p">):</span>
        <span class="n">features</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dict</span><span class="p">[</span><span class="n">token</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">features</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sequences</span><span class="p">)),</span> <span class="n">lengths</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_dict</span><span class="p">[</span>
        <span class="n">SeqToSeq</span><span class="o">.</span><span class="n">sequence_end</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">features</span>

  <span class="k">def</span> <span class="nf">_create_output_array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequences</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create the array describing the target sequences for a batch.&quot;&quot;&quot;</span>
    <span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sequences</span><span class="p">]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_output_length</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_tokens</span><span class="p">)),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">end_marker_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_dict</span><span class="p">[</span><span class="n">SeqToSeq</span><span class="o">.</span><span class="n">sequence_end</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sequences</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sequence</span><span class="p">):</span>
        <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_dict</span><span class="p">[</span><span class="n">token</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="k">if</span> <span class="n">lengths</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_output_length</span><span class="p">:</span>
        <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">lengths</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">end_marker_index</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">labels</span>

  <span class="k">def</span> <span class="nf">_batch_elements</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">elements</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Combine elements into batches.&quot;&quot;&quot;</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">elements</span><span class="p">:</span>
      <span class="n">batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">batch</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">yield</span> <span class="n">batch</span>

  <span class="k">def</span> <span class="nf">_generate_batches</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequences</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create feed_dicts for fitting.&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_elements</span><span class="p">(</span><span class="n">sequences</span><span class="p">):</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
        <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
      <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{}</span>
      <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_features</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_input_array</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
      <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_labels</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_output_array</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
      <span class="n">feed_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_gather_indices</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
                                         <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inputs</span><span class="p">)]</span>
      <span class="k">for</span> <span class="n">initial</span><span class="p">,</span> <span class="n">zero</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_initial_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_zero_states</span><span class="p">):</span>
        <span class="n">feed_dict</span><span class="p">[</span><span class="n">initial</span><span class="p">]</span> <span class="o">=</span> <span class="n">zero</span>
      <span class="k">yield</span> <span class="n">feed_dict</span></div>
</pre></div>

    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
      
    </p>
    <p>
        &copy; Copyright 2016, Stanford University and the Authors.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>