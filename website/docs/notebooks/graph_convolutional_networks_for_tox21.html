<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Graph Convolutions For Tox21 &mdash; deepchem 1.3.1 documentation</title>
    
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '1.3.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="deepchem 1.3.1 documentation" href="../index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-inverse navbar-default ">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><span><img src="../_static/logo.png"></span>
          deepchem</a>
        <span class="navbar-text navbar-version pull-left"><b>1.3</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="index.html">Notebooks</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../deepchem.html">deepchem package</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Graph Convolutions For Tox21</a></li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="graph-convolutions-for-tox21">
<h1>Graph Convolutions For Tox21<a class="headerlink" href="#graph-convolutions-for-tox21" title="Permalink to this headline">¶</a></h1>
<p>In this notebook, we will explore the use of TensorGraph to create graph
convolutional models with DeepChem. In particular, we will build a graph
convolutional network on the Tox21 dataset.</p>
<p>Let’s start with some basic imports.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">unicode_literals</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">deepchem</span> <span class="kn">as</span> <span class="nn">dc</span>
<span class="kn">from</span> <span class="nn">deepchem.models.tensorgraph.models.graph_models</span> <span class="kn">import</span> <span class="n">GraphConvTensorGraph</span>
</pre></div>
</div>
<p>Now, let’s use MoleculeNet to load the Tox21 dataset. We need to make
sure to process the data in a way that graph convolutional networks can
use For that, we make sure to set the featurizer option to ‘GraphConv’.
The MoleculeNet call will return a training set, an validation set, and
a test set for us to use. The call also returns <code class="docutils literal"><span class="pre">transformers</span></code>, a list
of data transformations that were applied to preprocess the dataset.
(Most deep networks are quite finicky and require a set of data
transformations to ensure that training proceeds stably.)</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="c1"># Load Tox21 dataset</span>
<span class="n">tox21_tasks</span><span class="p">,</span> <span class="n">tox21_datasets</span><span class="p">,</span> <span class="n">transformers</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">molnet</span><span class="o">.</span><span class="n">load_tox21</span><span class="p">(</span><span class="n">featurizer</span><span class="o">=</span><span class="s1">&#39;GraphConv&#39;</span><span class="p">)</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">tox21_datasets</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span>Loading dataset from disk.
Loading dataset from disk.
Loading dataset from disk.
</pre></div>
</div>
<p>Let’s now train a graph convolutional network on this dataset. DeepChem
has the class <code class="docutils literal"><span class="pre">GraphConvTensorGraph</span></code> that wraps a standard graph
convolutional architecture underneath the hood for user convenience.
Let’s instantiate an object of this class and train it on our dataset.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">GraphConvTensorGraph</span><span class="p">(</span>
    <span class="nb">len</span><span class="p">(</span><span class="n">tox21_tasks</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">)</span>
<span class="c1"># Set nb_epoch=10 for better results.</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">nb_epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span>/home/leswing/miniconda3/envs/deepchem/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  &quot;Converting sparse IndexedSlices to a dense Tensor of unknown shape. &quot;
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span>Starting epoch 0
Ending global_step 126: Average loss 590.739
TIMING: model fitting took 7.317 s
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="mf">590.7391258118645</span>
</pre></div>
</div>
<p>Let’s try to evaluate the performance of the model we’ve trained. For
this, we need to define a metric, a measure of model performance.
<code class="docutils literal"><span class="pre">dc.metrics</span></code> holds a collection of metrics already. For this dataset,
it is standard to use the ROC-AUC score, the area under the receiver
operating characteristic curve (which measures the tradeoff between
precision and recall). Luckily, the ROC-AUC score is already available
in DeepChem.</p>
<p>To measure the performance of the model under this metric, we can use
the convenience function <code class="docutils literal"><span class="pre">model.evaluate()</span></code>.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="n">metric</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">(</span>
    <span class="n">dc</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Evaluating model&quot;</span><span class="p">)</span>
<span class="n">train_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">metric</span><span class="p">],</span> <span class="n">transformers</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Training ROC-AUC Score: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">train_scores</span><span class="p">[</span><span class="s2">&quot;mean-roc_auc_score&quot;</span><span class="p">])</span>
<span class="n">valid_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">metric</span><span class="p">],</span> <span class="n">transformers</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Validation ROC-AUC Score: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">valid_scores</span><span class="p">[</span><span class="s2">&quot;mean-roc_auc_score&quot;</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span>Evaluating model
computed_metrics: [0.80045699830862893, 0.83618637604367374, 0.83908539936708681, 0.77873855933094183, 0.67692252993044244, 0.75578036941489168, 0.75895796821704797, 0.70234314980793855, 0.76387081283102387, 0.65924917162534913, 0.78448201448364341, 0.76675448900822296]
Training ROC-AUC Score: 0.760236
computed_metrics: [0.71533171721169553, 0.74090608465608465, 0.81106357802757933, 0.70627859684799188, 0.63177272727272715, 0.6326016835811501, 0.61491865697473169, 0.71286314850043442, 0.67676006592889104, 0.51656328658755846, 0.75414979999520937, 0.6603359173126615]
Validation ROC-AUC Score: 0.681129
</pre></div>
</div>
<p>What’s going on under the hood? Could we build <code class="docutils literal"><span class="pre">GraphConvTensorGraph</span></code>
ourselves? Of course! The first step is to create a <code class="docutils literal"><span class="pre">TensorGraph</span></code>
object. This object will hold the “computational graph” that defines the
computation that a graph convolutional network will perform.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deepchem.models.tensorgraph.tensor_graph</span> <span class="kn">import</span> <span class="n">TensorGraph</span>

<span class="n">tg</span> <span class="o">=</span> <span class="n">TensorGraph</span><span class="p">(</span><span class="n">use_queue</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s now define the inputs to our model. Conceptually, graph
convolutions just requires a the structure of the molecule in question
and a vector of features for every atom that describes the local
chemical environment. However in practice, due to TensorFlow’s
limitations as a general programming environment, we have to have some
auxiliary information as well preprocessed.</p>
<p><code class="docutils literal"><span class="pre">atom_features</span></code> holds a feature vector of length 75 for each atom. The
other feature inputs are required to support minibatching in TensorFlow.
<code class="docutils literal"><span class="pre">degree_slice</span></code> is an indexing convenience that makes it easy to locate
atoms from all molecules with a given degree. <code class="docutils literal"><span class="pre">membership</span></code> determines
the membership of atoms in molecules (atom <code class="docutils literal"><span class="pre">i</span></code> belongs to molecule
<code class="docutils literal"><span class="pre">membership[i]</span></code>). <code class="docutils literal"><span class="pre">deg_adjs</span></code> is a list that contains adjacency lists
grouped by atom degree For more details, check out the
<a class="reference external" href="https://github.com/deepchem/deepchem/blob/master/deepchem/feat/mol_graphs.py">code</a>.</p>
<p>To define feature inputs in <code class="docutils literal"><span class="pre">TensorGraph</span></code>, we use the <code class="docutils literal"><span class="pre">Feature</span></code>
layer. Conceptually, a <code class="docutils literal"><span class="pre">TensorGraph</span></code> is a mathematical graph composed
of layer objects. <code class="docutils literal"><span class="pre">Features</span></code> layers have to be the root nodes of the
graph since they consitute inputs.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deepchem.models.tensorgraph.layers</span> <span class="kn">import</span> <span class="n">Feature</span>

<span class="n">atom_features</span> <span class="o">=</span> <span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">75</span><span class="p">))</span>
<span class="n">degree_slice</span> <span class="o">=</span> <span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">membership</span> <span class="o">=</span> <span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

<span class="n">deg_adjs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">deg_adj</span> <span class="o">=</span> <span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">deg_adjs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">deg_adj</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s now implement the body of the graph convolutional network.
<code class="docutils literal"><span class="pre">TensorGraph</span></code> has a number of layers that encode various graph
operations. Namely, the <code class="docutils literal"><span class="pre">GraphConv</span></code>, <code class="docutils literal"><span class="pre">GraphPool</span></code> and <code class="docutils literal"><span class="pre">GraphGather</span></code>
layers. We will also apply standard neural network layers such as
<code class="docutils literal"><span class="pre">Dense</span></code> and <code class="docutils literal"><span class="pre">BatchNorm</span></code>.</p>
<p>The layers we’re adding effect a “feature transformation” that will
create one vector for each molecule.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deepchem.models.tensorgraph.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">GraphConv</span><span class="p">,</span> <span class="n">BatchNorm</span>
<span class="kn">from</span> <span class="nn">deepchem.models.tensorgraph.layers</span> <span class="kn">import</span> <span class="n">GraphPool</span><span class="p">,</span> <span class="n">GraphGather</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">gc1</span> <span class="o">=</span> <span class="n">GraphConv</span><span class="p">(</span>
    <span class="mi">64</span><span class="p">,</span>
    <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
    <span class="n">in_layers</span><span class="o">=</span><span class="p">[</span><span class="n">atom_features</span><span class="p">,</span> <span class="n">degree_slice</span><span class="p">,</span> <span class="n">membership</span><span class="p">]</span> <span class="o">+</span> <span class="n">deg_adjs</span><span class="p">)</span>
<span class="n">batch_norm1</span> <span class="o">=</span> <span class="n">BatchNorm</span><span class="p">(</span><span class="n">in_layers</span><span class="o">=</span><span class="p">[</span><span class="n">gc1</span><span class="p">])</span>
<span class="n">gp1</span> <span class="o">=</span> <span class="n">GraphPool</span><span class="p">(</span><span class="n">in_layers</span><span class="o">=</span><span class="p">[</span><span class="n">batch_norm1</span><span class="p">,</span> <span class="n">degree_slice</span><span class="p">,</span> <span class="n">membership</span><span class="p">]</span> <span class="o">+</span> <span class="n">deg_adjs</span><span class="p">)</span>
<span class="n">gc2</span> <span class="o">=</span> <span class="n">GraphConv</span><span class="p">(</span>
    <span class="mi">64</span><span class="p">,</span>
    <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
    <span class="n">in_layers</span><span class="o">=</span><span class="p">[</span><span class="n">gp1</span><span class="p">,</span> <span class="n">degree_slice</span><span class="p">,</span> <span class="n">membership</span><span class="p">]</span> <span class="o">+</span> <span class="n">deg_adjs</span><span class="p">)</span>
<span class="n">batch_norm2</span> <span class="o">=</span> <span class="n">BatchNorm</span><span class="p">(</span><span class="n">in_layers</span><span class="o">=</span><span class="p">[</span><span class="n">gc2</span><span class="p">])</span>
<span class="n">gp2</span> <span class="o">=</span> <span class="n">GraphPool</span><span class="p">(</span><span class="n">in_layers</span><span class="o">=</span><span class="p">[</span><span class="n">batch_norm2</span><span class="p">,</span> <span class="n">degree_slice</span><span class="p">,</span> <span class="n">membership</span><span class="p">]</span> <span class="o">+</span> <span class="n">deg_adjs</span><span class="p">)</span>
<span class="n">dense</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">out_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="p">[</span><span class="n">gp2</span><span class="p">])</span>
<span class="n">batch_norm3</span> <span class="o">=</span> <span class="n">BatchNorm</span><span class="p">(</span><span class="n">in_layers</span><span class="o">=</span><span class="p">[</span><span class="n">dense</span><span class="p">])</span>
<span class="n">readout</span> <span class="o">=</span> <span class="n">GraphGather</span><span class="p">(</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span>
    <span class="n">in_layers</span><span class="o">=</span><span class="p">[</span><span class="n">batch_norm3</span><span class="p">,</span> <span class="n">degree_slice</span><span class="p">,</span> <span class="n">membership</span><span class="p">]</span> <span class="o">+</span> <span class="n">deg_adjs</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s now make predictions from the <code class="docutils literal"><span class="pre">TensorGraph</span></code> model. Tox21 is a
multitask dataset. That is, there are 12 different datasets grouped
together, which share many common molecules, but with different outputs
for each. As a result, we have to add a separate output layer for each
task. We will use a <code class="docutils literal"><span class="pre">for</span></code> loop over the <code class="docutils literal"><span class="pre">tox21_tasks</span></code> list to make
this happen. We need to add labels for each</p>
<p>We also have to define a loss for the model which tells the network the
objective to minimize during training.</p>
<p>We have to tell <code class="docutils literal"><span class="pre">TensorGraph</span></code> which layers are outputs with
<code class="docutils literal"><span class="pre">TensorGraph.add_output(layer)</span></code>. Similarly, we tell the network its
loss with <code class="docutils literal"><span class="pre">TensorGraph.set_loss(loss)</span></code>.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deepchem.models.tensorgraph.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">SoftMax</span><span class="p">,</span> \
    <span class="n">SoftMaxCrossEntropy</span><span class="p">,</span> <span class="n">WeightedError</span><span class="p">,</span> <span class="n">Stack</span>
<span class="kn">from</span> <span class="nn">deepchem.models.tensorgraph.layers</span> <span class="kn">import</span> <span class="n">Label</span><span class="p">,</span> <span class="n">Weights</span>

<span class="n">costs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tox21_tasks</span><span class="p">)):</span>
    <span class="n">classification</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span>
        <span class="n">out_channels</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="p">[</span><span class="n">readout</span><span class="p">])</span>

    <span class="n">softmax</span> <span class="o">=</span> <span class="n">SoftMax</span><span class="p">(</span><span class="n">in_layers</span><span class="o">=</span><span class="p">[</span><span class="n">classification</span><span class="p">])</span>
    <span class="n">tg</span><span class="o">.</span><span class="n">add_output</span><span class="p">(</span><span class="n">softmax</span><span class="p">)</span>

    <span class="n">label</span> <span class="o">=</span> <span class="n">Label</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">SoftMaxCrossEntropy</span><span class="p">(</span><span class="n">in_layers</span><span class="o">=</span><span class="p">[</span><span class="n">label</span><span class="p">,</span> <span class="n">classification</span><span class="p">])</span>
    <span class="n">costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
<span class="n">all_cost</span> <span class="o">=</span> <span class="n">Stack</span><span class="p">(</span><span class="n">in_layers</span><span class="o">=</span><span class="n">costs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">Weights</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tox21_tasks</span><span class="p">)))</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">WeightedError</span><span class="p">(</span><span class="n">in_layers</span><span class="o">=</span><span class="p">[</span><span class="n">all_cost</span><span class="p">,</span> <span class="n">weights</span><span class="p">])</span>
<span class="n">tg</span><span class="o">.</span><span class="n">set_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
<p>Now that we’ve successfully defined our graph convolutional model in
<code class="docutils literal"><span class="pre">TensorGraph</span></code>, we need to train it. We can call <code class="docutils literal"><span class="pre">fit()</span></code>, but we need
to make sure that each minibatch of data populates all four <code class="docutils literal"><span class="pre">Feature</span></code>
objects that we’ve created. For this, we need to create a Python
generator that given a batch of data generates a dictionary whose keys
are the <code class="docutils literal"><span class="pre">Feature</span></code> layers and whose values are Numpy arrays we’d like
to use for this step of training.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deepchem.metrics</span> <span class="kn">import</span> <span class="n">to_one_hot</span>
<span class="kn">from</span> <span class="nn">deepchem.feat.mol_graphs</span> <span class="kn">import</span> <span class="n">ConvMol</span>

<span class="k">def</span> <span class="nf">data_generator</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">predict</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">pad_batches</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">predict</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Starting epoch </span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">epoch</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="p">(</span><span class="n">X_b</span><span class="p">,</span> <span class="n">y_b</span><span class="p">,</span> <span class="n">w_b</span><span class="p">,</span> <span class="n">ids_b</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">iterbatches</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="n">pad_batches</span><span class="o">=</span><span class="n">pad_batches</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="bp">True</span><span class="p">)):</span>
      <span class="n">d</span> <span class="o">=</span> <span class="p">{}</span>
      <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
        <span class="n">d</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">to_one_hot</span><span class="p">(</span><span class="n">y_b</span><span class="p">[:,</span> <span class="n">index</span><span class="p">])</span>
      <span class="n">d</span><span class="p">[</span><span class="n">weights</span><span class="p">]</span> <span class="o">=</span> <span class="n">w_b</span>
      <span class="n">multiConvMol</span> <span class="o">=</span> <span class="n">ConvMol</span><span class="o">.</span><span class="n">agglomerate_mols</span><span class="p">(</span><span class="n">X_b</span><span class="p">)</span>
      <span class="n">d</span><span class="p">[</span><span class="n">atom_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">multiConvMol</span><span class="o">.</span><span class="n">get_atom_features</span><span class="p">()</span>
      <span class="n">d</span><span class="p">[</span><span class="n">degree_slice</span><span class="p">]</span> <span class="o">=</span> <span class="n">multiConvMol</span><span class="o">.</span><span class="n">deg_slice</span>
      <span class="n">d</span><span class="p">[</span><span class="n">membership</span><span class="p">]</span> <span class="o">=</span> <span class="n">multiConvMol</span><span class="o">.</span><span class="n">membership</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">multiConvMol</span><span class="o">.</span><span class="n">get_deg_adjacency_lists</span><span class="p">())):</span>
        <span class="n">d</span><span class="p">[</span><span class="n">deg_adjs</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">multiConvMol</span><span class="o">.</span><span class="n">get_deg_adjacency_lists</span><span class="p">()[</span><span class="n">i</span><span class="p">]</span>
      <span class="k">yield</span> <span class="n">d</span>
</pre></div>
</div>
<p>Now, we can train the model using
<code class="docutils literal"><span class="pre">TensorGraph.fit_generator(generator)</span></code> which will use the generator
we’ve defined to train the model.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="c1"># Epochs set to 1 to render tutorials online.</span>
<span class="c1"># Set epochs=10 for better results.</span>
<span class="n">tg</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">(</span><span class="n">data_generator</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span>Starting epoch 0
Ending global_step 251: Average loss 530.84
TIMING: model fitting took 6.949 s
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="mf">530.8396410260882</span>
</pre></div>
</div>
<p>Now that we have trained our graph convolutional method, let’s evaluate
its performance. We again have to use our defined generator to evaluate
model performance.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="n">metric</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">(</span>
    <span class="n">dc</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">reshape_y_pred</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    TensorGraph.Predict returns a list of arrays, one for each output</span>
<span class="sd">    We also have to remove the padding on the last batch</span>
<span class="sd">    Metrics taks results of shape (samples, n_task, prob_of_class)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">retval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">retval</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]</span>


<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Evaluating model&quot;</span><span class="p">)</span>
<span class="n">train_predictions</span> <span class="o">=</span> <span class="n">tg</span><span class="o">.</span><span class="n">predict_on_generator</span><span class="p">(</span><span class="n">data_generator</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">predict</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="n">train_predictions</span> <span class="o">=</span> <span class="n">reshape_y_pred</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">train_predictions</span><span class="p">)</span>
<span class="n">train_scores</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute_metric</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">train_predictions</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">w</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Training ROC-AUC Score: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">train_scores</span><span class="p">)</span>

<span class="n">valid_predictions</span> <span class="o">=</span> <span class="n">tg</span><span class="o">.</span><span class="n">predict_on_generator</span><span class="p">(</span><span class="n">data_generator</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="n">predict</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="n">valid_predictions</span> <span class="o">=</span> <span class="n">reshape_y_pred</span><span class="p">(</span><span class="n">valid_dataset</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">valid_predictions</span><span class="p">)</span>
<span class="n">valid_scores</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute_metric</span><span class="p">(</span><span class="n">valid_dataset</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">valid_predictions</span><span class="p">,</span> <span class="n">valid_dataset</span><span class="o">.</span><span class="n">w</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Valid ROC-AUC Score: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">valid_scores</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span>Evaluating model
computed_metrics: [0.83463194036351052, 0.86218739964675661, 0.84894031662657832, 0.80217986671584707, 0.70559942152332189, 0.79751934844253025, 0.8103057689046107, 0.71659210162938414, 0.80849247997327445, 0.72071717294380933, 0.83433314746710274, 0.78304357554399506]
Training ROC-AUC Score: 0.793712
computed_metrics: [0.78221936377578793, 0.78993055555555547, 0.81705388431256543, 0.77777071682765631, 0.66802272727272727, 0.67197702777122181, 0.64295604015230179, 0.72305596655628368, 0.74692724275959499, 0.63050611290902547, 0.80023473616134511, 0.73880275624461667]
Valid ROC-AUC Score: 0.732455
</pre></div>
</div>
<p>Success! The model we’ve constructed behaves nearly identically to
<code class="docutils literal"><span class="pre">GraphConvTensorGraph</span></code>. If you’re looking to build your own custom
models, you can follow the example we’ve provided here to do so. We hope
to see exciting constructions from your end soon!</p>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="../_sources/notebooks/graph_convolutional_networks_for_tox21.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2016, Stanford University and the Authors.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>