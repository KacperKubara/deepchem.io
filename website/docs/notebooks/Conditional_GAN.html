<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Conditional Generative Adversarial Network &mdash; deepchem 1.3.1 documentation</title>
    
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '1.3.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="deepchem 1.3.1 documentation" href="../index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-inverse navbar-default ">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><span><img src="../_static/logo.png"></span>
          deepchem</a>
        <span class="navbar-text navbar-version pull-left"><b>1.3</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="index.html">Notebooks</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../deepchem.html">deepchem package</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Conditional Generative Adversarial Network</a></li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="conditional-generative-adversarial-network">
<h1>Conditional Generative Adversarial Network<a class="headerlink" href="#conditional-generative-adversarial-network" title="Permalink to this headline">¶</a></h1>
<p><em>Note: This example implements a GAN from scratch. The same model could
be implemented much more easily with the ``dc.models.GAN`` class. See
the MNIST GAN notebook for an example of using that class. It can still
be useful to know how to implement a GAN from scratch for advanced
situations that are beyond the scope of what the standard GAN class
supports.</em></p>
<p>A Generative Adversarial Network (GAN) is a type of generative model. It
consists of two parts called the “generator” and the “discriminator”.
The generator takes random values as input and transforms them into an
output that (hopefully) resembles the training data. The discriminator
takes a set of samples as input and tries to distinguish the real
training samples from the ones created by the generator. Both of them
are trained together. The discriminator tries to get better and better
at telling real from false data, while the generator tries to get better
and better at fooling the discriminator.</p>
<p>A Conditional GAN (CGAN) allows additional inputs to the generator and
discriminator that their output is conditioned on. For example, this
might be a class label, and the GAN tries to learn how the data
distribution varies between classes.</p>
<p>For this example, we will create a data distribution consisting of a set
of ellipses in 2D, each with a random position, shape, and orientation.
Each class corresponds to a different ellipse. Let’s randomly generate
the ellipses.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">deepchem</span> <span class="kn">as</span> <span class="nn">dc</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="n">n_classes</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">class_centers</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="p">(</span><span class="n">n_classes</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">class_transforms</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">):</span>
    <span class="n">xscale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">yscale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">angle</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="p">[[</span><span class="n">xscale</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angle</span><span class="p">),</span> <span class="o">-</span><span class="n">yscale</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angle</span><span class="p">)],</span>
         <span class="p">[</span><span class="n">xscale</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angle</span><span class="p">),</span> <span class="n">yscale</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angle</span><span class="p">)]]</span>
    <span class="n">class_transforms</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="n">class_transforms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">class_transforms</span><span class="p">)</span>
</pre></div>
</div>
<p>This function generates random data from the distribution. For each
point it chooses a random class, then a random position in that class’
ellipse.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_data</span><span class="p">(</span><span class="n">n_points</span><span class="p">):</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_points</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n_points</span><span class="p">)</span>
    <span class="n">angle</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n_points</span><span class="p">)</span>
    <span class="n">points</span> <span class="o">=</span> <span class="p">(</span><span class="n">r</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angle</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angle</span><span class="p">)]))</span><span class="o">.</span><span class="n">T</span>
    <span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ijk,ik-&gt;ij&#39;</span><span class="p">,</span> <span class="n">class_transforms</span><span class="p">[</span><span class="n">classes</span><span class="p">],</span> <span class="n">points</span><span class="p">)</span>
    <span class="n">points</span> <span class="o">+=</span> <span class="n">class_centers</span><span class="p">[</span><span class="n">classes</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">classes</span><span class="p">,</span> <span class="n">points</span>
</pre></div>
</div>
<p>Let’s plot a bunch of random points drawn from this distribution to see
what it looks like. Points are colored based on their class label.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span>%matplotlib inline
import matplotlib.pyplot as plot
classes, points = generate_data(1000)
plot.scatter(x=points[:,0], y=points[:,1], c=classes)
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span>&lt;matplotlib.collections.PathCollection at 0x11fc3d860&gt;
</pre></div>
</div>
<img alt="../_images/Conditional_GAN_5_1.png" src="../_images/Conditional_GAN_5_1.png" />
<p>Now let’s create the model for our CGAN.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">deepchem.models.tensorgraph.layers</span> <span class="kn">as</span> <span class="nn">layers</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">TensorGraph</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">use_queue</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Inputs to the model</span>

<span class="n">random_in</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> <span class="c1"># Random input to the generator</span>
<span class="n">generator_classes</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span> <span class="c1"># The classes of the generated samples</span>
<span class="n">real_data_points</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="c1"># The training samples</span>
<span class="n">real_data_classes</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Feature</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span> <span class="c1"># The classes of the training samples</span>
<span class="n">is_real</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Weights</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># Flags to distinguish real from generated samples</span>

<span class="c1"># The generator</span>

<span class="n">gen_in</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Concat</span><span class="p">([</span><span class="n">random_in</span><span class="p">,</span> <span class="n">generator_classes</span><span class="p">])</span>
<span class="n">gen_dense1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">gen_in</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
<span class="n">gen_dense2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">gen_dense1</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
<span class="n">generator_points</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">gen_dense2</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_output</span><span class="p">(</span><span class="n">generator_points</span><span class="p">)</span>

<span class="c1"># The discriminator</span>

<span class="n">all_points</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Concat</span><span class="p">([</span><span class="n">generator_points</span><span class="p">,</span> <span class="n">real_data_points</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">all_classes</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Concat</span><span class="p">([</span><span class="n">generator_classes</span><span class="p">,</span> <span class="n">real_data_classes</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">discrim_in</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Concat</span><span class="p">([</span><span class="n">all_points</span><span class="p">,</span> <span class="n">all_classes</span><span class="p">])</span>
<span class="n">discrim_dense1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">discrim_in</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
<span class="n">discrim_dense2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">discrim_dense1</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
<span class="n">discrim_prob</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">discrim_dense2</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">)</span>
</pre></div>
</div>
<p>We’ll use different loss functions for training the generator and
discriminator. The discriminator outputs its predictions in the form of
a probability that each sample is a real sample (that is, that it came
from the training set rather than the generator). Its loss consists of
two terms. The first term tries to maximize the output probability for
real data, and the second term tries to minimize the output probability
for generated samples. The loss function for the generator is just a
single term: it tries to maximize the discriminator’s output probability
for generated samples.</p>
<p>For each one, we create a “submodel” specifying a set of layers that
will be optimized based on a loss function.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="c1"># Discriminator</span>

<span class="n">discrim_real_data_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">layers</span><span class="o">.</span><span class="n">Log</span><span class="p">(</span><span class="n">discrim_prob</span><span class="o">+</span><span class="mf">1e-10</span><span class="p">)</span> <span class="o">*</span> <span class="n">is_real</span>
<span class="n">discrim_gen_data_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">layers</span><span class="o">.</span><span class="n">Log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">discrim_prob</span><span class="o">+</span><span class="mf">1e-10</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">is_real</span><span class="p">)</span>
<span class="n">discrim_loss</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">(</span><span class="n">discrim_real_data_loss</span> <span class="o">+</span> <span class="n">discrim_gen_data_loss</span><span class="p">)</span>
<span class="n">discrim_submodel</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">create_submodel</span><span class="p">(</span><span class="n">layers</span><span class="o">=</span><span class="p">[</span><span class="n">discrim_dense1</span><span class="p">,</span> <span class="n">discrim_dense2</span><span class="p">,</span> <span class="n">discrim_prob</span><span class="p">],</span> <span class="n">loss</span><span class="o">=</span><span class="n">discrim_loss</span><span class="p">)</span>

<span class="c1"># Generator</span>

<span class="n">gen_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">layers</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Log</span><span class="p">(</span><span class="n">discrim_prob</span><span class="o">+</span><span class="mf">1e-10</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">is_real</span><span class="p">))</span>
<span class="n">gen_submodel</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">create_submodel</span><span class="p">(</span><span class="n">layers</span><span class="o">=</span><span class="p">[</span><span class="n">gen_dense1</span><span class="p">,</span> <span class="n">gen_dense2</span><span class="p">,</span> <span class="n">generator_points</span><span class="p">],</span> <span class="n">loss</span><span class="o">=</span><span class="n">gen_loss</span><span class="p">)</span>
</pre></div>
</div>
<p>Now to fit the model. Here are some important points to notice about the
code.</p>
<ul class="simple">
<li>We use <code class="docutils literal"><span class="pre">fit_generator()</span></code> to train only a single batch at a time,
and we alternate between the discriminator and the generator. That
way. both parts of the model improve together.</li>
<li>We only train the generator half as often as the discriminator. On
this particular model, that gives much better results. You will often
need to adjust <code class="docutils literal"><span class="pre">(#</span> <span class="pre">of</span> <span class="pre">discriminator</span> <span class="pre">steps)/(#</span> <span class="pre">of</span> <span class="pre">generator</span> <span class="pre">steps)</span></code>
to get good results on a given problem.</li>
<li>We disable checkpointing by specifying <code class="docutils literal"><span class="pre">checkpoint_interval=0</span></code>.
Since each call to <code class="docutils literal"><span class="pre">fit_generator()</span></code> includes only a single batch,
it would otherwise save a checkpoint to disk after every batch, which
would be very slow. If this were a real project and not just an
example, we would want to occasionally call
<code class="docutils literal"><span class="pre">model.save_checkpoint()</span></code> to write checkpoints at a reasonable
interval.</li>
</ul>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">batch_size</span>
<span class="n">discrim_error</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">gen_error</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20000</span><span class="p">):</span>
    <span class="n">classes</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">class_flags</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">to_one_hot</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
    <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">random_in</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)),</span>
               <span class="n">generator_classes</span><span class="p">:</span> <span class="n">class_flags</span><span class="p">,</span>
               <span class="n">real_data_points</span><span class="p">:</span> <span class="n">points</span><span class="p">,</span>
               <span class="n">real_data_classes</span><span class="p">:</span> <span class="n">class_flags</span><span class="p">,</span>
               <span class="n">is_real</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span><span class="mi">1</span><span class="p">))])}</span>
    <span class="n">discrim_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">([</span><span class="n">feed_dict</span><span class="p">],</span>
                                             <span class="n">submodel</span><span class="o">=</span><span class="n">discrim_submodel</span><span class="p">,</span>
                                             <span class="n">checkpoint_interval</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">step</span><span class="o">%</span><span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">gen_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">([</span><span class="n">feed_dict</span><span class="p">],</span>
                                             <span class="n">submodel</span><span class="o">=</span><span class="n">gen_submodel</span><span class="p">,</span>
                                             <span class="n">checkpoint_interval</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">step</span><span class="o">%</span><span class="mi">1000</span> <span class="o">==</span> <span class="mi">999</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">discrim_error</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">gen_error</span><span class="p">))</span>
        <span class="n">discrim_error</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">gen_error</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span>999 1.55168287337 0.0408441077992
1999 1.09775845635 0.10187220595
2999 0.645102792382 0.287973743975
3999 0.680221937269 0.421649519399
4999 1.01530539939 0.21572620222
5999 0.355141538292 0.51490073061
6999 0.342691998512 0.522037278384
7999 0.668916338205 0.268597296476
8999 0.716327803612 0.262840693563
9999 0.713392020047 0.29249474436
10999 0.701064119875 0.309196961999
11999 0.69168697983 0.326060062766
12999 0.688140272975 0.335194783509
13999 0.687209348738 0.336962600589
14999 0.685669041574 0.343026666999
15999 0.686265172005 0.343531137526
16999 0.686260136843 0.346471596062
17999 0.687051311135 0.347908975482
18999 0.689062111676 0.344198456705
19999 0.691419941247 0.344754773915
</pre></div>
</div>
<p>Have the trained model generate some data, and see how well it matches
the training distribution we plotted before.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="n">classes</span><span class="p">,</span> <span class="n">points</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">random_in</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span><span class="p">)),</span>
             <span class="n">generator_classes</span><span class="p">:</span> <span class="n">dc</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">to_one_hot</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)}</span>
<span class="n">gen_points</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_on_generator</span><span class="p">([</span><span class="n">feed_dict</span><span class="p">])</span>
<span class="n">plot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">gen_points</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">gen_points</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span>&lt;matplotlib.collections.PathCollection at 0x120561a58&gt;
</pre></div>
</div>
<img alt="../_images/Conditional_GAN_13_1.png" src="../_images/Conditional_GAN_13_1.png" />
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="../_sources/notebooks/Conditional_GAN.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2016, Stanford University and the Authors.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>