<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>MNIST GAN &mdash; deepchem 1.3.1 documentation</title>
    
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '1.3.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="deepchem 1.3.1 documentation" href="../index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-inverse navbar-default ">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><span><img src="../_static/logo.png"></span>
          deepchem</a>
        <span class="navbar-text navbar-version pull-left"><b>1.3</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="index.html">Notebooks</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../deepchem.html">deepchem package</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">MNIST GAN</a></li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="mnist-gan">
<h1>MNIST GAN<a class="headerlink" href="#mnist-gan" title="Permalink to this headline">¶</a></h1>
<p>In this example, we will train a Generative Adversarial Network (GAN) on
the MNIST dataset. This is a large collection of 28x28 pixel images of
handwritten digits. We will try to train a network to produce new images
of handwritten digits.</p>
<p>To begin, let’s import all the libraries we’ll need and load the dataset
(which comes bundled with Tensorflow).</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span>import deepchem as dc
import tensorflow as tf
from deepchem.models.tensorgraph import layers
from tensorflow.examples.tutorials.mnist import input_data
import matplotlib.pyplot as plot
import matplotlib.gridspec as gridspec
%matplotlib inline

mnist = input_data.read_data_sets(&#39;MNIST_data&#39;, one_hot=True)
images = mnist.train.images.reshape((-1, 28, 28, 1))
dataset = dc.data.NumpyDataset(images)
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span>Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
</pre></div>
</div>
<p>Let’s view some of the images to get an idea of what they look like.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_digits</span><span class="p">(</span><span class="n">im</span><span class="p">):</span>
  <span class="n">plot</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
  <span class="n">grid</span> <span class="o">=</span> <span class="n">gridspec</span><span class="o">.</span><span class="n">GridSpec</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">g</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">grid</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plot</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">im</span><span class="p">[</span><span class="n">i</span><span class="p">,:,:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>

<span class="n">plot_digits</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/MNIST_GAN_3_0.png" src="../_images/MNIST_GAN_3_0.png" />
<p>Now we can create our GAN. It consists of two parts:</p>
<ol class="arabic simple">
<li>The generator takes random noise as its input and produces output
that will hopefully resemble the training data.</li>
<li>The discriminator takes a set of samples as input (possibly training
data, possibly created by the generator), and tries to determine
which are which. Its output is interpreted as the probability that
each sample is from the training set.</li>
</ol>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DigitGAN</span><span class="p">(</span><span class="n">dc</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GAN</span><span class="p">):</span>

  <span class="k">def</span> <span class="nf">get_noise_input_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">get_data_input_shapes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>

  <span class="k">def</span> <span class="nf">create_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noise_input</span><span class="p">,</span> <span class="n">conditional_inputs</span><span class="p">):</span>
    <span class="n">dense1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">noise_input</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">normalizer_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">)</span>
    <span class="n">dense2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense1</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">,</span> <span class="n">normalizer_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">)</span>
    <span class="n">reshaped</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">((</span><span class="bp">None</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">dense2</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">reshaped</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">create_discriminator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_inputs</span><span class="p">,</span> <span class="n">conditional_inputs</span><span class="p">):</span>
    <span class="n">conv</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">num_outputs</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">dc</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">model_ops</span><span class="o">.</span><span class="n">lrelu</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span> <span class="n">normalizer_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">data_inputs</span><span class="p">)</span>
    <span class="n">dense</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">in_layers</span><span class="o">=</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">conv</span><span class="p">),</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dense</span>

<span class="n">gan</span> <span class="o">=</span> <span class="n">DigitGAN</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">)</span>
</pre></div>
</div>
<p>Now to train it. The generator and discriminator are both trained
together. The generator tries to get better at fooling the
discriminator, while the discriminator tries to get better at
distinguishing real data from generated data (which in turn gives the
generator a better training signal to learn from).</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">iterbatches</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">iterbatches</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">gan</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
      <span class="k">yield</span> <span class="p">{</span><span class="n">gan</span><span class="o">.</span><span class="n">data_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]}</span>

<span class="n">gan</span><span class="o">.</span><span class="n">fit_gan</span><span class="p">(</span><span class="n">iterbatches</span><span class="p">(</span><span class="mi">50</span><span class="p">),</span> <span class="n">generator_steps</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">checkpoint_interval</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span>Ending global_step 5000: generator average loss 5.6996, discriminator average loss 0.0341601
Ending global_step 10000: generator average loss 4.60495, discriminator average loss 0.112247
Ending global_step 15000: generator average loss 3.5461, discriminator average loss 0.205332
Ending global_step 20000: generator average loss 3.22442, discriminator average loss 0.239572
Ending global_step 25000: generator average loss 2.99321, discriminator average loss 0.292008
Ending global_step 27500: generator average loss 2.83743, discriminator average loss 0.310524
TIMING: model fitting took 291.696 s
</pre></div>
</div>
<p>Let’s generate some data and see how the results look.</p>
<div class="code ipython3 highlight-python"><div class="highlight"><pre><span></span><span class="n">plot_digits</span><span class="p">(</span><span class="n">gan</span><span class="o">.</span><span class="n">predict_gan_generator</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">))</span>
</pre></div>
</div>
<img alt="../_images/MNIST_GAN_9_0.png" src="../_images/MNIST_GAN_9_0.png" />
<p>Not too bad. Most of the generated images look convincingly like
handwritten digits, but only a few digits are represented. This is a
common problem in GANs called “mode collapse”. The generator learns to
produce output that closely resembles training data, but the range of
its output only covers a subset of the training distribution. Finding
ways to prevent mode collapse is an active area of research for GANs.</p>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="../_sources/notebooks/MNIST_GAN.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2016, Stanford University and the Authors.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>